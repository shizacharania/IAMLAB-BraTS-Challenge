{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch # import torch modules\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "98_y6CHWgje0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResSE_Block(nn.Module): # resSE block as the foundation of encoder and decoder blocks\n",
        "  def __init__(self, input_channels, size):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv3d(in_channels=input_channels, out_channels=input_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(num_features=4) #n features = channels\n",
        "    self.relu = nn.ReLU()\n",
        "    # add variables for SE\n",
        "    self.globalpooling = torch.nn.AvgPool3d(kernel_size=size)\n",
        "    self.input_channels = input_channels\n",
        "    self.fclayer1 = nn.Linear(in_features=input_channels, out_features=input_channels//4, bias=True) # reduces channels by reduction ratio\n",
        "    self.fclayer2 = nn.Linear(in_features=input_channels//4, out_features=input_channels, bias=True) # expands channels back\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # print(x.shape)\n",
        "    # print(\"\\nGoing to ResSE\")\n",
        "\n",
        "    # residual block\n",
        "    x1 = self.conv(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x1)\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    # print(\"x5\")\n",
        "    print(x5.shape)\n",
        "\n",
        "    # the SE module\n",
        "    x6 = self.globalpooling(x5) # global pooling layer to decrease spatial dimensions\n",
        "    # print(x6.shape)\n",
        "\n",
        "    x7 = x6.view(1, -1) # you need to view it in [1, x] format so it can go through an fc layer in pytorch (https://stackoverflow.com/questions/65945996/1d-cnn-on-pytorch-mat1-and-mat2-shapes-cannot-be-multiplied-10x3-and-10x2)\n",
        "    # print(x7.shape)\n",
        "\n",
        "    x7 = self.fclayer1(x7) # reduce channel\n",
        "    # print(x7.shape)\n",
        "    x8 = self.relu(x7)\n",
        "    # print(x8.shape)\n",
        "    x9 = self.fclayer2(x8) # increase channel\n",
        "    # print(x9.shape)\n",
        "    x10 = self.sigmoid(x9)\n",
        "    # print(x10.shape)\n",
        "\n",
        "    # scale - basically you go through the layers with [1, x] because it needs that format\n",
        "    # but then for scaling, you first need to add two extra dimensions in end (so it's same size/has the same number of dimensions as the input for SE module)\n",
        "    x11 = x10.view(1, self.input_channels, 1, 1, 1) # basically the size you want it to be - channels stays the same\n",
        "    # print(x11.shape)\n",
        "\n",
        "    # multiply the weights by the channels\n",
        "    x12 = torch.multiply(x5, x11) # e.x. [1, 24, 1, 1, 1] and [1, 24, 128, 128, 128]\n",
        "    # (number of batches and channels for which you need to multiply each weight to the channel, so should be same #)\n",
        "    # print(x12.shape)\n",
        "\n",
        "    # summation and then ReLU\n",
        "    x13 = torch.add(x12, x)\n",
        "    # print(x13.shape)\n",
        "    x14 = self.relu(x13)\n",
        "    print(x14.shape)\n",
        "    # print(\"Done ResSE\\n\")\n",
        "    \n",
        "    return x14 # returns output"
      ],
      "metadata": {
        "id": "WCSJf-NrjKT5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test ResSE_Block class with first block\n",
        "\n",
        "input = torch.randn((1, 24,128,128,128), dtype=torch.float)\n",
        "\n",
        "trial = ResSE_Block(input_channels=24, size=128)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ix1w-GAbXjR",
        "outputId": "1ef956fe-83ca-44e8-f39c-61f47d5e30e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResSE_Block(\n",
            "  (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (globalpooling): AvgPool3d(kernel_size=128, stride=128, padding=0)\n",
            "  (fclayer1): Linear(in_features=24, out_features=6, bias=True)\n",
            "  (fclayer2): Linear(in_features=6, out_features=24, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test ResSE_Block class\n",
        "\n",
        "input = torch.randn((1, 48, 96, 96, 96), dtype=torch.float)\n",
        "trial = ResSE_Block(input_channels=48, size=96)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukTdZD0ejFa-",
        "outputId": "96b3820a-5146-40ac-ef3a-8fa129cd37dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResSE_Block(\n",
            "  (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (globalpooling): AvgPool3d(kernel_size=96, stride=96, padding=0)\n",
            "  (fclayer1): Linear(in_features=48, out_features=12, bias=True)\n",
            "  (fclayer2): Linear(in_features=12, out_features=48, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "torch.Size([1, 48, 96, 96, 96])\n",
            "torch.Size([1, 48, 96, 96, 96])\n",
            "torch.Size([1, 48, 96, 96, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3cwjFdqCff93"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module): # if input is x, y, y, y --> output should be x*2, y/2, y/2, y/2 (except first and last block)\n",
        "  def __init__(self, n_blocks, input_channels, output_channels, size):\n",
        "    super().__init__()\n",
        "    self.resSEblock = ResSE_Block(input_channels, size)\n",
        "    self.downsample = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.n_blocks = n_blocks\n",
        "  def forward(self, x, downsample_bool):\n",
        "    # print(x.shape)\n",
        "    # print(x1.shape)\n",
        "    if self.n_blocks==1:\n",
        "      x1 = self.resSEblock(x)\n",
        "      # print(\" 1 downsample \")\n",
        "      # print(\"\\noutput of encoder block\")\n",
        "      if (downsample_bool==True):\n",
        "        x2 = self.downsample(x1)\n",
        "        return x1, x2\n",
        "        # print(x2.shape)\n",
        "        # print()\n",
        "      return x1, x1\n",
        "    else:\n",
        "      # print(\"side case x shape\")\n",
        "      # print(x.shape)\n",
        "      x1 = self.resSEblock(x)\n",
        "      # print(\"after first res\")\n",
        "      x2 = self.resSEblock(x1)\n",
        "      # print(\"\\noutput of encoder block\")\n",
        "      x3 = self.downsample(x2)\n",
        "      # print(x3.shape)\n",
        "      print()\n",
        "      return x2, x3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test encoder block with first block\n",
        "input = torch.randn((1, 24,128,128,128), dtype=torch.float)\n",
        "\n",
        "trial = EncoderBlock(n_blocks=1, input_channels=24, output_channels=48, size=128) # 1st encoder block\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, True)"
      ],
      "metadata": {
        "id": "WGRRVrUqkyeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a2c298-43e5-4b64-aa85-a8e253a8a65c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderBlock(\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=128, stride=128, padding=0)\n",
            "    (fclayer1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fclayer2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (downsample): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last block\n",
        "input = torch.randn((1, 384,8,8,8), dtype=torch.float)\n",
        "\n",
        "trial = EncoderBlock(n_blocks=1, input_channels=384, output_channels=384, size=8)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, False)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzjP4R_8togA",
        "outputId": "9ebe92ca-b428-4da8-8f0e-fa93b15a4896"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderBlock(\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=8, stride=8, padding=0)\n",
            "    (fclayer1): Linear(in_features=384, out_features=96, bias=True)\n",
            "    (fclayer2): Linear(in_features=96, out_features=384, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (downsample): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block1(nn.Module): # first scale attention block for the last decoding block\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 24x128x128x128\n",
        "    self.conv_initial1 = nn.Conv3d(in_channels=48, out_channels=24, kernel_size=1, stride=1) # conv for decreasing s2 channels\n",
        "    self.conv_initial2 = nn.Conv3d(in_channels=96, out_channels=24, kernel_size=1, stride=1) # conv for decreasing s3 channels\n",
        "    self.conv_initial3 = nn.Conv3d(in_channels=192, out_channels=24, kernel_size=1, stride=1) # conv for decreasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=24, out_features=6) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=6, out_features=24) # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1) # softmax for channels\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s1.shape[1] # number of channels we're working with \n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # decreasing channels using Conv3D\n",
        "    s2 = self.conv_initial1(s2) \n",
        "    s3 = self.conv_initial2(s3)\n",
        "    s4 = self.conv_initial3(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s2 = self.instancenorm(s2)\n",
        "    s3 = self.instancenorm(s3)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s2 = self.relu(s2)\n",
        "    s3 = self.relu(s3)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # trilinear upsampling for scales 2, 3, 4 (their spatial sizes - w, h, l)\n",
        "    s2 = torch.nn.functional.interpolate(s2, size=(128,128,128), mode='trilinear')\n",
        "    s3 = torch.nn.functional.interpolate(s3, size=(128,128,128), mode='trilinear')\n",
        "    s4 = torch.nn.functional.interpolate(s4, size=(128,128,128), mode='trilinear')\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales \n",
        "    p1 = s1 + s2 + s3 +s4\n",
        "    print(p1.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G1 = self.global_avg_pooling(p1)\n",
        "    print(G1.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G1 = G1.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G1.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g1 = self.fcn1(G1)\n",
        "    print(g1.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g1)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    # softmax\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g1)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g1)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g1)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S11 = torch.multiply(E1, s1)\n",
        "    w2_S12 = torch.multiply(E2, s2)\n",
        "    w3_S13 = torch.multiply(E3, s3)\n",
        "    w4_S14 = torch.multiply(E4, s4)\n",
        "    print(w1_S11.shape)\n",
        "    print(w2_S12.shape)\n",
        "    print(w3_S13.shape)\n",
        "    print(w4_S14.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S11 + w2_S12 + w3_S13 + w4_S14\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "4J5quBz5Z2Oz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test SA_Block1\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block1()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1qeVFZRd1W1",
        "outputId": "8926cd7c-1cdb-40f1-ef66-66d922c501dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block1(\n",
            "  (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "  (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 48x64x64x64\n",
        "    self.maxpool_initial1 = nn.MaxPool3d(kernel_size=2, stride=2) # maxpooling for first scale (reduce spatial size)\n",
        "    self.conv1 = nn.Conv3d(in_channels=24, out_channels=48, kernel_size=1, stride=1) # conv for increasing s1 channels\n",
        "    self.conv_initial3 = nn.Conv3d(in_channels=96, out_channels=48, kernel_size=1, stride=1) # conv for decreasing s3 channels\n",
        "    self.conv_initial4 = nn.Conv3d(in_channels=192, out_channels=48, kernel_size=1, stride=1) # conv for decreasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=48, out_features=12) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=12, out_features=48) # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1) # softmax for channels\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s2.shape[1]\n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # increasing spatial sizes of scale 1\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    # increasing spatial sizes of scale 1 (2 times)\n",
        "    s1 = self.conv1(s1) # increasing channels for scale 1\n",
        "    s3 = self.conv_initial3(s3) # decreasing channels for scale 3\n",
        "    s4 = self.conv_initial4(s4) # decreasing channels for scale 4\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s1 = self.instancenorm(s1)\n",
        "    s3 = self.instancenorm(s3)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s1 = self.relu(s1)\n",
        "    s3 = self.relu(s3)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # trilinear upsampling for scales 3 and 4 (their spatial sizes - w, h, l)\n",
        "    s3 = torch.nn.functional.interpolate(s3, size=(64,64,64), mode='trilinear')\n",
        "    s4 = torch.nn.functional.interpolate(s4, size=(64,64,64), mode='trilinear')\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales\n",
        "    p2 = s1 + s2 + s3 +s4\n",
        "    print(p2.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G2 = self.global_avg_pooling(p2)\n",
        "    print(G2.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G2 = G2.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G2.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g2 = self.fcn1(G2)\n",
        "    print(g2.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g2)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g2)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g2)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g2)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S21 = torch.multiply(E1, s1)\n",
        "    w2_S22 = torch.multiply(E2, s2)\n",
        "    w3_S23 = torch.multiply(E3, s3)\n",
        "    w4_S24 = torch.multiply(E4, s4)\n",
        "    print(w1_S21.shape)\n",
        "    print(w2_S22.shape)\n",
        "    print(w3_S23.shape)\n",
        "    print(w4_S24.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S21 + w2_S22 + w3_S23 + w4_S24\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "3cTIUj3b9hVj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test SA_Block2\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block2()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjZJwu6u_B-1",
        "outputId": "6b76bc52-d417-4d20-e145-e39d72b3e4c8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block2(\n",
            "  (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "  (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 96x32x32x32\n",
        "    self.maxpool_initial1 = nn.MaxPool3d(kernel_size=2, stride=2) # maxpooling for 1st and 2nd scale (reduce spatial size)\n",
        "    self.conv1 = nn.Conv3d(in_channels=24, out_channels=96, kernel_size=1, stride=1) # conv for increasing s1 channels\n",
        "    self.conv2 = nn.Conv3d(in_channels=48, out_channels=96, kernel_size=1, stride=1) # conv for increasing s2 channels\n",
        "    self.conv_initial4 = nn.Conv3d(in_channels=192, out_channels=96, kernel_size=1, stride=1) # conv for decreasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=96, out_features=24) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=24, out_features=96)  # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # softmax for channels\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s3.shape[1]\n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # increasing spatial sizes of scale 1 (2 times)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    # increasing channels for scale 1\n",
        "    s1 = self.conv1(s1)\n",
        "    # increasing spatial sizes of scale 2\n",
        "    s2 = self.maxpool_initial1(s2)\n",
        "    # increasing channels for scale 2\n",
        "    s2 = self.conv2(s2)\n",
        "    s4 = self.conv_initial4(s4) # decreasing channels for scale 4\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s1 = self.instancenorm(s1)\n",
        "    s2 = self.instancenorm(s2)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s1 = self.relu(s1)\n",
        "    s2 = self.relu(s2)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # trilinear upsampling for scales 3 and 4 (their spatial sizes - w, h, l)\n",
        "    s4 = torch.nn.functional.interpolate(s4, size=(32,32,32), mode='trilinear')\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales\n",
        "    p3 = s1 + s2 + s3 +s4\n",
        "    print(p3.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G3 = self.global_avg_pooling(p3)\n",
        "    print(G3.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G3 = G3.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G3.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g3 = self.fcn1(G3)\n",
        "    print(g3.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g3)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    # softmax\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g3)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g3)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g3)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S31 = torch.multiply(E1, s1)\n",
        "    w2_S32 = torch.multiply(E2, s2)\n",
        "    w3_S33 = torch.multiply(E3, s3)\n",
        "    w4_S34 = torch.multiply(E4, s4)\n",
        "    print(w1_S31.shape)\n",
        "    print(w2_S32.shape)\n",
        "    print(w3_S33.shape)\n",
        "    print(w4_S34.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S31 + w2_S32 + w3_S33 + w4_S34\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "AW2EDDBTEJ9g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test SA_Block3\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block3()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p47_b-BrGvRg",
        "outputId": "54390185-6161-414b-8a7d-168b4ef2729f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block3(\n",
            "  (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "  (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 192x16x16x16\n",
        "    self.maxpool_initial1 = nn.MaxPool3d(kernel_size=2, stride=2) # maxpooling for scale 1,2,3 (reduce spatial size)\n",
        "    self.conv1 = nn.Conv3d(in_channels=24, out_channels=192, kernel_size=1, stride=1) # conv for increasing s2 channels\n",
        "    self.conv2 = nn.Conv3d(in_channels=48, out_channels=192, kernel_size=1, stride=1) # conv for increasing s3 channels\n",
        "    self.conv3 = nn.Conv3d(in_channels=96, out_channels=192, kernel_size=1, stride=1) # conv for increasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=192, out_features=48) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=48, out_features=192) # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # softmax for channels\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s4.shape[1]\n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # increasing spatial sizes of scale 1 (3 times)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.conv1(s1)\n",
        "\n",
        "    # increasing spatial sizes of scale 2 (2 times)\n",
        "    s2 = self.maxpool_initial1(s2)\n",
        "    s2 = self.maxpool_initial1(s2)\n",
        "    s2 = self.conv2(s2)\n",
        "\n",
        "    # increasing spatial sizes of scale 3\n",
        "    s3 = self.maxpool_initial1(s3)\n",
        "    s3 = self.conv3(s3)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s1 = self.instancenorm(s1)\n",
        "    s2 = self.instancenorm(s2)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s1 = self.relu(s1)\n",
        "    s2 = self.relu(s2)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales\n",
        "    p4 = s1 + s2 + s3 +s4\n",
        "    print(p4.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G4 = self.global_avg_pooling(p4)\n",
        "    print(G4.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G4 = G4.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G4.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g4 = self.fcn1(G4)\n",
        "    print(g4.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g4)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    # softmax\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g4)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g4)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g4)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S41 = torch.multiply(E1, s1)\n",
        "    w2_S42 = torch.multiply(E2, s2)\n",
        "    w3_S43 = torch.multiply(E3, s3)\n",
        "    w4_S44 = torch.multiply(E4, s4)\n",
        "    print(w1_S41.shape)\n",
        "    print(w2_S42.shape)\n",
        "    print(w3_S43.shape)\n",
        "    print(w4_S44.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S41 + w2_S42 + w3_S43 + w4_S44\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "oUXyxyT8Iap1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block4()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxvsjyotI8iI",
        "outputId": "e1c038d9-d8e4-4827-dd9a-13e3555032da"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block4(\n",
            "  (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "  (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module): # note: also contains sa block \n",
        "  def __init__(self, input_channels, output_channels, size):\n",
        "    super().__init__()\n",
        "    self.upsample = nn.ConvTranspose3d(in_channels=input_channels, out_channels=output_channels, kernel_size=2, stride=2)\n",
        "    # ^for the upsampling, conv transpose is not the same thing as conv. if you do kernel size of 3 and stride of 2 with this (i.e. what the paper said),\n",
        "    # then the output is an odd number. so, i just made the kernel size = 2 and stride = 2, but still increased the channels by 2 times\n",
        "    self.resSEblock = ResSE_Block(output_channels, size)\n",
        "    self.sa_block1 = SA_Block1()\n",
        "    self.sa_block2 = SA_Block2()\n",
        "    self.sa_block3 = SA_Block3()\n",
        "    self.sa_block4 = SA_Block4()\n",
        "\n",
        "  def forward(self, x, s1, s2, s3, s4, number_scale):\n",
        "    print(x.shape)\n",
        "    # depending on the scale, pick the class for the scale attention block\n",
        "    if number_scale == 1:\n",
        "      x1 = self.sa_block1(s1, s2, s3, s4)\n",
        "    elif number_scale == 2:\n",
        "      x1 = self.sa_block2(s1, s2, s3, s4)\n",
        "    elif number_scale == 3:\n",
        "      x1 = self.sa_block3(s1, s2, s3, s4)\n",
        "    elif number_scale == 4:\n",
        "      x1 = self.sa_block4(s1, s2, s3, s4)\n",
        "\n",
        "    x2 = self.upsample(x) # upsample\n",
        "    print(x2.shape)\n",
        "    x3 = torch.add(x1, x2) # add input + sa-net block's output\n",
        "    x4 = self.resSEblock(x3) # res block\n",
        "    return x4"
      ],
      "metadata": {
        "id": "TuHq6-3HK3rX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test decoder block class\n",
        "input = torch.randn((384,8,8,8), dtype=torch.float) \n",
        "\n",
        "trial = DecoderBlock(input_channels=384, output_channels=192, size=16)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 4)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "id": "fv3dY2EpLQPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd67bbeb-763f-430e-c334-4ed5223532db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=16, stride=16, padding=0)\n",
            "    (fclayer1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fclayer2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([384, 8, 8, 8])\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((192,16,16,16), dtype=torch.float)\n",
        "\n",
        "trial = DecoderBlock(input_channels=192, output_channels=96, size=32)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 3)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaSXVf2xSWvG",
        "outputId": "82261f53-938b-4c28-849d-a56d9f295aba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=32, stride=32, padding=0)\n",
            "    (fclayer1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fclayer2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([192, 16, 16, 16])\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((96,32,32,32), dtype=torch.float)\n",
        "\n",
        "trial = DecoderBlock(input_channels=96, output_channels=48, size=64)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 2)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LT0GZGGSsHz",
        "outputId": "a86526a7-29b1-4c76-8ebf-9bf4d3eec07c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=64, stride=64, padding=0)\n",
            "    (fclayer1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fclayer2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([96, 32, 32, 32])\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((48,64,64,64), dtype=torch.float)\n",
        "\n",
        "trial = DecoderBlock(input_channels=48, output_channels=24, size=128)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 1)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-99jiyo2S2P8",
        "outputId": "f79a20f4-8af9-4dd0-fde5-f791505fb708"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=128, stride=128, padding=0)\n",
            "    (fclayer1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fclayer2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([48, 64, 64, 64])\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # first conv3d with 1x1x1 kernel (just to increase channels)\n",
        "    self.conv3d_1x1x1 = nn.Conv3d(in_channels=4, out_channels=24, kernel_size=1, stride=1)\n",
        "\n",
        "    # encoder blocks\n",
        "    self.encoderblock1 = EncoderBlock(n_blocks=1, input_channels=24, output_channels=48, size=128)\n",
        "    self.encoderblock2 = EncoderBlock(n_blocks=2, input_channels=48, output_channels=96, size=64)\n",
        "    self.encoderblock3 = EncoderBlock(n_blocks=2, input_channels=96, output_channels=192, size=32)\n",
        "    self.encoderblock4 = EncoderBlock(n_blocks=2, input_channels=192, output_channels=384, size=16)\n",
        "    self.encoderblock5 = EncoderBlock(n_blocks=1, input_channels=384, output_channels=1, size=8) # output_channels doesn't matter\n",
        "\n",
        "    # decoder blocks\n",
        "    self.decoderblock1 = DecoderBlock(input_channels=384, output_channels=192, size=16)\n",
        "    self.decoderblock2 = DecoderBlock(input_channels=192, output_channels=96, size=32)\n",
        "    self.decoderblock3 = DecoderBlock(input_channels=96, output_channels=48, size=64)\n",
        "    self.decoderblock4 = DecoderBlock(input_channels=48, output_channels=24, size=128)\n",
        "\n",
        "    # 1x1x1 convs to change channel size (leading to output of model)\n",
        "    self.conv1x1x1a = nn.Conv3d(in_channels=192, out_channels=3, kernel_size=1)\n",
        "    self.conv1x1x1b = nn.Conv3d(in_channels=96, out_channels=3, kernel_size=1)\n",
        "    self.conv1x1x1c = nn.Conv3d(in_channels=48, out_channels=3, kernel_size=1)\n",
        "    self.conv1x1x1d = nn.Conv3d(in_channels=24, out_channels=3, kernel_size=1)\n",
        "\n",
        "    # scale attention blocks for each scale\n",
        "    self.sa_block1 = SA_Block1()\n",
        "    self.sa_block2 = SA_Block2()\n",
        "    self.sa_block3 = SA_Block3()\n",
        "    self.sa_block4 = SA_Block4()\n",
        "\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    # increase channels of input\n",
        "    x = self.conv3d_1x1x1(x)\n",
        "    print(x.shape)\n",
        "    # encoder block # 1\n",
        "    out1, x1 = self.encoderblock1(x, True)\n",
        "    print(out1.shape)\n",
        "    print(x1.shape)\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 2\n",
        "    out2, x2 = self.encoderblock2(x1, True)\n",
        "    print(out2.shape)\n",
        "    print(x2.shape)\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 3\n",
        "    out3, x3 = self.encoderblock3(x2, True)\n",
        "    print(out3.shape)\n",
        "    print(x3.shape) \n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 4\n",
        "    out4, x4 = self.encoderblock4(x3, True)\n",
        "    print(out4.shape)\n",
        "    print(x4.shape) \n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 5\n",
        "    out5, x5 = self.encoderblock5(x4, False)\n",
        "    print(out5.shape)\n",
        "    print(x5.shape)\n",
        "\n",
        "    print(\"\\nDecoder time\\n\")\n",
        "    # decoder block # 1 (contains SA-Net)\n",
        "    x6 = self.decoderblock1(x5, out1, out2, out3, out4, 4)\n",
        "    print(x6.shape)\n",
        "    output1 = self.conv1x1x1a(x6)\n",
        "    print(\"output1 \" + str(output1.shape))\n",
        "    trilinearoutput1 = nn.functional.interpolate(input=output1, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output1 \" + str(trilinearoutput1.shape))\n",
        "\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # decoder block # 2 (contains SA-Net)\n",
        "    x7 = self.decoderblock2(x6, out1, out2, out3, out4, 3)\n",
        "    print(x7.shape)\n",
        "    output2 = self.conv1x1x1b(x7)\n",
        "    print(\"output2 \" + str(output2.shape))\n",
        "    trilinearoutput2 = nn.functional.interpolate(input=output2, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output2 \" + str(trilinearoutput2.shape))\n",
        "\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # decoder block # 3 (contains SA-Net)\n",
        "    x8 = self.decoderblock3(x7, out1, out2, out3, out4, 2)\n",
        "    print(x8.shape)\n",
        "    output3 = self.conv1x1x1c(x8)\n",
        "    print(\"output3 \" + str(output3.shape))\n",
        "    trilinearoutput3 = nn.functional.interpolate(input=output3, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output3 \" + str(trilinearoutput3.shape))\n",
        "\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # decoder block # 4 (contains SA-Net)\n",
        "    x9 = self.decoderblock4(x8, out1, out2, out3, out4, 1)\n",
        "    print(x9.shape)\n",
        "    output4 = self.conv1x1x1d(x9)\n",
        "    print(\"output4 \" + str(output4.shape))\n",
        "    trilinearoutput4 = nn.functional.interpolate(input=output4, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output4 \" + str(trilinearoutput4.shape))\n",
        "\n",
        "    print()\n",
        "    output = trilinearoutput1 + trilinearoutput2 + trilinearoutput3 + trilinearoutput4\n",
        "    print(output.shape)\n",
        "\n",
        "    channel1 = output[:, 0, :, :, :]\n",
        "    print(channel1.shape)\n",
        "\n",
        "    channel2 = output[:, 1, :, :, :]\n",
        "    print(channel2.shape)\n",
        "\n",
        "    channel3 = output[:, 2, :, :, :]\n",
        "    print(channel3.shape)\n",
        "\n",
        "    print()\n",
        "    sig_channel1 = self.sigmoid(channel1)\n",
        "    print(sig_channel1.shape)\n",
        "\n",
        "    sig_channel2 = self.sigmoid(channel2)\n",
        "    print(sig_channel2.shape)\n",
        "\n",
        "    sig_channel3 = self.sigmoid(channel3)\n",
        "    print(sig_channel3.shape)\n",
        "\n",
        "    return output, sig_channel1, sig_channel2, sig_channel3"
      ],
      "metadata": {
        "id": "S15bw1K6mFip"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((1,4,128,128,128), dtype=torch.float)\n",
        "\n",
        "model = SA_Net()\n",
        "\n",
        "# print(model)\n",
        "print()\n",
        "\n",
        "out = model(input)"
      ],
      "metadata": {
        "id": "ACPaXIW2mbeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6710d9d6-9dca-4a37-cf62-ae6d077f1781"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "torch.Size([1, 4, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "Decoder time\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "output1 torch.Size([1, 3, 16, 16, 16])\n",
            "trilinear interpolation output1 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "output2 torch.Size([1, 3, 32, 32, 32])\n",
            "trilinear interpolation output2 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "output3 torch.Size([1, 3, 64, 64, 64])\n",
            "trilinear interpolation output3 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "output4 torch.Size([1, 3, 128, 128, 128])\n",
            "trilinear interpolation output4 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, sig_channel1, sig_channel2, sig_channel3 = out"
      ],
      "metadata": {
        "id": "S4Rvs44Y2pQT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(sig_channel1.shape)\n",
        "print(sig_channel2.shape)\n",
        "print(sig_channel3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YK-PnjKRkZJ",
        "outputId": "a471975c-897b-43d7-9d32-9de5be186637"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sig_channel1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b42cmdoP21GZ",
        "outputId": "9a42ac2b-ed01-42af-99e4-969c36d34083"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.5716, 0.5552, 0.5552,  ..., 0.4568, 0.4549, 0.5002],\n",
            "          [0.5512, 0.4958, 0.4490,  ..., 0.4544, 0.3612, 0.4417],\n",
            "          [0.5873, 0.4497, 0.5823,  ..., 0.4256, 0.5121, 0.4284],\n",
            "          ...,\n",
            "          [0.4803, 0.4738, 0.4276,  ..., 0.4475, 0.3451, 0.4034],\n",
            "          [0.5116, 0.4068, 0.5013,  ..., 0.3989, 0.5134, 0.4020],\n",
            "          [0.4747, 0.4377, 0.4679,  ..., 0.4448, 0.4739, 0.3962]],\n",
            "\n",
            "         [[0.6225, 0.5824, 0.6087,  ..., 0.4519, 0.4913, 0.5248],\n",
            "          [0.5689, 0.5636, 0.5723,  ..., 0.5018, 0.4957, 0.4275],\n",
            "          [0.5772, 0.5105, 0.5441,  ..., 0.4463, 0.4802, 0.4452],\n",
            "          ...,\n",
            "          [0.5262, 0.5222, 0.5289,  ..., 0.4769, 0.4800, 0.3670],\n",
            "          [0.5234, 0.4438, 0.4865,  ..., 0.4590, 0.4562, 0.3591],\n",
            "          [0.4972, 0.4619, 0.4757,  ..., 0.4745, 0.4942, 0.3745]],\n",
            "\n",
            "         [[0.6289, 0.6129, 0.6311,  ..., 0.5142, 0.4942, 0.5335],\n",
            "          [0.5663, 0.6174, 0.5527,  ..., 0.5816, 0.4733, 0.5401],\n",
            "          [0.6069, 0.5428, 0.6031,  ..., 0.4724, 0.5192, 0.4765],\n",
            "          ...,\n",
            "          [0.5389, 0.5583, 0.4978,  ..., 0.5259, 0.4147, 0.4396],\n",
            "          [0.5176, 0.4431, 0.4583,  ..., 0.4416, 0.4337, 0.3731],\n",
            "          [0.4741, 0.4468, 0.4514,  ..., 0.4771, 0.4593, 0.3914]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.5769, 0.5232, 0.5325,  ..., 0.4981, 0.5301, 0.4957],\n",
            "          [0.5867, 0.5178, 0.4918,  ..., 0.5341, 0.5171, 0.4215],\n",
            "          [0.5351, 0.4785, 0.4890,  ..., 0.4966, 0.5359, 0.4772],\n",
            "          ...,\n",
            "          [0.6301, 0.6378, 0.5653,  ..., 0.4935, 0.5205, 0.4039],\n",
            "          [0.6073, 0.5148, 0.5548,  ..., 0.4018, 0.4814, 0.4085],\n",
            "          [0.5815, 0.5238, 0.5501,  ..., 0.4627, 0.5184, 0.4234]],\n",
            "\n",
            "         [[0.6068, 0.5545, 0.5580,  ..., 0.5333, 0.5546, 0.4793],\n",
            "          [0.5272, 0.5277, 0.5425,  ..., 0.5549, 0.5036, 0.4796],\n",
            "          [0.5744, 0.4763, 0.5222,  ..., 0.5268, 0.5801, 0.5107],\n",
            "          ...,\n",
            "          [0.5870, 0.6186, 0.6173,  ..., 0.5001, 0.4766, 0.4529],\n",
            "          [0.5767, 0.5462, 0.5498,  ..., 0.4763, 0.5080, 0.4257],\n",
            "          [0.5372, 0.5083, 0.5152,  ..., 0.4450, 0.4436, 0.3931]],\n",
            "\n",
            "         [[0.5662, 0.5582, 0.5549,  ..., 0.5570, 0.5412, 0.5327],\n",
            "          [0.5940, 0.5417, 0.5930,  ..., 0.5410, 0.6125, 0.5227],\n",
            "          [0.5372, 0.5181, 0.5380,  ..., 0.5455, 0.5522, 0.5313],\n",
            "          ...,\n",
            "          [0.6193, 0.6153, 0.6737,  ..., 0.4758, 0.5815, 0.4682],\n",
            "          [0.6056, 0.5927, 0.6019,  ..., 0.4730, 0.4913, 0.4760],\n",
            "          [0.5910, 0.5722, 0.5923,  ..., 0.5080, 0.5186, 0.4348]]]],\n",
            "       grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "a5kfKHfscVSn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_images = []\n",
        "for i in range(2):\n",
        "  newx = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_images.append(newx)"
      ],
      "metadata": {
        "id": "kZ7gjWYYcWpx"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_images))\n",
        "print(randomized_training_images[0].shape)\n",
        "# print(randomized_training_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kne4m1AcYGe",
        "outputId": "3ddf45b0-740e-46dc-868d-784e77dc8273"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "vXnGIQencYOo"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_segmentations))\n",
        "print(randomized_training_segmentations[0].shape)\n",
        "# print(randomized_training_segmentations[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcvBFEzIcYRf",
        "outputId": "c8a8a94d-cad1-42fc-b57a-45ff014bdb25"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_data = list(zip(randomized_training_images, randomized_training_segmentations))"
      ],
      "metadata": {
        "id": "b1s0G_K6cYUF"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset=randomized_training_data, batch_size=1, shuffle=True) # batch size should be 1"
      ],
      "metadata": {
        "id": "H8q0AQnFcYWX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0p_15dTcYY_",
        "outputId": "e913f7f6-de83-479f-a73b-b10cd429e0e0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_images.append(newy)"
      ],
      "metadata": {
        "id": "G8xOMErHcYb2"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_images))\n",
        "print(randomized_validation_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgj9inGVcfd7",
        "outputId": "251ec1f2-437d-47bc-f25a-e3d2e7ceaafc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "_Ib2uFNOcfgy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_segmentations))\n",
        "print(randomized_validation_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JelW4D2Hcfjh",
        "outputId": "559e12f4-c781-404e-9ea0-bd7b7ddb7125"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_data = list(zip(randomized_validation_images, randomized_validation_segmentations))"
      ],
      "metadata": {
        "id": "6klhcyNGcfm4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationloader = torch.utils.data.DataLoader(dataset=randomized_validation_data, batch_size=1, shuffle=True) # batch size should be 1"
      ],
      "metadata": {
        "id": "WpLDAruycYgN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validationloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G42uovD4ckY1",
        "outputId": "73f59e99-4bda-4585-d339-c9f11b279c53"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_images.append(newy)"
      ],
      "metadata": {
        "id": "P2Vh1_GsckbK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_images))\n",
        "print(randomized_testing_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb7l3fYfcmRK",
        "outputId": "f6219af0-0039-4768-c689-ef178bb3092c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "95hcqyQGcnRo"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_segmentations))\n",
        "print(randomized_testing_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeTEhDiWcnUF",
        "outputId": "8621af33-9193-4877-d95f-afd197e39a96"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_data = list(zip(randomized_testing_images, randomized_testing_segmentations))"
      ],
      "metadata": {
        "id": "6zXZyYi9cnXN"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testingloader = torch.utils.data.DataLoader(dataset=randomized_testing_data, batch_size=1, shuffle=True) # batch size needs to be 1"
      ],
      "metadata": {
        "id": "8y6W4rxEckdv"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "SA-Net\n",
        "implement voxel-wise focal loss\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "k1PxWUzXs2l1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f945c4d-b2fd-4454-8d95-464a99a5bad2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSA-Net\\nimplement voxel-wise focal loss\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class JaccardandFocalLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def forward(self, y_pred, y_true):\n",
        "    #focal\n",
        "    BCE_loss = nn.BCELoss()(y_pred, y_true) # the problem here was that I didn't declare and object for the class\n",
        "    # https://discuss.pytorch.org/t/runtimeerror-boolean-value-of-tensor-with-more-than-one-value-is-ambiguous/95361\n",
        "    pt = torch.exp(-BCE_loss) # this is the only part of implementation that's hard to understand\n",
        "    focal_loss = (1 - pt)**2*BCE_loss\n",
        "\n",
        "    # flatten to easily do it pixel by pixel\n",
        "    y_true = y_true.view(-1)\n",
        "    y_pred = y_pred.view(-1)\n",
        "    intersection = (y_true*y_pred).sum()\n",
        "    union = y_true.sum() + y_pred.sum() + intersection\n",
        "    jaccard_loss = 1 - intersection/union\n",
        "\n",
        "    return focal_loss + jaccard_loss"
      ],
      "metadata": {
        "id": "5oMQ12ga3ama"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class FocalLoss(nn.Module):\n",
        "#     def __init__(self, gamma=2): # a=1 and γ=2 works the best\n",
        "#         super().__init__()\n",
        "#         self.gamma = gamma\n",
        "\n",
        "#     def forward(self, y_pred, y_true):\n",
        "#       print(\"here\")\n",
        "#       BCE_loss = nn.BCELoss(pred, true)\n",
        "#       print(\"done 1\")\n",
        "#       pt = torch.exp(-BCE_loss) # this is the only part of implementation that's hard to understand\n",
        "#       print(\"done 2\")\n",
        "#       focal_loss = (1 - pt)**self.gamma*BCE_loss\n",
        "#       print(\"done 3\")\n",
        "#       return focal_loss"
      ],
      "metadata": {
        "id": "mvJHzdQnI6TI"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim"
      ],
      "metadata": {
        "id": "AEV2OCf4sYz-"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs\n",
        "epochs = 2 # should be 300 \n",
        "# loss\n",
        "criterion = JaccardandFocalLoss()\n",
        "# criterion2 = FocalLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.003, weight_decay=10**-5)"
      ],
      "metadata": {
        "id": "Amk1Ekx_rlCe"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "iowZn4E6nffJ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = [] # losses from training every epoch\n",
        "validation_losses = [] # losses from validation in every epoch\n",
        "\n",
        "for i in range(epochs): # for every epoch\n",
        "  start_epoch = datetime.datetime.now() # start the timer in datetime module\n",
        "  training_loss = 0 # training loss for this epoch\n",
        "  validation_loss = 0 # validation loss for this epoch\n",
        "  class1_trloss = 0 # class 1 loss for this epoch\n",
        "  class2_trloss = 0 # class 2 loss for this epoch\n",
        "  class3_trloss = 0 # class 3 loss for this epoch\n",
        "  print(\"training time\")\n",
        "  for images, segs in trainloader: # getting one batch from trainloader\n",
        "    optimizer.zero_grad() # turn on gradients (used for forward and backprop)\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    # need to squeeze the 1 in first dimension\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    output, sig_channel1, sig_channel2, sig_channel3 = model(images)\n",
        "    print()\n",
        "    # binary channels\n",
        "    sig_channel1 = sig_channel1.squeeze()\n",
        "    sig_channel2 = sig_channel2.squeeze()\n",
        "    sig_channel3 = sig_channel3.squeeze()\n",
        "    print(output.shape)\n",
        "    print(sig_channel1.shape)\n",
        "    print(sig_channel2.shape)\n",
        "    print(sig_channel3.shape)\n",
        "\n",
        "    print(segs.shape) # torch.Size([3, 128, 128, 128])\n",
        "    true_channel1 = segs[0, :, :, :]\n",
        "    true_channel2 = segs[1, :, :, :]\n",
        "    true_channel3 = segs[2, :, :, :]\n",
        "    \n",
        "    print()\n",
        "    print()\n",
        "    print(true_channel1.shape)\n",
        "    print(sig_channel1.shape)\n",
        "    channel1_loss = criterion(true_channel1, sig_channel1) # comparing one individual channel to another (class 1)\n",
        "    print(channel1_loss)\n",
        "    class1_trloss += channel1_loss.item()\n",
        "\n",
        "    print(true_channel2.shape)\n",
        "    print(sig_channel2.shape)\n",
        "    channel2_loss = criterion(true_channel2, sig_channel2) # comparing one individual channel to another (class 2)\n",
        "    print(channel2_loss)\n",
        "    class2_trloss += channel2_loss.item()\n",
        "\n",
        "    print(true_channel3.shape)\n",
        "    print(sig_channel3.shape)\n",
        "    channel3_loss = criterion(true_channel3, sig_channel3) # comparing one individual channel to another (class 3)\n",
        "    print(channel3_loss)\n",
        "    class3_trloss += channel3_loss.item()\n",
        "\n",
        "    print()\n",
        "    loss = (channel1_loss + channel2_loss + channel3_loss)/3\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    loss.backward() # back propagation\n",
        "    training_loss += loss.item() # add loss to training loss\n",
        "    print()\n",
        "\n",
        "  print(\"validation time\")\n",
        "  for images, segs in validationloader: # getting one batch from validationloader\n",
        "    optimizer.zero_grad() # keep gradients on (used for forward and backprop)\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    # need to squeeze the 1 in first dimension\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    output, sig_channel1, sig_channel2, sig_channel3 = model(images)\n",
        "    print()\n",
        "    sig_channel1 = sig_channel1.squeeze()\n",
        "    sig_channel2 = sig_channel2.squeeze()\n",
        "    sig_channel3 = sig_channel3.squeeze()\n",
        "    print(output.shape)\n",
        "    print(sig_channel1.shape)\n",
        "    print(sig_channel2.shape)\n",
        "    print(sig_channel3.shape)\n",
        "\n",
        "    print(segs.shape) # torch.Size([3, 128, 128, 128])\n",
        "    true_channel1 = segs[0, :, :, :]\n",
        "    true_channel2 = segs[1, :, :, :]\n",
        "    true_channel3 = segs[2, :, :, :]\n",
        "    \n",
        "    print()\n",
        "    print()\n",
        "    print(true_channel1.shape)\n",
        "    print(sig_channel1.shape)\n",
        "    channel1_loss = criterion(true_channel1, sig_channel1) # comparing one individual channel to another (class 1)\n",
        "    print(channel1_loss)\n",
        "\n",
        "    print(true_channel2.shape)\n",
        "    print(sig_channel2.shape)\n",
        "    channel2_loss = criterion(true_channel2, sig_channel2) # comparing one individual channel to another (class 2)\n",
        "    print(channel2_loss)\n",
        "\n",
        "    print(true_channel3.shape)\n",
        "    print(sig_channel3.shape)\n",
        "    channel3_loss = criterion(true_channel3, sig_channel3) # comparing one individual channel to another (class 3)\n",
        "    print(channel3_loss)\n",
        "\n",
        "    print()\n",
        "    loss = (channel1_loss + channel2_loss + channel3_loss)/3 # calculating loss from formula in paper\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    loss.backward() # backpropagation\n",
        "    validation_loss += loss.item() # add loss to validation loss\n",
        "    print()\n",
        "\n",
        "  # find avg losses for each image\n",
        "  training_losses.append(training_loss/len(trainloader))\n",
        "  validation_losses.append(validation_loss/len(validationloader))\n",
        "\n",
        "  # print results about epoch\n",
        "  print(\"Epoch: {}/{}... Training Loss: {}... Validation Loss: {}...\".format(i+1,epochs, training_losses[-1], validation_losses[-1]))\n",
        "  if validation_loss < min(validation_losses):\n",
        "    print(\"Validation loss has decreased...saving model\")\n",
        "    torch.save(model.state_dict(), \"fcn.pth\")\n",
        "  \n",
        "  # end timer\n",
        "  end_epoch = datetime.datetime.now()\n",
        "  # calculate and print out time it takes for every epoch\n",
        "  time_epoch = end_epoch-start_epoch\n",
        "  print(\"Epoch time:\", str(time_epoch), \"\\n\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "bByWybESrlTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_losses)\n",
        "print(validation_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJUeQ_BCceCB",
        "outputId": "234136a9-e4e5-4c9d-f1c9-dac52b6ff07d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.2081958055496216, 1.2081958055496216]\n",
            "[1.2081413269042969, 1.2081413269042969]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9UQ--k3Cnq6G"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize losses\n",
        "plt.plot(training_losses, label=\"Training loss\")\n",
        "plt.plot(validation_losses, label=\"Validation loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "Ye2eeKGonsBj",
        "outputId": "080ef04c-d6e6-48de-e9ba-9433fc60631b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fe4a157e910>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(outputs, segmentations): # they find individual\n",
        "  # outputs = torch.Size([2, 3, 128, 128, 128])\n",
        "  # segmentations = torch.Size([2, 3, 128, 128, 128])\n",
        "  # print(segmentations.shape)\n",
        "  n_classes = segmentations.shape[0]\n",
        "  print(n_classes)\n",
        "  region_scores = []\n",
        "  for i in range(n_classes):\n",
        "    outputs = outputs.view(-1)\n",
        "    segmentations = segmentations.view(-1)\n",
        "    numerator = 2*(outputs*segmentations).sum()\n",
        "    denominator = outputs.sum() + segmentations.sum()\n",
        "    dice = (numerator) / (denominator)\n",
        "    region_scores.append(dice)\n",
        "  return region_scores"
      ],
      "metadata": {
        "id": "TdTolKrsl1F-"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1 NECROTIC TUMOUR CORE (NCR — label 1) - index 0\n",
        "\n",
        "2 GD-ENHANCING TUMOUR (ET — label 2) - index 1\n",
        "\n",
        "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3) - index 2\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "rJcpAUFhl2dT",
        "outputId": "71859a06-f3cf-4823-e71a-4adaf4826731"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1 NECROTIC TUMOUR CORE (NCR — label 1) - index 0\\n\\n2 GD-ENHANCING TUMOUR (ET — label 2) - index 1\\n\\n3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3) - index 2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff"
      ],
      "metadata": {
        "id": "Bfbn09OCPF1d"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hausdorff(outputs, segmentations): # for region for every image\n",
        "  print(outputs.shape)\n",
        "  print(segmentations.shape)\n",
        "\n",
        "  # for each image in batch\n",
        "  h_imgs = [0,0,0]\n",
        "  len_imgs = len(outputs)\n",
        "\n",
        "  for idx in range(len_imgs): # for each image\n",
        "    out = outputs[idx]\n",
        "    seg = segmentations[idx]\n",
        "    n_classes = out.shape[0]\n",
        "    # print(n_classes)\n",
        "\n",
        "    region_hd_scores = []\n",
        "    for i in range(n_classes): # for each class\n",
        "      region_out = out[i]\n",
        "      region_seg = seg[i]\n",
        "      # print(region_out.shape)\n",
        "      # print(region_seg.shape)\n",
        "\n",
        "      total_hd_image = 0\n",
        "      for j in range(region_out.shape[0]): # for each slice\n",
        "        out_slice = region_out[j]\n",
        "        seg_slice = region_seg[j]\n",
        "        # print(out_slice.shape)\n",
        "        # print(seg_slice.shape)\n",
        "        a = directed_hausdorff(out_slice, seg_slice)[0]\n",
        "        b = directed_hausdorff(seg_slice, out_slice)[0]\n",
        "        hd_slice = max(a, b)\n",
        "        total_hd_image += hd_slice\n",
        "      avg_hd_image = total_hd_image/region_out.shape[0]\n",
        "      # print(avg_hd_image)\n",
        "      region_hd_scores.append(avg_hd_image)\n",
        "    # print(region_hd_scores)\n",
        "    h_imgs[0] += region_hd_scores[0]\n",
        "    h_imgs[1] += region_hd_scores[1]\n",
        "    h_imgs[2] += region_hd_scores[2]\n",
        "  \n",
        "  for each in range(len(h_imgs)):\n",
        "    h_imgs[each] = h_imgs[each]/len_imgs\n",
        "  \n",
        "  print(h_imgs)\n",
        "\n",
        "  return h_imgs"
      ],
      "metadata": {
        "id": "nYniyTRrntkM"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, segs in testingloader:\n",
        "    with torch.no_grad(): # no gradients (there's no backprop, only evaluation)\n",
        "      print(len(images), len(segs))\n",
        "      print(images.shape)\n",
        "      print(segs.shape)\n",
        "      # exclude first dimension of 1\n",
        "      images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "      # segs = segs.long() - no\n",
        "      segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "      print(images.shape)\n",
        "      print(segs.shape)\n",
        "      output, sig_channel1, sig_channel2, sig_channel3 = model(images) # put images through model\n",
        "      # basically each classx_probabilities has 3 items each with 2 images in them\n",
        "      print()\n",
        "      print(output.shape)\n",
        "      print(sig_channel1.shape)\n",
        "      print(sig_channel2.shape)\n",
        "      print(sig_channel3.shape)\n",
        "\n",
        "      print()\n",
        "      activated_outputs = torch.cat((sig_channel1.unsqueeze(dim=1), sig_channel2.unsqueeze(dim=1), sig_channel3.unsqueeze(dim=1)),dim=1)\n",
        "      print(activated_outputs.shape)\n",
        "      \n",
        "      print(segs.shape)\n",
        "      region_scores = dice_score(activated_outputs, segs)\n",
        "\n",
        "      print(\"\\n\", \".......\"*5, \"\\n\")\n",
        "\n",
        "      print(len(region_scores))\n",
        "      print(region_scores)\n",
        "      print()\n",
        "\n",
        "      print(\"1 NECROTIC TUMOUR CORE (NCR — label 1)\")\n",
        "      print(region_scores[0].item())\n",
        "      print()\n",
        "\n",
        "      print(\"2 GD-ENHANCING TUMOUR (ET — label 2)\")\n",
        "      print(region_scores[1].item())\n",
        "      print()\n",
        "\n",
        "      print(\"3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\")\n",
        "      print(region_scores[2].item())\n",
        "\n",
        "      segs = segs.unsqueeze(dim=0)\n",
        "\n",
        "      print(\"\\n\", \".......\"*5, \"\\n\")\n",
        "      hd_scores = hausdorff(activated_outputs, segs)\n",
        "\n",
        "      print()\n",
        "      print(len(hd_scores))\n",
        "      print(hd_scores)\n",
        "      print()\n",
        "\n",
        "      print(\"1 NECROTIC TUMOUR CORE (NCR — label 1)\")\n",
        "      print(hd_scores[0])\n",
        "      print()\n",
        "\n",
        "      print(\"2 GD-ENHANCING TUMOUR (ET — label 2)\")\n",
        "      print(hd_scores[1])\n",
        "      print()\n",
        "\n",
        "      print(\"3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\")\n",
        "      print(hd_scores[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjGkfMrjl4rz",
        "outputId": "66ae2429-f538-4e01-b0a1-bcb9b955e8f3"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 1\n",
            "torch.Size([1, 1, 4, 128, 128, 128])\n",
            "torch.Size([1, 1, 3, 128, 128, 128])\n",
            "torch.Size([4, 128, 128, 128])\n",
            "torch.Size([3, 128, 128, 128])\n",
            "torch.Size([4, 128, 128, 128])\n",
            "torch.Size([24, 128, 128, 128])\n",
            "torch.Size([24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "Decoder time\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "output1 torch.Size([1, 3, 16, 16, 16])\n",
            "trilinear interpolation output1 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "output2 torch.Size([1, 3, 32, 32, 32])\n",
            "trilinear interpolation output2 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "output3 torch.Size([1, 3, 64, 64, 64])\n",
            "trilinear interpolation output3 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "output4 torch.Size([1, 3, 128, 128, 128])\n",
            "trilinear interpolation output4 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([3, 128, 128, 128])\n",
            "3\n",
            "\n",
            " ................................... \n",
            "\n",
            "3\n",
            "[tensor(0.4739), tensor(0.4739), tensor(0.4739)]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR — label 1)\n",
            "0.4738621115684509\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET — label 2)\n",
            "0.4738621115684509\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\n",
            "0.4738621115684509\n",
            "\n",
            " ................................... \n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "[3.541757199984179, 3.5846239576590393, 3.589420167000951]\n",
            "\n",
            "3\n",
            "[3.541757199984179, 3.5846239576590393, 3.589420167000951]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR — label 1)\n",
            "3.541757199984179\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET — label 2)\n",
            "3.5846239576590393\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\n",
            "3.589420167000951\n",
            "1 1\n",
            "torch.Size([1, 1, 4, 128, 128, 128])\n",
            "torch.Size([1, 1, 3, 128, 128, 128])\n",
            "torch.Size([4, 128, 128, 128])\n",
            "torch.Size([3, 128, 128, 128])\n",
            "torch.Size([4, 128, 128, 128])\n",
            "torch.Size([24, 128, 128, 128])\n",
            "torch.Size([24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "Decoder time\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "output1 torch.Size([1, 3, 16, 16, 16])\n",
            "trilinear interpolation output1 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "output2 torch.Size([1, 3, 32, 32, 32])\n",
            "trilinear interpolation output2 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "output3 torch.Size([1, 3, 64, 64, 64])\n",
            "trilinear interpolation output3 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "output4 torch.Size([1, 3, 128, 128, 128])\n",
            "trilinear interpolation output4 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "torch.Size([1, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([3, 128, 128, 128])\n",
            "3\n",
            "\n",
            " ................................... \n",
            "\n",
            "3\n",
            "[tensor(0.4736), tensor(0.4736), tensor(0.4736)]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR — label 1)\n",
            "0.47364524006843567\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET — label 2)\n",
            "0.47364524006843567\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\n",
            "0.47364524006843567\n",
            "\n",
            " ................................... \n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "torch.Size([1, 3, 128, 128, 128])\n",
            "[3.5387088062053498, 3.5888529672252347, 3.5932930375360645]\n",
            "\n",
            "3\n",
            "[3.5387088062053498, 3.5888529672252347, 3.5932930375360645]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR — label 1)\n",
            "3.5387088062053498\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET — label 2)\n",
            "3.5888529672252347\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\n",
            "3.5932930375360645\n"
          ]
        }
      ]
    }
  ]
}