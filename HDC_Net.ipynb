{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HDC-Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 307,
      "metadata": {
        "id": "OXG09_X81jA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_to_conv2d(ts, n):\n",
        "  # from [x, 64, 64, 64]\n",
        "  ts = ts.unsqueeze(dim=0)\n",
        "  ts = torch.nn.functional.interpolate(ts, scale_factor=[1/n,1,1])\n",
        "  ts = ts.squeeze(dim=0)\n",
        "  return ts\n",
        "\n",
        "def adapt_from_conv2d(ts, n):\n",
        "  # from [x, 1, 64, 64]\n",
        "  ts = ts.unsqueeze(dim=0)\n",
        "  ts = torch.nn.functional.interpolate(ts, scale_factor=[n,1,1])\n",
        "  # ts = ts.squeeze(dim=0)\n",
        "  return ts"
      ],
      "metadata": {
        "id": "ip8YrXxIUXDw"
      },
      "execution_count": 308,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Block(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    self.one_one_one1 = nn.Conv3d(channels, channels, kernel_size=1, stride=1)\n",
        "    # self.three_three_one = nn.Conv3d(8, 8, kernel_size=[3,3,1], stride=1)\n",
        "    self.three_three_one = nn.Conv2d(1, 1, kernel_size=3, stride=1, padding=1) # doesn't work with 2d convs because of dimensions\n",
        "    self.one_one_one2 = nn.Conv3d(4, channels, kernel_size=1, stride=1)\n",
        "  def forward(self, x):\n",
        "    slices = x.shape[2]\n",
        "    print(slices)\n",
        "    print(x.shape)\n",
        "\n",
        "    x1 = self.one_one_one1(x)\n",
        "    print(x1.shape)\n",
        "\n",
        "    channel_group1 = x1[:, 0, :, :, :]\n",
        "    channel_group1 = adapt_to_conv2d(channel_group1, slices)\n",
        "    print(channel_group1.shape)\n",
        "\n",
        "    channel_group2 = x1[:, 1, :, :, :]\n",
        "    channel_group2 = adapt_to_conv2d(channel_group2, slices)\n",
        "    print(channel_group2.shape)\n",
        "\n",
        "    channel_group3 = x1[:, 2, :, :, :]\n",
        "    channel_group3 = adapt_to_conv2d(channel_group3, slices)\n",
        "    print(channel_group3.shape)\n",
        "\n",
        "    channel_group4 = x1[:, 3, :, :, :]\n",
        "    channel_group4 = adapt_to_conv2d(channel_group4, slices)\n",
        "    print(channel_group4.shape)\n",
        "\n",
        "    print()\n",
        "\n",
        "    final_group2 = self.three_three_one(channel_group2)\n",
        "    print(final_group2.shape)\n",
        "    \n",
        "    print()\n",
        "\n",
        "    group2_group3 = torch.cat([final_group2, channel_group3], dim=0)\n",
        "    print(group2_group3.shape)\n",
        "    final_group23 = self.three_three_one(group2_group3)\n",
        "    print(final_group23.shape)\n",
        "\n",
        "    print()\n",
        "\n",
        "    group2_group3_group4 = torch.cat([final_group23, channel_group4], dim=0)\n",
        "    print(group2_group3_group4.shape)\n",
        "    final_group234 = self.three_three_one(group2_group3_group4)\n",
        "    print(final_group234.shape)\n",
        "\n",
        "    print()\n",
        "\n",
        "    final_group1234 = torch.cat([final_group234, channel_group1], dim=0)\n",
        "    print(final_group1234.shape)\n",
        "\n",
        "    final_group1234 = adapt_from_conv2d(final_group1234, slices)\n",
        "    print(final_group1234.shape)\n",
        "\n",
        "    x2 = self.one_one_one2(final_group1234)\n",
        "    print(x2.shape)\n",
        "\n",
        "    x3 = x + x2\n",
        "\n",
        "    return x3"
      ],
      "metadata": {
        "id": "c3Udsg0fIlx3"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(1, 32, 32, 32, 32), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Block(32)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCTjnTjRKHJN",
        "outputId": "574c7e62-071a-4a04-93fb-5f1f176832d4"
      },
      "execution_count": 310,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 32, 32, 32, 32])\n",
            "HDC_Block(\n",
            "  (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (three_three_one): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (one_one_one2): Conv3d(4, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            ")\n",
            "\n",
            "32\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "torch.Size([2, 1, 32, 32])\n",
            "torch.Size([2, 1, 32, 32])\n",
            "\n",
            "torch.Size([3, 1, 32, 32])\n",
            "torch.Size([3, 1, 32, 32])\n",
            "\n",
            "torch.Size([4, 1, 32, 32])\n",
            "torch.Size([1, 4, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Net(nn.Module):\n",
        "  def __init__(self, x):\n",
        "    super().__init__()\n",
        "    # self.pds = torch.nn.functional.interpolate(x)\n",
        "    self.conv1 = nn.Conv3d(in_channels=32, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
        "    self.HDC = HDC_Block(32)\n",
        "    self.maxpool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "    self.softmax = nn.Softmax()\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    nimages, channels, width, height, depth = x.shape\n",
        "    print(nimages, channels, width, height, depth)\n",
        "    print(x.type)\n",
        "    # x1 = torch.tensor(scipy.ndimage.zoom(x, [1, 8.0, 0.5, 0.5, 0.5])) # using this function took about 2 minutes and for many images, it's not reasonable\n",
        "    x1 = torch.nn.functional.interpolate(x, scale_factor=0.5) # interpolate only looks at dim 2,3,4... (doesn't regard for channel and number of images)\n",
        "    # instead, I used torch.nn.functional.interpolate to interpolate the spatial dimensions, but for the channels I used a 1x1x1 conv\n",
        "    # because they did want to avoid using 3x3x3 conv and it will work same\n",
        "    print(x1.shape)\n",
        "    x1 = nn.Conv3d(in_channels=4, out_channels=32, kernel_size=1, stride=1)(x1)\n",
        "    print(x1.shape)\n",
        "    x2 = self.conv1(x1)\n",
        "    print(x2.shape)\n",
        "\n",
        "    print()\n",
        "\n",
        "    x3 = self.HDC(x2)\n",
        "    x4 = self.maxpool(x3)\n",
        "    print(x4.shape)\n",
        "\n",
        "    print()\n",
        "    \n",
        "    x5 = self.HDC(x4)\n",
        "    x6 = self.maxpool(x5)\n",
        "    print(x6.shape)\n",
        "\n",
        "    print()\n",
        "\n",
        "    x7 = self.HDC(x6)\n",
        "    x8 = self.maxpool(x7)\n",
        "    print(x8.shape)\n",
        "\n",
        "    print()\n",
        "\n",
        "    x9 = self.HDC(x8)\n",
        "    print(x9.shape)\n",
        "\n",
        "    print()\n",
        "    \n",
        "    x10 = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)(x9)\n",
        "    print(x10.shape)\n",
        "    x11 = torch.add(x10, x7)\n",
        "    print(x11.shape)\n",
        "    x12 = self.HDC(x11)\n",
        "    print(x12.shape)\n",
        "\n",
        "    x13 = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)(x12)\n",
        "    print(x13.shape)\n",
        "    x14 = torch.add(x13, x5)\n",
        "    print(x14.shape)\n",
        "    x15 = self.HDC(x14)\n",
        "    print(x15.shape)\n",
        "\n",
        "    x16 = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)(x15)\n",
        "    print(x16.shape)\n",
        "    x17 = torch.add(x16, x3)\n",
        "    print(x17.shape)\n",
        "    x18 = self.HDC(x17)\n",
        "    print(x18.shape)\n",
        "\n",
        "    print()\n",
        "    \n",
        "    x19 = nn.ConvTranspose3d(32, 3, kernel_size=2, stride=2)(x18)\n",
        "    print(x19.shape)\n",
        "\n",
        "    prob = self.softmax(x19)\n",
        "\n",
        "    return x19, prob"
      ],
      "metadata": {
        "id": "FnUEVd9i3bS8"
      },
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Net(x)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bf1ybX73Wjd",
        "outputId": "a8951a86-24c6-4145-d50e-8d3864e2f415"
      },
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 128, 128, 128])\n",
            "HDC_Net(\n",
            "  (conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (HDC): HDC_Block(\n",
            "    (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (three_three_one): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (one_one_one2): Conv3d(4, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  )\n",
            "  (maxpool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "torch.Size([1, 4, 128, 128, 128])\n",
            "1 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f96b170c590>\n",
            "torch.Size([1, 4, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "\n",
            "64\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "\n",
            "torch.Size([1, 1, 64, 64])\n",
            "\n",
            "torch.Size([2, 1, 64, 64])\n",
            "torch.Size([2, 1, 64, 64])\n",
            "\n",
            "torch.Size([3, 1, 64, 64])\n",
            "torch.Size([3, 1, 64, 64])\n",
            "\n",
            "torch.Size([4, 1, 64, 64])\n",
            "torch.Size([1, 4, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "\n",
            "32\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "torch.Size([2, 1, 32, 32])\n",
            "torch.Size([2, 1, 32, 32])\n",
            "\n",
            "torch.Size([3, 1, 32, 32])\n",
            "torch.Size([3, 1, 32, 32])\n",
            "\n",
            "torch.Size([4, 1, 32, 32])\n",
            "torch.Size([1, 4, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "\n",
            "16\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "\n",
            "torch.Size([1, 1, 16, 16])\n",
            "\n",
            "torch.Size([2, 1, 16, 16])\n",
            "torch.Size([2, 1, 16, 16])\n",
            "\n",
            "torch.Size([3, 1, 16, 16])\n",
            "torch.Size([3, 1, 16, 16])\n",
            "\n",
            "torch.Size([4, 1, 16, 16])\n",
            "torch.Size([1, 4, 16, 16, 16])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 32, 8, 8, 8])\n",
            "\n",
            "8\n",
            "torch.Size([1, 32, 8, 8, 8])\n",
            "torch.Size([1, 32, 8, 8, 8])\n",
            "torch.Size([1, 1, 8, 8])\n",
            "torch.Size([1, 1, 8, 8])\n",
            "torch.Size([1, 1, 8, 8])\n",
            "torch.Size([1, 1, 8, 8])\n",
            "\n",
            "torch.Size([1, 1, 8, 8])\n",
            "\n",
            "torch.Size([2, 1, 8, 8])\n",
            "torch.Size([2, 1, 8, 8])\n",
            "\n",
            "torch.Size([3, 1, 8, 8])\n",
            "torch.Size([3, 1, 8, 8])\n",
            "\n",
            "torch.Size([4, 1, 8, 8])\n",
            "torch.Size([1, 4, 8, 8, 8])\n",
            "torch.Size([1, 32, 8, 8, 8])\n",
            "torch.Size([1, 32, 8, 8, 8])\n",
            "\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "16\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "torch.Size([1, 1, 16, 16])\n",
            "\n",
            "torch.Size([1, 1, 16, 16])\n",
            "\n",
            "torch.Size([2, 1, 16, 16])\n",
            "torch.Size([2, 1, 16, 16])\n",
            "\n",
            "torch.Size([3, 1, 16, 16])\n",
            "torch.Size([3, 1, 16, 16])\n",
            "\n",
            "torch.Size([4, 1, 16, 16])\n",
            "torch.Size([1, 4, 16, 16, 16])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 32, 16, 16, 16])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "32\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "torch.Size([1, 1, 32, 32])\n",
            "\n",
            "torch.Size([2, 1, 32, 32])\n",
            "torch.Size([2, 1, 32, 32])\n",
            "\n",
            "torch.Size([3, 1, 32, 32])\n",
            "torch.Size([3, 1, 32, 32])\n",
            "\n",
            "torch.Size([4, 1, 32, 32])\n",
            "torch.Size([1, 4, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 32, 32, 32])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "64\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "torch.Size([1, 1, 64, 64])\n",
            "\n",
            "torch.Size([1, 1, 64, 64])\n",
            "\n",
            "torch.Size([2, 1, 64, 64])\n",
            "torch.Size([2, 1, 64, 64])\n",
            "\n",
            "torch.Size([3, 1, 64, 64])\n",
            "torch.Size([3, 1, 64, 64])\n",
            "\n",
            "torch.Size([4, 1, 64, 64])\n",
            "torch.Size([1, 4, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "torch.Size([1, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, probability = out"
      ],
      "metadata": {
        "id": "Z4lqjhQl9QRF"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dX3XHUnj9SiF",
        "outputId": "81745829-8869-42c9-8a37-c4952cb310df"
      },
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n",
            "tensor([[[[[ 1.3352e-02,  5.1008e-01, -1.2334e-01,  ...,  3.5770e-01,\n",
            "            -1.8187e-02,  5.3047e-01],\n",
            "           [-2.1438e-01, -1.6631e-01, -3.2354e-01,  ..., -2.4701e-01,\n",
            "            -3.4320e-01, -1.0304e-01],\n",
            "           [-1.8454e-01,  6.6412e-01,  3.9195e-02,  ...,  4.4311e-01,\n",
            "             1.6506e-01,  4.8279e-01],\n",
            "           ...,\n",
            "           [-2.8958e-01, -8.6609e-02, -4.3220e-01,  ..., -1.0983e-01,\n",
            "            -3.5034e-01,  2.6012e-02],\n",
            "           [-1.7226e-01,  5.1136e-01,  1.0627e-01,  ...,  3.8220e-01,\n",
            "             1.7234e-01,  5.2318e-01],\n",
            "           [ 2.1654e-01, -1.7558e-01,  1.4851e-01,  ..., -2.5490e-01,\n",
            "             1.4170e-01,  2.2263e-01]],\n",
            "\n",
            "          [[ 5.3952e-01, -7.9148e-01,  7.1376e-01,  ..., -7.3147e-01,\n",
            "             7.1752e-01, -6.5223e-01],\n",
            "           [ 4.2476e-01,  6.2628e-01,  3.4775e-01,  ...,  5.7942e-01,\n",
            "             2.5304e-01,  4.2800e-01],\n",
            "           [ 3.1814e-01, -7.5857e-01,  5.5796e-01,  ..., -5.6664e-01,\n",
            "             5.7474e-01, -7.5530e-01],\n",
            "           ...,\n",
            "           [ 3.9993e-01,  4.8722e-01,  3.8495e-01,  ...,  6.8976e-01,\n",
            "             4.0613e-01,  6.6219e-01],\n",
            "           [ 2.4970e-01, -5.6308e-01,  5.1660e-01,  ..., -6.0572e-01,\n",
            "             4.0601e-01, -6.8102e-01],\n",
            "           [ 1.2897e-01,  3.5510e-01,  4.0662e-01,  ...,  4.6849e-01,\n",
            "             4.0142e-01,  7.0462e-01]],\n",
            "\n",
            "          [[-1.2312e-01,  5.4659e-01, -2.3263e-01,  ...,  5.2029e-01,\n",
            "            -2.3418e-01,  3.6789e-01],\n",
            "           [-4.4890e-01,  2.3879e-02, -2.6717e-01,  ..., -2.0318e-01,\n",
            "            -2.1445e-01, -1.1581e-01],\n",
            "           [-3.2551e-02,  3.7719e-01, -1.9680e-01,  ...,  4.4865e-01,\n",
            "             1.0428e-01,  4.8693e-01],\n",
            "           ...,\n",
            "           [-4.8829e-01, -1.3706e-01, -4.0854e-01,  ..., -2.3691e-01,\n",
            "            -2.2509e-01,  1.4456e-02],\n",
            "           [-6.5822e-02,  3.7858e-01,  1.3742e-02,  ...,  3.5814e-01,\n",
            "             5.1088e-02,  5.4167e-01],\n",
            "           [-2.7628e-02, -2.3522e-01, -3.7364e-02,  ..., -4.4562e-01,\n",
            "             9.0096e-02, -2.3599e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 4.7244e-01, -8.0369e-01,  6.7949e-01,  ..., -8.1145e-01,\n",
            "             6.6134e-01, -8.2317e-01],\n",
            "           [ 4.2942e-01,  7.4596e-01,  4.0891e-01,  ...,  6.1462e-01,\n",
            "             5.3262e-01,  7.6812e-01],\n",
            "           [ 2.3969e-01, -6.6638e-01,  4.1169e-01,  ..., -8.3025e-01,\n",
            "             5.0126e-01, -9.7558e-01],\n",
            "           ...,\n",
            "           [ 4.5719e-01,  7.0944e-01,  4.3314e-01,  ...,  7.3739e-01,\n",
            "             5.5494e-01,  7.7527e-01],\n",
            "           [ 4.0385e-01, -5.0307e-01,  4.2345e-01,  ..., -7.0172e-01,\n",
            "             5.9516e-01, -8.5633e-01],\n",
            "           [ 4.7033e-01,  6.2012e-01,  3.7631e-01,  ...,  6.2528e-01,\n",
            "             5.0654e-01,  6.4032e-01]],\n",
            "\n",
            "          [[-4.9432e-02,  4.8952e-01, -1.5514e-01,  ...,  5.6718e-01,\n",
            "            -2.2145e-01,  3.1273e-01],\n",
            "           [-3.7070e-01, -2.2109e-01, -3.0796e-01,  ..., -1.0097e-01,\n",
            "            -1.7569e-01, -6.4434e-02],\n",
            "           [-8.9873e-02,  4.0043e-01, -1.4446e-01,  ...,  4.7274e-01,\n",
            "            -2.4180e-02,  6.1808e-01],\n",
            "           ...,\n",
            "           [-2.3820e-01, -2.6922e-01, -2.2978e-01,  ..., -3.0238e-01,\n",
            "            -1.5777e-01, -5.1871e-02],\n",
            "           [-1.2863e-01,  3.5165e-01, -6.6237e-02,  ...,  3.5289e-01,\n",
            "            -3.1809e-02,  4.8821e-01],\n",
            "           [-1.2624e-01, -3.8008e-01,  1.1823e-01,  ..., -3.7189e-01,\n",
            "             1.8631e-01, -2.8059e-01]],\n",
            "\n",
            "          [[ 5.4934e-01, -6.6072e-01,  3.2381e-01,  ..., -7.0504e-01,\n",
            "             3.2100e-01, -3.7186e-01],\n",
            "           [ 2.1954e-01,  4.8756e-01,  5.1447e-01,  ...,  4.7279e-01,\n",
            "             4.6079e-01,  5.5192e-01],\n",
            "           [ 6.2271e-01, -5.7724e-01,  3.3681e-01,  ..., -7.3462e-01,\n",
            "             2.6583e-01, -5.2477e-01],\n",
            "           ...,\n",
            "           [ 1.4065e-02,  5.3010e-01,  2.7958e-01,  ...,  6.2730e-01,\n",
            "             5.8041e-01,  7.1723e-01],\n",
            "           [ 6.5186e-01, -4.6194e-01,  2.3987e-01,  ..., -5.3053e-01,\n",
            "             2.9898e-01, -4.0466e-01],\n",
            "           [ 5.9262e-01,  5.2869e-01,  5.3461e-01,  ...,  5.4999e-01,\n",
            "             5.8960e-01,  6.8726e-01]]],\n",
            "\n",
            "\n",
            "         [[[-5.0849e-02,  3.9012e-01,  5.0613e-02,  ...,  4.2836e-01,\n",
            "             8.1933e-02,  1.0290e-01],\n",
            "           [ 1.2632e-01, -5.1674e-01,  2.6552e-01,  ..., -7.2038e-01,\n",
            "             2.0857e-02, -4.5724e-01],\n",
            "           [-4.3040e-01,  2.1138e-02,  1.7284e-01,  ...,  2.1953e-01,\n",
            "             2.3099e-01,  4.1412e-01],\n",
            "           ...,\n",
            "           [ 1.9431e-01, -6.1413e-01,  2.2355e-01,  ..., -7.6115e-01,\n",
            "             1.0211e-01, -4.1823e-01],\n",
            "           [-3.6200e-01, -1.0591e-02,  1.6215e-01,  ...,  9.0282e-02,\n",
            "             7.5216e-02,  2.5417e-01],\n",
            "           [ 3.0041e-01, -7.6357e-01,  2.1103e-01,  ..., -7.9898e-01,\n",
            "             1.2181e-01, -7.6166e-01]],\n",
            "\n",
            "          [[-2.6439e-01,  3.7187e-01, -6.9017e-01,  ...,  2.0834e-01,\n",
            "            -5.2209e-01,  7.5482e-01],\n",
            "           [ 5.6446e-01, -1.0348e+00,  5.0571e-01,  ..., -1.0870e+00,\n",
            "             3.9927e-01, -9.5083e-01],\n",
            "           [-7.3749e-01,  4.3996e-01, -7.0440e-01,  ...,  2.4304e-01,\n",
            "            -6.5529e-01,  5.4203e-01],\n",
            "           ...,\n",
            "           [ 5.9082e-01, -1.0766e+00,  6.4774e-01,  ..., -1.2159e+00,\n",
            "             3.7082e-01, -1.0398e+00],\n",
            "           [-6.5340e-01,  4.2769e-01, -8.4472e-01,  ...,  4.3295e-01,\n",
            "            -7.3967e-01,  5.4927e-01],\n",
            "           [ 2.9206e-01, -1.0365e+00,  4.9199e-01,  ..., -1.0766e+00,\n",
            "             4.3686e-01, -9.9621e-01]],\n",
            "\n",
            "          [[-1.4136e-01,  1.3578e-01, -2.7203e-02,  ...,  2.3881e-01,\n",
            "            -1.2555e-01,  4.1496e-01],\n",
            "           [-4.4809e-02, -4.3456e-01, -1.6350e-01,  ..., -4.9920e-01,\n",
            "            -1.0869e-01, -7.4109e-01],\n",
            "           [-6.5212e-02,  6.1500e-01, -6.2856e-02,  ...,  6.1424e-01,\n",
            "             1.8729e-02,  3.8990e-01],\n",
            "           ...,\n",
            "           [-1.6133e-01, -4.6155e-01, -7.9632e-02,  ..., -6.6962e-01,\n",
            "            -6.3700e-02, -6.5600e-01],\n",
            "           [ 1.1581e-01,  4.7280e-01,  2.5056e-03,  ...,  5.4621e-01,\n",
            "            -5.4667e-03,  4.0282e-01],\n",
            "           [-1.1790e-01, -1.0358e+00, -6.0428e-02,  ..., -9.6196e-01,\n",
            "            -1.5474e-01, -6.8877e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-2.7580e-01,  3.0670e-01, -7.2995e-01,  ...,  2.3465e-01,\n",
            "            -6.5604e-01,  3.5034e-01],\n",
            "           [ 5.4220e-01, -1.0032e+00,  4.4348e-01,  ..., -1.0100e+00,\n",
            "             3.8411e-01, -1.0049e+00],\n",
            "           [-6.3211e-01,  2.8732e-01, -8.6448e-01,  ...,  1.7534e-01,\n",
            "            -7.4799e-01,  2.9943e-01],\n",
            "           ...,\n",
            "           [ 6.2082e-01, -1.1041e+00,  6.0569e-01,  ..., -9.7662e-01,\n",
            "             5.0324e-01, -9.2594e-01],\n",
            "           [-5.6861e-01,  5.1848e-01, -7.2840e-01,  ...,  2.4041e-01,\n",
            "            -6.6212e-01,  3.5904e-01],\n",
            "           [ 2.6491e-01, -1.1167e+00,  3.8931e-01,  ..., -9.9868e-01,\n",
            "             5.4247e-01, -9.7400e-01]],\n",
            "\n",
            "          [[-1.6043e-01,  1.3137e-01, -2.7537e-01,  ..., -8.0755e-02,\n",
            "            -2.2456e-01,  5.0054e-01],\n",
            "           [-7.8277e-02, -4.8005e-01, -5.5083e-02,  ..., -4.4162e-01,\n",
            "            -1.2937e-01, -7.2974e-01],\n",
            "           [-5.9690e-02,  4.4782e-01, -1.0732e-01,  ...,  3.9504e-01,\n",
            "            -1.9803e-01,  2.3900e-01],\n",
            "           ...,\n",
            "           [-1.8780e-01, -6.4243e-01, -8.4095e-03,  ..., -6.0438e-01,\n",
            "            -7.7988e-02, -7.2841e-01],\n",
            "           [-6.3530e-02,  3.1521e-01, -1.1867e-01,  ...,  3.9792e-01,\n",
            "            -9.2473e-02,  3.6443e-01],\n",
            "           [-1.2528e-01, -9.0153e-01, -1.9594e-01,  ..., -8.9124e-01,\n",
            "            -2.0046e-01, -7.0914e-01]],\n",
            "\n",
            "          [[-2.7594e-01,  7.0473e-01, -3.1535e-01,  ...,  6.2114e-01,\n",
            "            -2.4179e-01,  4.8840e-01],\n",
            "           [ 4.9675e-01, -1.0890e+00,  6.9548e-01,  ..., -1.1478e+00,\n",
            "             6.6024e-01, -9.8449e-01],\n",
            "           [-2.1126e-01,  5.5056e-01, -4.4829e-01,  ...,  1.5899e-01,\n",
            "            -5.2998e-01,  2.7332e-01],\n",
            "           ...,\n",
            "           [ 4.9758e-01, -1.1492e+00,  9.1850e-01,  ..., -9.7319e-01,\n",
            "             7.1834e-01, -9.5330e-01],\n",
            "           [-2.3511e-01,  4.3628e-01, -4.6924e-01,  ...,  3.8175e-01,\n",
            "            -4.1746e-01,  2.8369e-01],\n",
            "           [ 6.8005e-01, -9.3199e-01,  6.1130e-01,  ..., -8.9826e-01,\n",
            "             6.1762e-01, -1.0433e+00]]],\n",
            "\n",
            "\n",
            "         [[[ 1.1361e-03, -1.1188e+00,  3.6618e-01,  ..., -9.8182e-01,\n",
            "             1.9040e-01, -9.0493e-01],\n",
            "           [-1.3693e-01,  3.6545e-02,  2.2355e-01,  ...,  1.0335e-01,\n",
            "             2.7129e-01,  6.3496e-02],\n",
            "           [ 4.0744e-01, -7.3837e-01,  6.7473e-02,  ..., -7.4790e-01,\n",
            "             3.4948e-03, -1.0613e+00],\n",
            "           ...,\n",
            "           [-1.5316e-01, -4.6328e-02,  1.8089e-01,  ..., -2.7529e-02,\n",
            "             1.6962e-01,  1.3042e-01],\n",
            "           [ 3.0549e-01, -6.7574e-01,  1.8329e-01,  ..., -6.0556e-01,\n",
            "             8.0541e-02, -1.1432e+00],\n",
            "           [ 3.1552e-01,  1.8371e-01,  7.5103e-02,  ...,  1.6238e-01,\n",
            "            -3.3306e-02,  1.0643e-01]],\n",
            "\n",
            "          [[ 2.9640e-01,  5.3741e-01, -3.6283e-01,  ...,  2.8745e-01,\n",
            "            -3.5044e-01,  5.3813e-01],\n",
            "           [ 4.6986e-01,  2.6585e-01,  6.2654e-01,  ...,  1.5300e-01,\n",
            "             6.2391e-01, -8.5913e-04],\n",
            "           [-4.6617e-02,  6.3976e-01, -2.8412e-01,  ...,  4.0899e-01,\n",
            "            -4.1046e-01,  4.6579e-01],\n",
            "           ...,\n",
            "           [ 5.2328e-01,  2.5893e-01,  5.8496e-01,  ...,  3.0182e-01,\n",
            "             5.9113e-01,  1.3713e-01],\n",
            "           [-6.1726e-02,  4.1606e-01, -4.0638e-01,  ...,  5.5034e-01,\n",
            "            -3.3820e-01,  4.9447e-01],\n",
            "           [ 3.6189e-01,  1.3835e-01,  5.2908e-01,  ...,  2.2054e-01,\n",
            "             4.0481e-01,  4.5730e-01]],\n",
            "\n",
            "          [[ 1.7752e-01, -1.0865e+00,  1.2049e-01,  ..., -8.5804e-01,\n",
            "            -7.6095e-02, -9.0048e-01],\n",
            "           [ 1.0345e-01,  1.3199e-01, -8.1546e-02,  ...,  9.6165e-02,\n",
            "             6.3064e-02,  1.3698e-01],\n",
            "           [ 1.4690e-01, -9.0957e-01, -2.7802e-01,  ..., -7.3139e-01,\n",
            "            -3.7672e-01, -8.8712e-01],\n",
            "           ...,\n",
            "           [ 2.4938e-01,  1.0107e-01, -7.0358e-02,  ...,  3.0995e-01,\n",
            "            -8.6985e-02,  1.0235e-01],\n",
            "           [ 5.9212e-02, -7.0390e-01, -2.2692e-01,  ..., -6.0045e-01,\n",
            "            -3.4130e-01, -6.7354e-01],\n",
            "           [ 1.2404e-02,  1.8743e-01,  1.3516e-01,  ...,  1.0760e-01,\n",
            "             2.0992e-01, -1.4100e-01]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 2.9920e-01,  4.7353e-01, -2.8162e-01,  ...,  4.2125e-01,\n",
            "            -2.2040e-01,  5.2809e-01],\n",
            "           [ 5.1586e-01,  3.2843e-01,  6.4454e-01,  ...,  1.8852e-01,\n",
            "             5.0648e-01,  4.9637e-02],\n",
            "           [ 1.7627e-01,  6.2070e-01, -2.2946e-01,  ...,  4.5276e-01,\n",
            "            -2.4151e-01,  2.8350e-01],\n",
            "           ...,\n",
            "           [ 3.4412e-01,  3.9264e-01,  5.3724e-01,  ...,  4.3840e-01,\n",
            "             4.7832e-01,  1.8118e-01],\n",
            "           [ 1.4718e-01,  3.9398e-01, -2.2588e-01,  ...,  4.5578e-01,\n",
            "            -3.1623e-01,  3.2547e-01],\n",
            "           [ 3.5708e-01,  1.2142e-01,  4.3127e-01,  ...,  1.6107e-01,\n",
            "             3.4600e-01,  2.3402e-01]],\n",
            "\n",
            "          [[ 3.1051e-01, -1.0214e+00,  6.9104e-02,  ..., -9.2635e-01,\n",
            "             1.2910e-02, -9.7373e-01],\n",
            "           [ 1.6882e-01,  1.8355e-01, -8.7512e-02,  ...,  1.7957e-01,\n",
            "             2.5284e-02,  1.0057e-01],\n",
            "           [ 1.8817e-01, -8.2408e-01, -2.6104e-01,  ..., -8.5861e-01,\n",
            "            -4.1822e-01, -9.4828e-01],\n",
            "           ...,\n",
            "           [ 1.4177e-01,  2.6177e-01, -6.5674e-02,  ...,  2.1984e-01,\n",
            "             1.5191e-02,  1.7109e-01],\n",
            "           [ 6.6631e-02, -7.4761e-01, -2.8500e-01,  ..., -7.3801e-01,\n",
            "            -4.7158e-01, -7.7265e-01],\n",
            "           [ 1.5549e-01,  1.4702e-01,  1.6770e-01,  ...,  1.4147e-01,\n",
            "             1.6178e-01, -1.7272e-01]],\n",
            "\n",
            "          [[ 1.6085e-01,  6.8400e-01,  9.3782e-02,  ...,  5.4149e-01,\n",
            "             1.5200e-01,  4.0327e-01],\n",
            "           [ 6.4964e-01,  2.7722e-01,  4.1354e-01,  ...,  1.5873e-01,\n",
            "             3.4760e-01,  3.2663e-01],\n",
            "           [ 2.8561e-01,  4.3993e-01,  3.4052e-01,  ...,  3.3802e-01,\n",
            "             1.8966e-01,  1.5638e-01],\n",
            "           ...,\n",
            "           [ 7.5720e-01,  2.7129e-01,  3.7620e-01,  ...,  3.3066e-01,\n",
            "             3.6498e-01,  3.3913e-01],\n",
            "           [ 1.6647e-01,  3.0465e-01,  2.4040e-01,  ...,  3.4206e-01,\n",
            "             6.4902e-02,  1.8084e-01],\n",
            "           [ 4.9909e-01,  1.7951e-01,  3.2015e-01,  ...,  1.4073e-01,\n",
            "             4.4542e-01,  1.0978e-01]]]]], grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probability.shape)\n",
        "print(probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NRhxzDM9Z8n",
        "outputId": "d915a1c5-0bfe-4618-b010-d5c846713db9"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n",
            "tensor([[[[[0.3418, 0.4801, 0.2617,  ..., 0.4282, 0.2996, 0.5291],\n",
            "           [0.2868, 0.3414, 0.2207,  ..., 0.3287, 0.2332, 0.3469],\n",
            "           [0.2786, 0.5644, 0.3153,  ..., 0.4754, 0.3426, 0.4657],\n",
            "           ...,\n",
            "           [0.2654, 0.3801, 0.2095,  ..., 0.3836, 0.2351, 0.3635],\n",
            "           [0.2907, 0.5267, 0.3187,  ..., 0.4719, 0.3546, 0.5120],\n",
            "           [0.3133, 0.3347, 0.3340,  ..., 0.3228, 0.3546, 0.4417]],\n",
            "\n",
            "          [[0.4481, 0.1254, 0.6304,  ..., 0.1580, 0.6123, 0.1194],\n",
            "           [0.3129, 0.5299, 0.2863,  ..., 0.5430, 0.2773, 0.5255],\n",
            "           [0.4896, 0.1196, 0.5835,  ..., 0.1695, 0.6004, 0.1242],\n",
            "           ...,\n",
            "           [0.2993, 0.4987, 0.2839,  ..., 0.5473, 0.3156, 0.5637],\n",
            "           [0.4678, 0.1573, 0.6047,  ..., 0.1428, 0.5577, 0.1305],\n",
            "           [0.2907, 0.4869, 0.3106,  ..., 0.5016, 0.3290, 0.5093]],\n",
            "\n",
            "          [[0.3001, 0.5381, 0.2739,  ..., 0.4983, 0.3043, 0.4293],\n",
            "           [0.2361, 0.3641, 0.3018,  ..., 0.3233, 0.2914, 0.3543],\n",
            "           [0.3160, 0.3930, 0.3262,  ..., 0.4020, 0.3943, 0.4628],\n",
            "           ...,\n",
            "           [0.2233, 0.3343, 0.2637,  ..., 0.2962, 0.3009, 0.3841],\n",
            "           [0.3001, 0.4102, 0.3604,  ..., 0.3860, 0.3816, 0.4615],\n",
            "           [0.3385, 0.3361, 0.3159,  ..., 0.2998, 0.3436, 0.3656]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.4321, 0.1312, 0.6147,  ..., 0.1374, 0.5946, 0.1235],\n",
            "           [0.3116, 0.5457, 0.3029,  ..., 0.5405, 0.3526, 0.6034],\n",
            "           [0.4243, 0.1386, 0.5538,  ..., 0.1362, 0.5674, 0.1234],\n",
            "           ...,\n",
            "           [0.3256, 0.5287, 0.3032,  ..., 0.5204, 0.3477, 0.5765],\n",
            "           [0.4647, 0.1605, 0.5439,  ..., 0.1482, 0.5930, 0.1310],\n",
            "           [0.3694, 0.5607, 0.3258,  ..., 0.5477, 0.3462, 0.5362]],\n",
            "\n",
            "          [[0.3005, 0.5209, 0.3187,  ..., 0.5722, 0.3067, 0.4028],\n",
            "           [0.2466, 0.3058, 0.2829,  ..., 0.3295, 0.3058, 0.3713],\n",
            "           [0.2984, 0.4269, 0.3416,  ..., 0.4568, 0.3977, 0.5282],\n",
            "           ...,\n",
            "           [0.2846, 0.2951, 0.2919,  ..., 0.2920, 0.3056, 0.3626],\n",
            "           [0.3046, 0.4353, 0.3633,  ..., 0.4198, 0.3868, 0.4615],\n",
            "           [0.3006, 0.3042, 0.3596,  ..., 0.3062, 0.3766, 0.3616]],\n",
            "\n",
            "          [[0.4725, 0.1142, 0.4306,  ..., 0.1213, 0.4142, 0.1807],\n",
            "           [0.2593, 0.4958, 0.3223,  ..., 0.5186, 0.3212, 0.4967],\n",
            "           [0.4655, 0.1459, 0.4065,  ..., 0.1571, 0.4205, 0.1924],\n",
            "           ...,\n",
            "           [0.2117, 0.5106, 0.2503,  ..., 0.5141, 0.3385, 0.5338],\n",
            "           [0.4933, 0.1783, 0.4012,  ..., 0.1700, 0.4386, 0.2089],\n",
            "           [0.3331, 0.5162, 0.3464,  ..., 0.5266, 0.3455, 0.5752]]],\n",
            "\n",
            "\n",
            "         [[[0.3205, 0.4258, 0.3114,  ..., 0.4596, 0.3312, 0.3450],\n",
            "           [0.4033, 0.2405, 0.3978,  ..., 0.2047, 0.3356, 0.2434],\n",
            "           [0.2179, 0.2967, 0.3604,  ..., 0.3801, 0.3659, 0.4348],\n",
            "           ...,\n",
            "           [0.4305, 0.2243, 0.4037,  ..., 0.2000, 0.3696, 0.2331],\n",
            "           [0.2405, 0.3125, 0.3370,  ..., 0.3524, 0.3218, 0.3912],\n",
            "           [0.3407, 0.1859, 0.3556,  ..., 0.1873, 0.3477, 0.1651]],\n",
            "\n",
            "          [[0.2005, 0.4012, 0.1548,  ..., 0.4044, 0.1773, 0.4878],\n",
            "           [0.3598, 0.1006, 0.3353,  ..., 0.1026, 0.3209, 0.1323],\n",
            "           [0.1704, 0.3964, 0.1651,  ..., 0.3809, 0.1755, 0.4546],\n",
            "           ...,\n",
            "           [0.3622, 0.1044, 0.3693,  ..., 0.0814, 0.3047, 0.1028],\n",
            "           [0.1896, 0.4238, 0.1550,  ..., 0.4035, 0.1773, 0.4467],\n",
            "           [0.3423, 0.1211, 0.3383,  ..., 0.1070, 0.3409, 0.0930]],\n",
            "\n",
            "          [[0.2946, 0.3568, 0.3363,  ..., 0.3761, 0.3392, 0.4500],\n",
            "           [0.3537, 0.2302, 0.3348,  ..., 0.2405, 0.3239, 0.1896],\n",
            "           [0.3059, 0.4985, 0.3730,  ..., 0.4744, 0.3620, 0.4200],\n",
            "           ...,\n",
            "           [0.3097, 0.2416, 0.3664,  ..., 0.1921, 0.3536, 0.1965],\n",
            "           [0.3599, 0.4508, 0.3563,  ..., 0.4659, 0.3606, 0.4016],\n",
            "           [0.3092, 0.1509, 0.3087,  ..., 0.1789, 0.2690, 0.2324]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.2045, 0.3983, 0.1502,  ..., 0.3912, 0.1592, 0.3994],\n",
            "           [0.3488, 0.0949, 0.3136,  ..., 0.1065, 0.3039, 0.1025],\n",
            "           [0.1774, 0.3596, 0.1546,  ..., 0.3724, 0.1627, 0.4418],\n",
            "           ...,\n",
            "           [0.3835, 0.0862, 0.3603,  ..., 0.0937, 0.3302, 0.1052],\n",
            "           [0.1757, 0.4458, 0.1719,  ..., 0.3802, 0.1687, 0.4418],\n",
            "           [0.3008, 0.0987, 0.3300,  ..., 0.1080, 0.3589, 0.1067]],\n",
            "\n",
            "          [[0.2689, 0.3641, 0.2826,  ..., 0.2993, 0.3057, 0.4860],\n",
            "           [0.3304, 0.2360, 0.3643,  ..., 0.2344, 0.3203, 0.1909],\n",
            "           [0.3075, 0.4476, 0.3545,  ..., 0.4226, 0.3342, 0.3615],\n",
            "           ...,\n",
            "           [0.2993, 0.2032, 0.3642,  ..., 0.2159, 0.3310, 0.1843],\n",
            "           [0.3251, 0.4197, 0.3448,  ..., 0.4392, 0.3640, 0.4077],\n",
            "           [0.3009, 0.1806, 0.2626,  ..., 0.1822, 0.2558, 0.2356]],\n",
            "\n",
            "          [[0.2070, 0.4475, 0.2273,  ..., 0.4568, 0.2360, 0.4271],\n",
            "           [0.3421, 0.1025, 0.3863,  ..., 0.1026, 0.3921, 0.1069],\n",
            "           [0.2022, 0.4507, 0.1854,  ..., 0.3838, 0.1898, 0.4274],\n",
            "           ...,\n",
            "           [0.3433, 0.0952, 0.4741,  ..., 0.1037, 0.3886, 0.1004],\n",
            "           [0.2032, 0.4378, 0.1974,  ..., 0.4232, 0.2143, 0.4159],\n",
            "           [0.3635, 0.1198, 0.3740,  ..., 0.1237, 0.3553, 0.1019]]],\n",
            "\n",
            "\n",
            "         [[[0.3377, 0.0942, 0.4269,  ..., 0.1122, 0.3691, 0.1259],\n",
            "           [0.3099, 0.4182, 0.3815,  ..., 0.4666, 0.4311, 0.4097],\n",
            "           [0.5036, 0.1388, 0.3243,  ..., 0.1445, 0.2915, 0.0994],\n",
            "           ...,\n",
            "           [0.3041, 0.3957, 0.3868,  ..., 0.4165, 0.3954, 0.4035],\n",
            "           [0.4688, 0.1607, 0.3442,  ..., 0.1757, 0.3235, 0.0967],\n",
            "           [0.3459, 0.4794, 0.3104,  ..., 0.4899, 0.2977, 0.3932]],\n",
            "\n",
            "          [[0.3514, 0.4734, 0.2148,  ..., 0.4377, 0.2105, 0.3928],\n",
            "           [0.3273, 0.3695, 0.3784,  ..., 0.3545, 0.4018, 0.3422],\n",
            "           [0.3400, 0.4840, 0.2514,  ..., 0.4496, 0.2242, 0.4212],\n",
            "           ...,\n",
            "           [0.3385, 0.3969, 0.3468,  ..., 0.3713, 0.3797, 0.3335],\n",
            "           [0.3426, 0.4189, 0.2403,  ..., 0.4537, 0.2650, 0.4228],\n",
            "           [0.3670, 0.3920, 0.3511,  ..., 0.3914, 0.3301, 0.3977]],\n",
            "\n",
            "          [[0.4053, 0.1051, 0.3898,  ..., 0.1256, 0.3564, 0.1208],\n",
            "           [0.4102, 0.4057, 0.3634,  ..., 0.4362, 0.3846, 0.4562],\n",
            "           [0.3781, 0.1085, 0.3008,  ..., 0.1235, 0.2437, 0.1171],\n",
            "           ...,\n",
            "           [0.4670, 0.4241, 0.3698,  ..., 0.5117, 0.3455, 0.4194],\n",
            "           [0.3401, 0.1390, 0.2833,  ..., 0.1480, 0.2578, 0.1369],\n",
            "           [0.3523, 0.5129, 0.3754,  ..., 0.5213, 0.3874, 0.4020]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3634, 0.4706, 0.2351,  ..., 0.4714, 0.2462, 0.4771],\n",
            "           [0.3397, 0.3594, 0.3834,  ..., 0.3530, 0.3435, 0.2941],\n",
            "           [0.3982, 0.5019, 0.2917,  ..., 0.4914, 0.2700, 0.4348],\n",
            "           ...,\n",
            "           [0.2908, 0.3851, 0.3365,  ..., 0.3859, 0.3221, 0.3183],\n",
            "           [0.3595, 0.3936, 0.2842,  ..., 0.4716, 0.2384, 0.4272],\n",
            "           [0.3298, 0.3405, 0.3442,  ..., 0.3443, 0.2949, 0.3571]],\n",
            "\n",
            "          [[0.4306, 0.1150, 0.3988,  ..., 0.1285, 0.3876, 0.1113],\n",
            "           [0.4230, 0.4583, 0.3527,  ..., 0.4362, 0.3739, 0.4379],\n",
            "           [0.3941, 0.1255, 0.3040,  ..., 0.1206, 0.2681, 0.1103],\n",
            "           ...,\n",
            "           [0.4161, 0.5018, 0.3439,  ..., 0.4922, 0.3633, 0.4531],\n",
            "           [0.3703, 0.1450, 0.2919,  ..., 0.1410, 0.2492, 0.1308],\n",
            "           [0.3985, 0.5153, 0.3778,  ..., 0.5116, 0.3675, 0.4028]],\n",
            "\n",
            "          [[0.3204, 0.4383, 0.3421,  ..., 0.4219, 0.3498, 0.3922],\n",
            "           [0.3986, 0.4017, 0.2914,  ..., 0.3788, 0.2868, 0.3965],\n",
            "           [0.3323, 0.4035, 0.4081,  ..., 0.4591, 0.3897, 0.3802],\n",
            "           ...,\n",
            "           [0.4450, 0.3942, 0.2756,  ..., 0.3821, 0.2729, 0.3658],\n",
            "           [0.3036, 0.3838, 0.4014,  ..., 0.4068, 0.3471, 0.3752],\n",
            "           [0.3034, 0.3640, 0.2796,  ..., 0.3497, 0.2991, 0.3229]]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ]
}