{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nnUnet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dNvh5XmGkoIS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Block1(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.lrelu = nn.LeakyReLU()\n",
        "    self.conv2 = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.instnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.instnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    return x\n",
        "\n",
        "class ConvBlockEncoder(nn.Module): # need to add nn.Module here\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    # self.conv = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=1)\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1) # before padding it was 64 x 63 x 63 x 63. by adding 1, you add one to each dimension needed\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.lrelu = nn.LeakyReLU()\n",
        "    self.conv2 = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.instnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.instnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    return x\n",
        "\n",
        "class ConvBlockDecoder(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.transconv = nn.ConvTranspose3d(in_channels=input_channels, out_channels=input_channels, kernel_size=2, stride=2)\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels+input_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.lrelu = nn.LeakyReLU()\n",
        "    self.conv2 = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "  def forward(self, x, concat_tensor):\n",
        "    x = self.transconv(x)\n",
        "    # print(\"after transpose: \" + str(x.shape))\n",
        "    x = torch.cat((x, concat_tensor), dim=0)\n",
        "    # print(\"after concat: \" + str(x.shape))\n",
        "    x = self.conv1(x)\n",
        "    # print(\"after conv1: \" + str(x.shape))\n",
        "    x = self.instnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.instnorm(x)\n",
        "    x = self.lrelu(x)\n",
        "    return x\n",
        "\n",
        "class nnUNet(nn.Module):\n",
        "  def __init__(self, input_shape):\n",
        "    super().__init__()\n",
        "    self.convblock1 = Block1(4, 32)\n",
        "    self.convblock2 = ConvBlockEncoder(32, 64)\n",
        "    self.convblock3 = ConvBlockEncoder(64, 128)\n",
        "    self.convblock4 = ConvBlockEncoder(128, 256)\n",
        "    self.convblock5 = ConvBlockEncoder(256, 320)\n",
        "    self.convblock6 = ConvBlockEncoder(320, 320)\n",
        "\n",
        "    self.convblock7 = ConvBlockDecoder(320, 256)\n",
        "    self.convblock8 = ConvBlockDecoder(256, 128)\n",
        "    self.convblock9 = ConvBlockDecoder(128, 64)\n",
        "    self.convblock10 = ConvBlockDecoder(64, 32)\n",
        "    self.convblock11 = ConvBlockDecoder(32, 16)\n",
        "    self.convblock11b = nn.Conv3d(in_channels=16, out_channels=3, kernel_size=1, stride=1) # output is 3 channels for WT, ET, TC\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, x, ):\n",
        "    print(x.shape) # [4, 128, 128, 128]\n",
        "\n",
        "    # ENCODER\n",
        "    x1 = self.convblock1(x)\n",
        "    print(x1.shape) # [32, 128, 128, 128]\n",
        "\n",
        "    x2 = self.convblock2(x1)\n",
        "    print(x2.shape) # [64, 64, 64, 64]\n",
        "\n",
        "    x3 = self.convblock3(x2)\n",
        "    print(x3.shape) # [128, 32, 32, 32]\n",
        "\n",
        "    x4 = self.convblock4(x3)\n",
        "    print(x4.shape) # [256, 16, 16, 16]\n",
        "\n",
        "    x5 = self.convblock5(x4)\n",
        "    print(x5.shape) # [320, 8, 8, 8]\n",
        "\n",
        "    x6 = self.convblock6(x5)\n",
        "    print(x6.shape) # [320, 4, 4, 4]\n",
        "\n",
        "    x7 = self.convblock7(x6, x5)\n",
        "    print(x7.shape) # [256, 8, 8, 8]\n",
        "\n",
        "    x8 = self.convblock8(x7, x4)\n",
        "    print(x8.shape) # [128, 16, 16, 16]\n",
        "\n",
        "    x9 = self.convblock9(x8, x3)\n",
        "    print(x9.shape) # [64, 32, 32, 32]\n",
        "\n",
        "    x10 = self.convblock10(x9, x2)\n",
        "    print(x10.shape) # [32, 64, 64, 64]\n",
        "\n",
        "    x11 = self.convblock11(x10, x1)\n",
        "    print(x11.shape) # [16, 128, 128, 128]\n",
        "\n",
        "    x12 = self.convblock11b(x11)\n",
        "    print(x12.shape) # [3, 128, 128, 128]\n",
        "\n",
        "    x13 = self.softmax(x12)\n",
        "    print(x13.shape) # [3, 128, 128, 128] - i thought that the shape would change when using softmax, but only the values change to add up to 1\n",
        "\n",
        "    return x13"
      ],
      "metadata": {
        "id": "6H5SBQZPkvqm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "when dim = 1\n",
        ">>> torch.cat((x, x, x), 1)\n",
        "tensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n",
        "         -1.0969, -0.4614],\n",
        "        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n",
        "         -0.5790,  0.1497]])\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OFZFoUZJGLeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(4, 128, 128, 128), dtype=torch.float32)\n",
        "# print(x.shape)\n",
        "\n",
        "model = nnUNet(x.shape)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tleGdND9076M",
        "outputId": "d0d032f0-e421-4c8d-c9d2-68cad52c6ef1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nnUNet(\n",
            "  (convblock1): Block1(\n",
            "    (conv1): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock2): ConvBlockEncoder(\n",
            "    (conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock3): ConvBlockEncoder(\n",
            "    (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock4): ConvBlockEncoder(\n",
            "    (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock5): ConvBlockEncoder(\n",
            "    (conv1): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock6): ConvBlockEncoder(\n",
            "    (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock7): ConvBlockDecoder(\n",
            "    (transconv): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv1): Conv3d(640, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock8): ConvBlockDecoder(\n",
            "    (transconv): ConvTranspose3d(256, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv1): Conv3d(512, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock9): ConvBlockDecoder(\n",
            "    (transconv): ConvTranspose3d(128, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv1): Conv3d(256, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock10): ConvBlockDecoder(\n",
            "    (transconv): ConvTranspose3d(64, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv1): Conv3d(128, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock11): ConvBlockDecoder(\n",
            "    (transconv): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv1): Conv3d(64, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (lrelu): LeakyReLU(negative_slope=0.01)\n",
            "    (conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (convblock11b): Conv3d(16, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "torch.Size([4, 128, 128, 128])\n",
            "torch.Size([32, 128, 128, 128])\n",
            "torch.Size([64, 64, 64, 64])\n",
            "torch.Size([128, 32, 32, 32])\n",
            "torch.Size([256, 16, 16, 16])\n",
            "torch.Size([320, 8, 8, 8])\n",
            "torch.Size([320, 4, 4, 4])\n",
            "torch.Size([256, 8, 8, 8])\n",
            "torch.Size([128, 16, 16, 16])\n",
            "torch.Size([64, 32, 32, 32])\n",
            "torch.Size([32, 64, 64, 64])\n",
            "torch.Size([16, 128, 128, 128])\n",
            "torch.Size([3, 128, 128, 128])\n",
            "torch.Size([3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out.shape)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXdpgptyfJ48",
        "outputId": "06f8757f-a0de-45da-b7b8-8432ebce9428"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 128, 128, 128])\n",
            "tensor([[[[0.0114, 0.0073, 0.0071,  ..., 0.0091, 0.0054, 0.0066],\n",
            "          [0.0065, 0.0085, 0.0094,  ..., 0.0079, 0.0119, 0.0092],\n",
            "          [0.0077, 0.0083, 0.0112,  ..., 0.0074, 0.0071, 0.0087],\n",
            "          ...,\n",
            "          [0.0069, 0.0101, 0.0121,  ..., 0.0088, 0.0091, 0.0083],\n",
            "          [0.0067, 0.0073, 0.0085,  ..., 0.0074, 0.0087, 0.0081],\n",
            "          [0.0089, 0.0079, 0.0110,  ..., 0.0071, 0.0064, 0.0054]],\n",
            "\n",
            "         [[0.0081, 0.0089, 0.0038,  ..., 0.0062, 0.0048, 0.0063],\n",
            "          [0.0089, 0.0060, 0.0062,  ..., 0.0042, 0.0058, 0.0075],\n",
            "          [0.0074, 0.0042, 0.0054,  ..., 0.0055, 0.0050, 0.0082],\n",
            "          ...,\n",
            "          [0.0079, 0.0058, 0.0054,  ..., 0.0153, 0.0074, 0.0101],\n",
            "          [0.0053, 0.0071, 0.0053,  ..., 0.0074, 0.0062, 0.0078],\n",
            "          [0.0109, 0.0070, 0.0090,  ..., 0.0098, 0.0104, 0.0074]],\n",
            "\n",
            "         [[0.0119, 0.0068, 0.0087,  ..., 0.0061, 0.0090, 0.0081],\n",
            "          [0.0084, 0.0068, 0.0065,  ..., 0.0096, 0.0095, 0.0075],\n",
            "          [0.0081, 0.0109, 0.0066,  ..., 0.0126, 0.0099, 0.0097],\n",
            "          ...,\n",
            "          [0.0088, 0.0049, 0.0036,  ..., 0.0100, 0.0125, 0.0076],\n",
            "          [0.0071, 0.0117, 0.0083,  ..., 0.0067, 0.0097, 0.0042],\n",
            "          [0.0095, 0.0086, 0.0068,  ..., 0.0075, 0.0077, 0.0076]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0059, 0.0074, 0.0081,  ..., 0.0068, 0.0103, 0.0101],\n",
            "          [0.0062, 0.0068, 0.0099,  ..., 0.0082, 0.0090, 0.0085],\n",
            "          [0.0079, 0.0047, 0.0106,  ..., 0.0094, 0.0069, 0.0064],\n",
            "          ...,\n",
            "          [0.0060, 0.0055, 0.0062,  ..., 0.0091, 0.0096, 0.0073],\n",
            "          [0.0069, 0.0060, 0.0069,  ..., 0.0105, 0.0109, 0.0090],\n",
            "          [0.0072, 0.0070, 0.0058,  ..., 0.0115, 0.0081, 0.0060]],\n",
            "\n",
            "         [[0.0068, 0.0067, 0.0074,  ..., 0.0076, 0.0058, 0.0094],\n",
            "          [0.0055, 0.0079, 0.0106,  ..., 0.0062, 0.0089, 0.0077],\n",
            "          [0.0080, 0.0112, 0.0056,  ..., 0.0080, 0.0060, 0.0070],\n",
            "          ...,\n",
            "          [0.0063, 0.0108, 0.0066,  ..., 0.0078, 0.0074, 0.0063],\n",
            "          [0.0074, 0.0090, 0.0057,  ..., 0.0084, 0.0071, 0.0060],\n",
            "          [0.0078, 0.0059, 0.0074,  ..., 0.0087, 0.0075, 0.0087]],\n",
            "\n",
            "         [[0.0088, 0.0078, 0.0109,  ..., 0.0087, 0.0082, 0.0074],\n",
            "          [0.0067, 0.0069, 0.0081,  ..., 0.0052, 0.0059, 0.0091],\n",
            "          [0.0080, 0.0107, 0.0060,  ..., 0.0074, 0.0079, 0.0082],\n",
            "          ...,\n",
            "          [0.0064, 0.0071, 0.0098,  ..., 0.0066, 0.0068, 0.0083],\n",
            "          [0.0073, 0.0069, 0.0085,  ..., 0.0059, 0.0047, 0.0080],\n",
            "          [0.0061, 0.0077, 0.0078,  ..., 0.0051, 0.0040, 0.0070]]],\n",
            "\n",
            "\n",
            "        [[[0.0063, 0.0064, 0.0069,  ..., 0.0073, 0.0054, 0.0079],\n",
            "          [0.0101, 0.0079, 0.0069,  ..., 0.0069, 0.0073, 0.0072],\n",
            "          [0.0062, 0.0077, 0.0049,  ..., 0.0054, 0.0050, 0.0063],\n",
            "          ...,\n",
            "          [0.0073, 0.0075, 0.0052,  ..., 0.0082, 0.0082, 0.0051],\n",
            "          [0.0078, 0.0059, 0.0045,  ..., 0.0064, 0.0057, 0.0040],\n",
            "          [0.0055, 0.0058, 0.0057,  ..., 0.0058, 0.0048, 0.0053]],\n",
            "\n",
            "         [[0.0056, 0.0037, 0.0042,  ..., 0.0079, 0.0117, 0.0079],\n",
            "          [0.0079, 0.0057, 0.0068,  ..., 0.0056, 0.0079, 0.0066],\n",
            "          [0.0132, 0.0049, 0.0108,  ..., 0.0073, 0.0041, 0.0040],\n",
            "          ...,\n",
            "          [0.0066, 0.0059, 0.0085,  ..., 0.0039, 0.0054, 0.0050],\n",
            "          [0.0060, 0.0066, 0.0069,  ..., 0.0043, 0.0082, 0.0036],\n",
            "          [0.0082, 0.0089, 0.0067,  ..., 0.0064, 0.0062, 0.0079]],\n",
            "\n",
            "         [[0.0095, 0.0068, 0.0096,  ..., 0.0031, 0.0056, 0.0066],\n",
            "          [0.0060, 0.0065, 0.0149,  ..., 0.0108, 0.0057, 0.0067],\n",
            "          [0.0106, 0.0046, 0.0103,  ..., 0.0089, 0.0075, 0.0058],\n",
            "          ...,\n",
            "          [0.0115, 0.0067, 0.0060,  ..., 0.0103, 0.0056, 0.0070],\n",
            "          [0.0063, 0.0064, 0.0088,  ..., 0.0076, 0.0064, 0.0061],\n",
            "          [0.0074, 0.0062, 0.0084,  ..., 0.0091, 0.0063, 0.0111]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0083, 0.0091, 0.0055,  ..., 0.0085, 0.0062, 0.0052],\n",
            "          [0.0062, 0.0036, 0.0075,  ..., 0.0062, 0.0146, 0.0049],\n",
            "          [0.0064, 0.0075, 0.0029,  ..., 0.0079, 0.0084, 0.0125],\n",
            "          ...,\n",
            "          [0.0049, 0.0082, 0.0098,  ..., 0.0087, 0.0093, 0.0069],\n",
            "          [0.0069, 0.0091, 0.0093,  ..., 0.0095, 0.0095, 0.0058],\n",
            "          [0.0085, 0.0092, 0.0098,  ..., 0.0072, 0.0086, 0.0100]],\n",
            "\n",
            "         [[0.0048, 0.0066, 0.0077,  ..., 0.0090, 0.0055, 0.0078],\n",
            "          [0.0064, 0.0089, 0.0066,  ..., 0.0102, 0.0109, 0.0090],\n",
            "          [0.0086, 0.0071, 0.0075,  ..., 0.0057, 0.0103, 0.0051],\n",
            "          ...,\n",
            "          [0.0115, 0.0080, 0.0112,  ..., 0.0068, 0.0081, 0.0102],\n",
            "          [0.0068, 0.0116, 0.0060,  ..., 0.0103, 0.0069, 0.0076],\n",
            "          [0.0057, 0.0072, 0.0065,  ..., 0.0061, 0.0050, 0.0064]],\n",
            "\n",
            "         [[0.0077, 0.0076, 0.0065,  ..., 0.0054, 0.0122, 0.0082],\n",
            "          [0.0050, 0.0088, 0.0102,  ..., 0.0113, 0.0074, 0.0076],\n",
            "          [0.0066, 0.0058, 0.0090,  ..., 0.0068, 0.0054, 0.0081],\n",
            "          ...,\n",
            "          [0.0092, 0.0089, 0.0082,  ..., 0.0103, 0.0070, 0.0053],\n",
            "          [0.0073, 0.0118, 0.0077,  ..., 0.0112, 0.0080, 0.0068],\n",
            "          [0.0068, 0.0044, 0.0044,  ..., 0.0063, 0.0073, 0.0077]]],\n",
            "\n",
            "\n",
            "        [[[0.0087, 0.0088, 0.0095,  ..., 0.0066, 0.0119, 0.0073],\n",
            "          [0.0105, 0.0059, 0.0096,  ..., 0.0101, 0.0065, 0.0080],\n",
            "          [0.0131, 0.0106, 0.0097,  ..., 0.0073, 0.0064, 0.0077],\n",
            "          ...,\n",
            "          [0.0136, 0.0054, 0.0143,  ..., 0.0063, 0.0072, 0.0112],\n",
            "          [0.0104, 0.0097, 0.0094,  ..., 0.0062, 0.0079, 0.0090],\n",
            "          [0.0094, 0.0077, 0.0067,  ..., 0.0078, 0.0110, 0.0110]],\n",
            "\n",
            "         [[0.0074, 0.0075, 0.0039,  ..., 0.0075, 0.0082, 0.0066],\n",
            "          [0.0059, 0.0129, 0.0048,  ..., 0.0080, 0.0120, 0.0080],\n",
            "          [0.0034, 0.0071, 0.0080,  ..., 0.0044, 0.0078, 0.0056],\n",
            "          ...,\n",
            "          [0.0053, 0.0059, 0.0124,  ..., 0.0042, 0.0087, 0.0071],\n",
            "          [0.0087, 0.0075, 0.0058,  ..., 0.0091, 0.0071, 0.0060],\n",
            "          [0.0042, 0.0060, 0.0051,  ..., 0.0065, 0.0048, 0.0083]],\n",
            "\n",
            "         [[0.0065, 0.0076, 0.0088,  ..., 0.0077, 0.0105, 0.0105],\n",
            "          [0.0079, 0.0069, 0.0056,  ..., 0.0094, 0.0060, 0.0068],\n",
            "          [0.0079, 0.0077, 0.0088,  ..., 0.0091, 0.0075, 0.0077],\n",
            "          ...,\n",
            "          [0.0124, 0.0106, 0.0089,  ..., 0.0055, 0.0062, 0.0108],\n",
            "          [0.0075, 0.0082, 0.0062,  ..., 0.0099, 0.0046, 0.0053],\n",
            "          [0.0089, 0.0076, 0.0105,  ..., 0.0063, 0.0111, 0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[0.0063, 0.0091, 0.0118,  ..., 0.0070, 0.0071, 0.0094],\n",
            "          [0.0084, 0.0138, 0.0106,  ..., 0.0130, 0.0110, 0.0060],\n",
            "          [0.0067, 0.0091, 0.0063,  ..., 0.0113, 0.0065, 0.0086],\n",
            "          ...,\n",
            "          [0.0100, 0.0148, 0.0129,  ..., 0.0075, 0.0082, 0.0064],\n",
            "          [0.0099, 0.0087, 0.0078,  ..., 0.0050, 0.0033, 0.0076],\n",
            "          [0.0090, 0.0068, 0.0048,  ..., 0.0041, 0.0053, 0.0050]],\n",
            "\n",
            "         [[0.0093, 0.0080, 0.0093,  ..., 0.0066, 0.0084, 0.0076],\n",
            "          [0.0117, 0.0058, 0.0056,  ..., 0.0060, 0.0063, 0.0058],\n",
            "          [0.0113, 0.0099, 0.0089,  ..., 0.0109, 0.0094, 0.0056],\n",
            "          ...,\n",
            "          [0.0044, 0.0081, 0.0056,  ..., 0.0045, 0.0126, 0.0095],\n",
            "          [0.0069, 0.0082, 0.0050,  ..., 0.0051, 0.0066, 0.0063],\n",
            "          [0.0079, 0.0059, 0.0168,  ..., 0.0079, 0.0065, 0.0066]],\n",
            "\n",
            "         [[0.0088, 0.0112, 0.0097,  ..., 0.0059, 0.0072, 0.0072],\n",
            "          [0.0132, 0.0075, 0.0082,  ..., 0.0083, 0.0127, 0.0061],\n",
            "          [0.0119, 0.0090, 0.0109,  ..., 0.0099, 0.0091, 0.0056],\n",
            "          ...,\n",
            "          [0.0088, 0.0130, 0.0130,  ..., 0.0095, 0.0082, 0.0053],\n",
            "          [0.0094, 0.0066, 0.0098,  ..., 0.0080, 0.0110, 0.0112],\n",
            "          [0.0095, 0.0128, 0.0144,  ..., 0.0139, 0.0206, 0.0114]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ]
}