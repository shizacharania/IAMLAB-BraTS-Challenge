{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OXG09_X81jA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Block(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    # my assumption was that if you wanted a convolution with 3x3x1, you couldn't have it be 3d and specify the kernel size like that\n",
        "    # however, looking at the code implementation, you can do that\n",
        "    self.one_one_one1 = nn.Conv3d(channels, channels, kernel_size=1, stride=1)\n",
        "    self.three_three_one = nn.Conv3d(8, 8, kernel_size=(3,3,1), padding=(1,1,0))\n",
        "    self.one_three_three = nn.Conv3d(channels, channels, kernel_size=(1,3,3), padding=(0,1,1))\n",
        "  def forward(self, x):\n",
        "    x1 = self.one_one_one1(x)\n",
        "    print(x1.shape)\n",
        "\n",
        "    # [2, 32, 64, 64, 64]\n",
        "\n",
        "    print(\"channel groups\")\n",
        "    channel_group1 = x1[:, 0:8, :, :, :] # one modality\n",
        "    print(channel_group1.shape)\n",
        "\n",
        "    channel_group2 = x1[:, 8:16, :, :, :]\n",
        "    print(channel_group2.shape)\n",
        "\n",
        "    channel_group3 = x1[:, 16:24, :, :, :]\n",
        "    print(channel_group3.shape)\n",
        "\n",
        "    channel_group4 = x1[:, 24:32, :, :, :]\n",
        "    print(channel_group4.shape)\n",
        "\n",
        "    x2 = self.three_three_one(channel_group2)\n",
        "    print(x2.shape)\n",
        "    x3 = self.three_three_one(channel_group3+x2)\n",
        "    print(x3.shape)\n",
        "    x4 = self.three_three_one(channel_group4+x3)\n",
        "    print(x4.shape)\n",
        "\n",
        "    end = torch.cat([channel_group1, x2, x3, x4], dim=1)\n",
        "    print(end.shape)\n",
        "\n",
        "    x5 = self.one_one_one1(end)\n",
        "    print(x5.shape)\n",
        "\n",
        "    out = self.one_three_three(x5)\n",
        "    print(out.shape)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5EfLQVgJ7r5n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 32, 64, 64, 64), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Block(32)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCTjnTjRKHJN",
        "outputId": "7d910591-06aa-4355-c375-351dae771c55"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 32, 64, 64, 64])\n",
            "HDC_Block(\n",
            "  (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "  (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Net(nn.Module):\n",
        "  def __init__(self, x):\n",
        "    super().__init__()\n",
        "    # self.pds = torch.nn.functional.interpolate(x)\n",
        "    self.conv1 = nn.Conv3d(in_channels=4, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
        "    self.downsample = nn.Conv3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.HDC = HDC_Block(32)\n",
        "    self.upsample = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.upinterpolate = nn.Upsample(scale_factor=2, mode='trilinear')\n",
        "    self.conv2 = nn.Conv3d(in_channels=32, out_channels=3, kernel_size=1, stride=1)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    nimages, channels, width, height, depth = x.shape\n",
        "    print(nimages, channels, width, height, depth)\n",
        "    print(x.type)\n",
        "    # x1 = torch.tensor(scipy.ndimage.zoom(x, [1, 8.0, 0.5, 0.5, 0.5])) # using this function took about 2 minutes and for many images, it's not reasonable\n",
        "    x1 = torch.nn.functional.interpolate(x, scale_factor=[0.5, 0.5, 0.5]) # PDS - interpolate only looks at dim 2,3,4... (doesn't regard for channel and number of images)\n",
        "    # instead, I used torch.nn.functional.interpolate to interpolate the spatial dimensions, but for the channels I used a 1x1x1 conv\n",
        "    # because they did want to avoid using 3x3x3 conv and it will work same\n",
        "    print(x1.shape)\n",
        "    x1 = self.conv1(x1)\n",
        "    print(x1.shape)\n",
        "\n",
        "    x2 = self.HDC(x1)\n",
        "    print(x2.shape)\n",
        "    print()\n",
        "    x3 = self.downsample(x2)\n",
        "    print(x3.shape)\n",
        "\n",
        "    x4 = self.HDC(x3)\n",
        "    print(x4.shape)\n",
        "    print()\n",
        "    x5 = self.downsample(x4)\n",
        "    print(x5.shape)\n",
        "\n",
        "    x6 = self.HDC(x5)\n",
        "    print(x6.shape)\n",
        "    print()\n",
        "    x7 = self.downsample(x6)\n",
        "    print(x7.shape)\n",
        "\n",
        "    x8 = self.HDC(x7)\n",
        "    print(x8.shape)\n",
        "    print()\n",
        "\n",
        "    print(\"decoder time\")\n",
        "\n",
        "    x9 = self.upsample(x8)\n",
        "    print(x9.shape)\n",
        "    x10 = torch.add(x9, x6)\n",
        "    print(x10.shape)\n",
        "    x11 = self.HDC(x10)\n",
        "    print(x11.shape)\n",
        "\n",
        "    x12 = self.upsample(x11)\n",
        "    print(x12.shape)\n",
        "    x13 = torch.add(x12, x4)\n",
        "    print(x13.shape)\n",
        "    x14 = self.HDC(x13)\n",
        "    print(x14.shape)\n",
        "\n",
        "    x15 = self.upsample(x14)\n",
        "    print(x15.shape)\n",
        "    x16 = torch.add(x15, x2)\n",
        "    print(x16.shape)\n",
        "    x17 = self.HDC(x16)\n",
        "    print(x17.shape)\n",
        "\n",
        "    print(\"\\nupsampling\\n\") # by this they meant interpolation\n",
        "\n",
        "    x18 = self.upinterpolate(x17)\n",
        "    print(x18.shape)\n",
        "\n",
        "    x19 = self.conv2(x18)\n",
        "    print(x19.shape)\n",
        "\n",
        "    out = self.softmax(x19)\n",
        "    print(out.shape)\n",
        "\n",
        "    return x19, out"
      ],
      "metadata": {
        "id": "FnUEVd9i3bS8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 4, 128, 128, 128), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Net(x)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "# out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bf1ybX73Wjd",
        "outputId": "ea431b17-ee27-4522-e944-5596c3396d84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 128, 128, 128])\n",
            "HDC_Net(\n",
            "  (conv1): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (downsample): Conv3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (HDC): HDC_Block(\n",
            "    (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "    (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            "  )\n",
            "  (upsample): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (upinterpolate): Upsample(scale_factor=2.0, mode=trilinear)\n",
            "  (conv2): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# output, probability = out"
      ],
      "metadata": {
        "id": "Z4lqjhQl9QRF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(output.shape)\n",
        "# print(output)"
      ],
      "metadata": {
        "id": "dX3XHUnj9SiF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(probability.shape)\n",
        "# print(probability)"
      ],
      "metadata": {
        "id": "3NRhxzDM9Z8n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KYmHvHW0gvIB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_images = []\n",
        "for i in range(2):\n",
        "  newx = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_images.append(newx)"
      ],
      "metadata": {
        "id": "lRm-uxBpgzku"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_images))\n",
        "print(randomized_training_images[0].shape)\n",
        "# print(randomized_training_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOFYVukkg0wi",
        "outputId": "27c589d3-abbf-4ffb-8ed6-d43d46fbb0de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "lLHd0_Jlg2D8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_segmentations))\n",
        "print(randomized_training_segmentations[0].shape)\n",
        "# print(randomized_training_segmentations[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Lpq1Yeg3ta",
        "outputId": "8a84477e-c41a-404b-9a1d-c19720cf5b86"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_data = list(zip(randomized_training_images, randomized_training_segmentations))"
      ],
      "metadata": {
        "id": "nO6zxE6rg48U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset=randomized_training_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "tm7kwmsHg6F4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVib00lgg7UU",
        "outputId": "bee9bf5d-0391-4174-f851-ac2e9623945f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_images.append(newy)"
      ],
      "metadata": {
        "id": "0OhQ4jPeg9NF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_images))\n",
        "print(randomized_validation_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQD263Dg_F-",
        "outputId": "4377f450-1307-4754-a8ac-a9af2600300e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "gRq6qPWAhBSd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_segmentations))\n",
        "print(randomized_validation_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsV3ZlvFhCrk",
        "outputId": "dd92cb79-f9cb-4069-c980-5f2177e1fc91"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_data = list(zip(randomized_validation_images, randomized_validation_segmentations))"
      ],
      "metadata": {
        "id": "2jXVLmIvhDxh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationloader = torch.utils.data.DataLoader(dataset=randomized_validation_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "-PjukyAkhFP3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validationloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPI6wgumhGZA",
        "outputId": "d8453616-b3b2-4b94-ea9f-24004357b4d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_images.append(newy)"
      ],
      "metadata": {
        "id": "ggGc5XCNhHu4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_images))\n",
        "print(randomized_testing_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcPrDJhhJHS",
        "outputId": "d0b2f027-e23a-4de4-a838-43502232b5b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "YKFnOHG0hKsv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_segmentations))\n",
        "print(randomized_testing_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wkfD4POhMQU",
        "outputId": "aa695617-e9eb-43bd-ce3b-335d9e125ba6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_data = list(zip(randomized_testing_images, randomized_testing_segmentations))"
      ],
      "metadata": {
        "id": "qnIpezVFhNt8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testingloader = torch.utils.data.DataLoader(dataset=randomized_testing_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "zvIhDCEchQii"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training + Validation:\n",
        "multi-class soft Dice function as the loss function\n",
        "\n",
        "Testing:\n",
        "mean accuracy\n",
        "dice coefficient\n",
        "hausdorff implementation\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "njyI0anWCXzA",
        "outputId": "b95a5f4c-76f4-4371-83af-d6e253942d24"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTraining + Validation:\\nmulti-class soft Dice function as the loss function\\n\\nTesting:\\nmean accuracy\\ndice coefficient\\nhausdorff implementation\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chose to make this a class because when you call dice loss in criterion, you don't have anything to input, but when u run the prediction through inside the training, then you have params\n",
        "# also because most sources I saw used a class\n",
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.smooth = 1\n",
        "  def forward(self, true, pred):\n",
        "    # flatten to easily do it pixel by pixel\n",
        "    true = true.view(-1)\n",
        "    pred = pred.view(-1)\n",
        "    numerator = 2*(true*pred).sum()\n",
        "    denominator = true.sum() + pred.sum()\n",
        "    dice_loss = 1 - (numerator + self.smooth) / (denominator + self.smooth)\n",
        "    return dice_loss"
      ],
      "metadata": {
        "id": "j1mhy3eKdCM9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim"
      ],
      "metadata": {
        "id": "kvtMJWXLgeJl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs\n",
        "epochs = 2 # should be 800\n",
        "# loss\n",
        "criterion = DiceLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=10**-3, weight_decay=10**-5)"
      ],
      "metadata": {
        "id": "2__9J37GgnAq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime"
      ],
      "metadata": {
        "id": "ZLqeEDDUl1L1"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  start_epoch = datetime.datetime.now()\n",
        "  training_loss = 0\n",
        "  validation_loss = 0\n",
        "  print(\"training time\")\n",
        "  for images, segs in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "\n",
        "    # arg_outputs = outputs.argmax(dim=1)\n",
        "    # print(arg_outputs.shape)\n",
        "    # print(arg_outputs)\n",
        "    # print(segs.shape)\n",
        "    print()\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    \n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    training_loss += loss.item()\n",
        "    print()\n",
        "  print(\"validation time\")\n",
        "  for images, segs in validationloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    validation_loss += loss.item()\n",
        "  training_losses.append(training_loss/len(trainloader))\n",
        "  validation_losses.append(validation_loss/len(validationloader))\n",
        "  print(\"Epoch: {}/{}... Training Loss: {}... Validation Loss: {}...\".format(i+1,epochs, training_losses[-1], validation_losses[-1]))\n",
        "  if validation_loss < min(validation_losses):\n",
        "    print(\"Validation loss has decreased...saving model\")\n",
        "    torch.save(model.state_dict(), \"fcn.pth\")\n",
        "  end_epoch = datetime.datetime.now()\n",
        "  time_epoch = end_epoch-start_epoch\n",
        "  print(\"Epoch time:\", str(time_epoch), \"\\n\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F02PVic5gpXT",
        "outputId": "2e613bf5-f150-4b2c-da5d-5d6888e91564"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fc45f6e30b0>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fc45f695350>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor(0.6001, grad_fn=<RsubBackward1>)\n",
            "Epoch: 1/2... Training Loss: 0.5999929904937744... Validation Loss: 0.600071907043457...\n",
            "Epoch time: 0:00:05.250780 \n",
            "\n",
            "\n",
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fc45f6957d0>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fc45f6e3590>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor(0.6001, grad_fn=<RsubBackward1>)\n",
            "Epoch: 2/2... Training Loss: 0.5999929904937744... Validation Loss: 0.600071907043457...\n",
            "Epoch time: 0:00:04.335367 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_losses)\n",
        "print(validation_losses)"
      ],
      "metadata": {
        "id": "g0I2BsZrNHcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6a7f61-7c7a-4904-d87b-2d468f685dec"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.5999929904937744, 0.5999929904937744]\n",
            "[0.600071907043457, 0.600071907043457]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "N0NootnrlxW7"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize losses\n",
        "plt.plot(training_losses, label=\"Training loss\")\n",
        "plt.plot(validation_losses, label=\"Validation loss\")\n",
        "plt.legend(frameon=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "lTegyA5-lw3J",
        "outputId": "6f3d3f1f-cf3b-42b3-b144-99052f3e74c7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fc3c8c0b110>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(outputs, segmentations): # they find individual\n",
        "  # outputs = torch.Size([2, 3, 128, 128, 128])\n",
        "  # segmentations = torch.Size([2, 3, 128, 128, 128])\n",
        "  # print(outputs.shape)\n",
        "  # print(segmentations.shape)\n",
        "  n_classes = segmentations.shape[1]\n",
        "  region_dice_scores = []\n",
        "  for i in range(n_classes):\n",
        "    outputs = outputs.view(-1)\n",
        "    segmentations = segmentations.view(-1)\n",
        "    numerator = 2*(outputs*segmentations).sum()\n",
        "    denominator = outputs.sum() + segmentations.sum()\n",
        "    dice = (numerator) / (denominator)\n",
        "    region_dice_scores.append(dice)\n",
        "  return region_dice_scores"
      ],
      "metadata": {
        "id": "c8DSrR2MXfHC"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def hausdorff95(outputs, segmentations):\n",
        "#   from scipy.spatial.distance import directed_hausdorff\n",
        "#   # make outputs and segmentations arrays\n",
        "#   outputs = outputs.numpy()\n",
        "#   segmentations = segmentations.numpy()\n",
        "#   hd95 = directed_hausdorff(outputs, outputs)\n",
        "#   print(len(hd95))\n",
        "#   print(hd95)\n",
        "#   return hd95"
      ],
      "metadata": {
        "id": "NNRMOty_IvtZ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1 NECROTIC TUMOUR CORE (NCR  label 1) - index 0\n",
        "\n",
        "2 GD-ENHANCING TUMOUR (ET  label 2) - index 1\n",
        "\n",
        "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED  label 3) - index 2\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "liYRO6MtW-H4",
        "outputId": "01a04fa5-a4d5-4613-bff2-601c2dcbd379"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1 NECROTIC TUMOUR CORE (NCR  label 1) - index 0\\n\\n2 GD-ENHANCING TUMOUR (ET  label 2) - index 1\\n\\n3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED  label 3) - index 2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from scipy.spatial._hausdorff import directed_hausdorff\n",
        "\n",
        "# def hausdorff_distance(point_set_a, point_set_b):\n",
        "#     difference = point_set_a-point_set_b\n",
        "#     # Calculate the square distances between each two points: |ai - bj|^2.\n",
        "#     square_distances = torch.einsum(\"...i,...i->...\", difference, difference)\n",
        "#     minimum_square_distance_a_to_b = torch.math.reduce_min(square_distances, axis=-1)\n",
        "#     return torch.math.sqrt(torch.math.reduce_max(minimum_square_distance_a_to_b, axis=-1))\n",
        "\n",
        "# # def HausdorffDist(A,B):\n",
        "# #     # Find pairwise distance\n",
        "# #     D_mat = np.sqrt(inner1d(A,A)[np.newaxis].T + inner1d(B,B)-2*(np.dot(A,B.T)))\n",
        "# #     # Find DH\n",
        "# #     dH = np.max(np.array([np.max(np.min(D_mat,axis=0)),np.max(np.min(D_mat,axis=1))]))\n",
        "# #     return(dH)"
      ],
      "metadata": {
        "id": "iNhVDfVdT3hC"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q monai\n",
        "# import monai"
      ],
      "metadata": {
        "id": "bQFULhTuYhXQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install slicer"
      ],
      "metadata": {
        "id": "1b0m-7NeNtUe"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import slicer"
      ],
      "metadata": {
        "id": "RVUyMf-lN4M7"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import slicer.vtkSlicerSegmentComparisonModuleLogicPython\n",
        "# s=getNode('vtkMRMLSegmentationNode1') # Whatever your input is\n",
        "# p1=s.GetClosedSurfaceRepresentation('Segment_1') # Again, depends on your input. If it's not a segmentation then you'll need to access the model nodes\n",
        "# p2=s.GetClosedSurfaceRepresentation('Segment_2')\n",
        "# pdf = slicer.vtkSlicerSegmentComparisonModuleLogic.vtkPolyDataDistanceHistogramFilter()\n",
        "# pdf.SetInputReferencePolyData(p1)\n",
        "# pdf.SetInputComparePolyData(p2)\n",
        "# pdf.Update()\n",
        "# pdf.GetNthPercentileHausdorffDistance(0)"
      ],
      "metadata": {
        "id": "kQ7f3_AZNbnX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def hausdorff95(outputs, segmentations):\n",
        "#   print(outputs.shape)\n",
        "#   print(segmentations.shape)\n",
        "#   n_classes = segmentations.shape[1]\n",
        "#   region_hd95_scores = []\n",
        "#   for i in range(n_classes):\n",
        "#     region_out = outputs[:, i, :, :, :].numpy()\n",
        "#     region_out = region_out.astype(np.uint8)\n",
        "#     region_seg = segmentations[:, i, :, :, :].numpy()\n",
        "#     region_seg = region_seg.astype(np.uint8)\n",
        "#     print(region_out.shape)\n",
        "#     print(region_seg.shape)\n",
        "#     print(\"\\nya\\n\")\n",
        "#     d = monai.metrics.compute_percent_hausdorff_distance(region_out, region_seg)\n",
        "#     print(\"done\")\n",
        "#     #   print(type(outputs[i]))\n",
        "#     #   print(type(segmentations[i]))\n",
        "#     #   out = outputs[i].numpy()\n",
        "#     #   seg = segmentations[i].numpy()\n",
        "#     #   print(type(out))\n",
        "#     #   print(type(seg))\n",
        "#       # numerator = 2*(outputs*segmentations).sum()\n",
        "#       # denominator = outputs.sum() + segmentations.sum()\n",
        "#       # dice = (numerator) / (denominator)\n",
        "#       # region_scores.append(dice)\n",
        "#   return region_hd95_scores"
      ],
      "metadata": {
        "id": "gtCZvH_KY_rm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -q kornia"
      ],
      "metadata": {
        "id": "4tEF3NK3kKW4"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import kornia.losses as losses"
      ],
      "metadata": {
        "id": "FVlPL3ewkaUA"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def hausdorff95(outputs, segmentations):\n",
        "#   print(outputs.shape)\n",
        "#   print(segmentations.shape)\n",
        "#   n_classes = segmentations.shape[1]\n",
        "#   region_hd95_scores = []\n",
        "#   for i in range(n_classes):\n",
        "#     region_out = outputs[:, i, :, :, :].numpy()\n",
        "#     region_out = region_out.astype(np.uint8)\n",
        "#     region_seg = segmentations[:, i, :, :, :].numpy()\n",
        "#     region_seg = region_seg.astype(np.uint8)\n",
        "#     print(region_out.shape)\n",
        "#     print(region_seg.shape)\n",
        "#     print(\"\\nya\\n\")\n",
        "#     d = monai.metrics.compute_percent_hausdorff_distance(region_out, region_seg)\n",
        "#     print(\"done\")\n",
        "#     #   print(type(outputs[i]))\n",
        "#     #   print(type(segmentations[i]))\n",
        "#     #   out = outputs[i].numpy()\n",
        "#     #   seg = segmentations[i].numpy()\n",
        "#     #   print(type(out))\n",
        "#     #   print(type(seg))\n",
        "#       # numerator = 2*(outputs*segmentations).sum()\n",
        "#       # denominator = outputs.sum() + segmentations.sum()\n",
        "#       # dice = (numerator) / (denominator)\n",
        "#       # region_scores.append(dice)\n",
        "#   return region_hd95_scores"
      ],
      "metadata": {
        "id": "JMguaLMojPiW"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "VQfPcWW2nygw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def hausdorff95(outputs, segmentations):\n",
        "#   n_classes = segmentations.shape[1]\n",
        "#   region_hd95_scores = []\n",
        "#   for i in range(n_classes):\n",
        "#     region_out = outputs[:, i, :, :, :]\n",
        "#     region_seg = segmentations[:, i, :, :, :]\n",
        "#     print(region_out.shape)\n",
        "#     print(region_seg.shape)\n",
        "#     difference = region_out-region_seg\n",
        "#     # Calculate the square distances between each two points: |ai - bj|^2.\n",
        "#     square_distances = torch.einsum(\"...i,...i->...\", difference, difference)\n",
        "#     print(square_distances.shape)\n",
        "#     minimum_square_distance_a_to_b = torch.min(square_distances, axis=-1)\n",
        "#     next = torch.max(minimum_square_distance_a_to_b, axis=-1)\n",
        "#     # return math.sqrt()"
      ],
      "metadata": {
        "id": "c7-b5TXCncis"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def HausdorffDist(A,B):\n",
        "#     # Find pairwise distance\n",
        "#     D_mat = np.sqrt(inner1d(A,A)[np.newaxis].T + inner1d(B,B)-2*(np.dot(A,B.T)))\n",
        "#     # Find DH\n",
        "#     dH = np.max(np.array([np.max(np.min(D_mat,axis=0)),np.max(np.min(D_mat,axis=1))]))\n",
        "#     return(dH)"
      ],
      "metadata": {
        "id": "_cL_Vv1HpIeT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff"
      ],
      "metadata": {
        "id": "Xj5rZBc6-aKW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hausdorff(outputs, segmentations): # for region for every image\n",
        "  # print(outputs.shape)\n",
        "  # print(segmentations.shape)\n",
        "\n",
        "  # for each image in batch\n",
        "  h_imgs = [0,0,0]\n",
        "  len_imgs = len(outputs)\n",
        "\n",
        "  for idx in range(len_imgs): # for each image\n",
        "    out = outputs[idx]\n",
        "    seg = segmentations[idx]\n",
        "    n_classes = out.shape[0]\n",
        "    # print(n_classes)\n",
        "\n",
        "    region_hd_scores = []\n",
        "    for i in range(n_classes): # for each class\n",
        "      region_out = out[i]\n",
        "      region_seg = seg[i]\n",
        "      # print(region_out.shape)\n",
        "      # print(region_seg.shape)\n",
        "\n",
        "      # print()\n",
        "      total_hd_image = 0\n",
        "      for j in range(region_out.shape[0]): # for each slice\n",
        "        out_slice = region_out[j]\n",
        "        seg_slice = region_seg[j]\n",
        "        # print(out_slice.shape)\n",
        "        # print(seg_slice.shape)\n",
        "        a = directed_hausdorff(out_slice, seg_slice)[0]\n",
        "        b = directed_hausdorff(seg_slice, out_slice)[0]\n",
        "        hd_slice = max(a, b)\n",
        "        total_hd_image += hd_slice\n",
        "      avg_hd_image = total_hd_image/region_out.shape[0]\n",
        "      # print(avg_hd_image)\n",
        "      region_hd_scores.append(avg_hd_image)\n",
        "    # print(region_hd95_scores)\n",
        "    h_imgs[0] += region_hd_scores[0]\n",
        "    h_imgs[1] += region_hd_scores[1]\n",
        "    h_imgs[2] += region_hd_scores[2]\n",
        "  \n",
        "  for each in range(len(h_imgs)):\n",
        "    h_imgs[each] = h_imgs[each]/len_imgs\n",
        "  \n",
        "  print(h_imgs)\n",
        "\n",
        "  return h_imgs"
      ],
      "metadata": {
        "id": "EP9p1B_u7CA3"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, segs in testingloader:\n",
        "    with torch.no_grad():\n",
        "      print(len(images), len(segs))\n",
        "      print(images.shape)\n",
        "      print(segs.shape)\n",
        "      images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "      # segs = segs.long() - no\n",
        "      segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "      print(images.shape)\n",
        "      print(segs.shape)\n",
        "      outputs, softmax_outputs = model(images)\n",
        "      print(outputs.shape)\n",
        "      print(softmax_outputs.shape)\n",
        "      print()\n",
        "\n",
        "      print(\"\\n\", \".......\"*5, \"\\n\")\n",
        "\n",
        "      region_dice_scores = dice_score(softmax_outputs, segs)\n",
        "\n",
        "      print(len(region_dice_scores))\n",
        "      print(region_dice_scores)\n",
        "      print()\n",
        "\n",
        "      print(\"1 NECROTIC TUMOUR CORE (NCR  label 1)\")\n",
        "      print(region_dice_scores[0].item())\n",
        "      print()\n",
        "\n",
        "      print(\"2 GD-ENHANCING TUMOUR (ET  label 2)\")\n",
        "      print(region_dice_scores[1].item())\n",
        "      print()\n",
        "\n",
        "      print(\"3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED  label 3)\")\n",
        "      print(region_dice_scores[2].item())\n",
        "\n",
        "      print(\"\\n\", \".......\"*5, \"\\n\")\n",
        "\n",
        "      hd_scores = hausdorff(softmax_outputs, segs)\n",
        "\n",
        "      print()\n",
        "      print(len(hd_scores))\n",
        "      print(hd_scores)\n",
        "      print()\n",
        "\n",
        "      print(\"1 NECROTIC TUMOUR CORE (NCR  label 1)\")\n",
        "      print(hd_scores[0])\n",
        "      print()\n",
        "\n",
        "      print(\"2 GD-ENHANCING TUMOUR (ET  label 2)\")\n",
        "      print(hd_scores[1])\n",
        "      print()\n",
        "\n",
        "      print(\"3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED  label 3)\")\n",
        "      print(hd_scores[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI2kt2CTXcnm",
        "outputId": "c93c685e-d74d-43a0-d71f-573fbbf39850"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fc3c72d68f0>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "\n",
            " ................................... \n",
            "\n",
            "3\n",
            "[tensor(0.4000), tensor(0.4000), tensor(0.4000)]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR  label 1)\n",
            "0.39996883273124695\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET  label 2)\n",
            "0.39996883273124695\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED  label 3)\n",
            "0.39996883273124695\n",
            "\n",
            " ................................... \n",
            "\n",
            "[3.911422844038931, 4.385733865284312, 4.3516512121260815]\n",
            "\n",
            "3\n",
            "[3.911422844038931, 4.385733865284312, 4.3516512121260815]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR  label 1)\n",
            "3.911422844038931\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET  label 2)\n",
            "4.385733865284312\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED  label 3)\n",
            "4.3516512121260815\n"
          ]
        }
      ]
    }
  ]
}