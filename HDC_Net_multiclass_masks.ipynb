{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "OXG09_X81jA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Block(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    # my assumption was that if you wanted a convolution with 3x3x1, you couldn't have it be 3d and specify the kernel size like that\n",
        "    # however, looking at the code implementation, you can do that\n",
        "    self.one_one_one1 = nn.Conv3d(channels, channels, kernel_size=1, stride=1)\n",
        "    self.three_three_one = nn.Conv3d(8, 8, kernel_size=(3,3,1), padding=(1,1,0))\n",
        "    self.one_three_three = nn.Conv3d(channels, channels, kernel_size=(1,3,3), padding=(0,1,1))\n",
        "  def forward(self, x):\n",
        "    x1 = self.one_one_one1(x)\n",
        "    print(x1.shape)\n",
        "\n",
        "    # [2, 32, 64, 64, 64]\n",
        "\n",
        "    print(\"channel groups\")\n",
        "    channel_group1 = x1[:, 0:8, :, :, :] # one modality\n",
        "    print(channel_group1.shape)\n",
        "\n",
        "    channel_group2 = x1[:, 8:16, :, :, :]\n",
        "    print(channel_group2.shape)\n",
        "\n",
        "    channel_group3 = x1[:, 16:24, :, :, :]\n",
        "    print(channel_group3.shape)\n",
        "\n",
        "    channel_group4 = x1[:, 24:32, :, :, :]\n",
        "    print(channel_group4.shape)\n",
        "\n",
        "    x2 = self.three_three_one(channel_group2)\n",
        "    print(x2.shape)\n",
        "    x3 = self.three_three_one(channel_group3+x2)\n",
        "    print(x3.shape)\n",
        "    x4 = self.three_three_one(channel_group4+x3)\n",
        "    print(x4.shape)\n",
        "\n",
        "    end = torch.cat([channel_group1, x2, x3, x4], dim=1)\n",
        "    print(end.shape)\n",
        "\n",
        "    x5 = self.one_one_one1(end)\n",
        "    print(x5.shape)\n",
        "\n",
        "    out = self.one_three_three(x5)\n",
        "    print(out.shape)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5EfLQVgJ7r5n"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 32, 64, 64, 64), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Block(32)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCTjnTjRKHJN",
        "outputId": "7eaa92a5-cea5-4986-c3f4-344a67ecdb41"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 32, 64, 64, 64])\n",
            "HDC_Block(\n",
            "  (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "  (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Net(nn.Module):\n",
        "  def __init__(self, x):\n",
        "    super().__init__()\n",
        "    # self.pds = torch.nn.functional.interpolate(x)\n",
        "    self.conv1 = nn.Conv3d(in_channels=4, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
        "    self.downsample = nn.Conv3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.HDC = HDC_Block(32)\n",
        "    self.upsample = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.upinterpolate = nn.Upsample(scale_factor=2, mode='trilinear')\n",
        "    self.conv2 = nn.Conv3d(in_channels=32, out_channels=4, kernel_size=1, stride=1)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    nimages, channels, width, height, depth = x.shape\n",
        "    print(nimages, channels, width, height, depth)\n",
        "    print(x.type)\n",
        "    # x1 = torch.tensor(scipy.ndimage.zoom(x, [1, 8.0, 0.5, 0.5, 0.5])) # using this function took about 2 minutes and for many images, it's not reasonable\n",
        "    x1 = torch.nn.functional.interpolate(x, scale_factor=[0.5, 0.5, 0.5]) # PDS - interpolate only looks at dim 2,3,4... (doesn't regard for channel and number of images)\n",
        "    # instead, I used torch.nn.functional.interpolate to interpolate the spatial dimensions, but for the channels I used a 1x1x1 conv\n",
        "    # because they did want to avoid using 3x3x3 conv and it will work same\n",
        "    print(x1.shape)\n",
        "    x1 = self.conv1(x1)\n",
        "    print(x1.shape)\n",
        "\n",
        "    x2 = self.HDC(x1)\n",
        "    print(x2.shape)\n",
        "    print()\n",
        "    x3 = self.downsample(x2)\n",
        "    print(x3.shape)\n",
        "\n",
        "    x4 = self.HDC(x3)\n",
        "    print(x4.shape)\n",
        "    print()\n",
        "    x5 = self.downsample(x4)\n",
        "    print(x5.shape)\n",
        "\n",
        "    x6 = self.HDC(x5)\n",
        "    print(x6.shape)\n",
        "    print()\n",
        "    x7 = self.downsample(x6)\n",
        "    print(x7.shape)\n",
        "\n",
        "    x8 = self.HDC(x7)\n",
        "    print(x8.shape)\n",
        "    print()\n",
        "\n",
        "    print(\"decoder time\")\n",
        "\n",
        "    x9 = self.upsample(x8)\n",
        "    print(x9.shape)\n",
        "    x10 = torch.add(x9, x6)\n",
        "    print(x10.shape)\n",
        "    x11 = self.HDC(x10)\n",
        "    print(x11.shape)\n",
        "\n",
        "    x12 = self.upsample(x11)\n",
        "    print(x12.shape)\n",
        "    x13 = torch.add(x12, x4)\n",
        "    print(x13.shape)\n",
        "    x14 = self.HDC(x13)\n",
        "    print(x14.shape)\n",
        "\n",
        "    x15 = self.upsample(x14)\n",
        "    print(x15.shape)\n",
        "    x16 = torch.add(x15, x2)\n",
        "    print(x16.shape)\n",
        "    x17 = self.HDC(x16)\n",
        "    print(x17.shape)\n",
        "\n",
        "    print(\"\\nupsampling\\n\") # by this they meant interpolation\n",
        "\n",
        "    x18 = self.upinterpolate(x17)\n",
        "    print(x18.shape)\n",
        "\n",
        "    x19 = self.conv2(x18)\n",
        "    print(x19.shape)\n",
        "\n",
        "    out = self.softmax(x19)\n",
        "    print(out.shape)\n",
        "\n",
        "    return x19, out"
      ],
      "metadata": {
        "id": "FnUEVd9i3bS8"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 4, 128, 128, 128), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Net(x)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bf1ybX73Wjd",
        "outputId": "276386e6-5e4a-4ccf-926c-bda22482d096"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 128, 128, 128])\n",
            "HDC_Net(\n",
            "  (conv1): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (downsample): Conv3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (HDC): HDC_Block(\n",
            "    (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "    (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            "  )\n",
            "  (upsample): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (upinterpolate): Upsample(scale_factor=2.0, mode=trilinear)\n",
            "  (conv2): Conv3d(32, 4, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fab71fcf230>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, probability = out"
      ],
      "metadata": {
        "id": "Z4lqjhQl9QRF"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "dX3XHUnj9SiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(probability.shape)\n",
        "print(probability)"
      ],
      "metadata": {
        "id": "3NRhxzDM9Z8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KYmHvHW0gvIB"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_images = []\n",
        "for i in range(2):\n",
        "  newx = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_images.append(newx)"
      ],
      "metadata": {
        "id": "lRm-uxBpgzku"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_images))\n",
        "print(randomized_training_images[0].shape)\n",
        "# print(randomized_training_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOFYVukkg0wi",
        "outputId": "7ae3c87b-526c-41e3-e49a-48e031618d42"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "lLHd0_Jlg2D8"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_segmentations))\n",
        "print(randomized_training_segmentations[0].shape)\n",
        "# print(randomized_training_segmentations[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Lpq1Yeg3ta",
        "outputId": "5053365f-c3df-418c-9177-b0aa40eeb1ac"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_data = list(zip(randomized_training_images, randomized_training_segmentations))"
      ],
      "metadata": {
        "id": "nO6zxE6rg48U"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset=randomized_training_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "tm7kwmsHg6F4"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVib00lgg7UU",
        "outputId": "ab0353a0-5509-490d-c1f2-630e89d81ba6"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_images.append(newy)"
      ],
      "metadata": {
        "id": "0OhQ4jPeg9NF"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_images))\n",
        "print(randomized_validation_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQD263Dg_F-",
        "outputId": "cba3b287-cee6-4fe2-f5f0-226424e85df3"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "gRq6qPWAhBSd"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_segmentations))\n",
        "print(randomized_validation_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsV3ZlvFhCrk",
        "outputId": "f66fcf59-d63e-4de6-f036-3c73e9ce8cca"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_data = list(zip(randomized_validation_images, randomized_validation_segmentations))"
      ],
      "metadata": {
        "id": "2jXVLmIvhDxh"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationloader = torch.utils.data.DataLoader(dataset=randomized_validation_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "-PjukyAkhFP3"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validationloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPI6wgumhGZA",
        "outputId": "8dfb1c39-e664-4307-854a-3f23d11cee23"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_images.append(newy)"
      ],
      "metadata": {
        "id": "ggGc5XCNhHu4"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_images))\n",
        "print(randomized_testing_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcPrDJhhJHS",
        "outputId": "1072bfaf-7253-461c-d043-e6bd7743d7f0"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "YKFnOHG0hKsv"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_segmentations))\n",
        "print(randomized_testing_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wkfD4POhMQU",
        "outputId": "a70f7f8b-5c14-48af-e17e-c8ac1b74db1d"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_data = list(zip(randomized_testing_segmentations, randomized_testing_segmentations))"
      ],
      "metadata": {
        "id": "qnIpezVFhNt8"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testingloader = torch.utils.data.DataLoader(dataset=randomized_testing_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "zvIhDCEchQii"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def dice_loss (y_preds, y_outputs):\n",
        "#   # talk more about this"
      ],
      "metadata": {
        "id": "_isXM9_HBqMa"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def multiclass_soft_dice_loss (y_preds, y_outputs):\n",
        "#   # talk more about this"
      ],
      "metadata": {
        "id": "Xc58JmdtB7OU"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def binary_soft_dice_loss (y_preds, y_outputs):\n",
        "#   # there is both a binary and a multiclass formula"
      ],
      "metadata": {
        "id": "sS0Q1yppCDTe"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training + Validation:\n",
        "multi-class soft Dice function as the loss function\n",
        "\n",
        "Testing:\n",
        "mean accuracy\n",
        "dice coefficient\n",
        "hausdorff implementation\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "njyI0anWCXzA",
        "outputId": "4204cf2c-cdf5-4e35-f79e-ba41486af021"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTraining + Validation:\\nmulti-class soft Dice function as the loss function\\n\\nTesting:\\nmean accuracy\\ndice coefficient\\nhausdorff implementation\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chose to make this a class because when you call dice loss in criterion, you don't have anything to input, but when u run the prediction through inside the training, then you have params\n",
        "# also because most sources I saw used a class\n",
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.smooth = 1\n",
        "  def forward(self, true, pred):\n",
        "    # flatten to easily do it pixel by pixel\n",
        "    true = true.view(-1)\n",
        "    pred = pred.view(-1)\n",
        "    numerator = 2*(true*pred).sum()\n",
        "    denominator = true.sum() + pred.sum()\n",
        "    dice_loss = 1 - (numerator + self.smooth) / (denominator + self.smooth)\n",
        "    return dice_loss"
      ],
      "metadata": {
        "id": "j1mhy3eKdCM9"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim"
      ],
      "metadata": {
        "id": "kvtMJWXLgeJl"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs\n",
        "epochs = 2 # should be 800\n",
        "# loss\n",
        "criterion = DiceLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=10**-3, weight_decay=10**-5)"
      ],
      "metadata": {
        "id": "2__9J37GgnAq"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  training_loss = 0\n",
        "  validation_loss = 0\n",
        "  print(\"training time\")\n",
        "  for images, segs in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "\n",
        "    # arg_outputs = outputs.argmax(dim=1)\n",
        "    # print(arg_outputs.shape)\n",
        "    # print(arg_outputs)\n",
        "    # print(segs.shape)\n",
        "    print()\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    \n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    training_loss += loss.item()\n",
        "    print()\n",
        "  print(\"validation time\")\n",
        "  for images, segs in validationloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    validation_loss += loss.item()\n",
        "  training_losses.append(training_loss/len(trainloader))\n",
        "  validation_losses.append(validation_loss/len(validationloader))\n",
        "  print(\"Epoch: {}/{}... Training Loss: {}... Validation Loss: {}...\".format(i+1,epochs, training_losses[-1], validation_losses[-1]))\n",
        "  if validation_loss < min(validation_losses):\n",
        "    print(\"Validation loss has decreased...saving model\")\n",
        "    torch.save(model.state_dict(), \"fcn.pth\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F02PVic5gpXT",
        "outputId": "307255f9-77cd-4fee-f3f5-e1793032bb10"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fab71863d10>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "\n",
            "tensor(0.6667, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fab7f2469b0>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "tensor(0.6667, grad_fn=<RsubBackward1>)\n",
            "Epoch: 1/2... Training Loss: 0.6666945219039917... Validation Loss: 0.666683554649353...\n",
            "\n",
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fab71832950>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "\n",
            "tensor(0.6667, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7fab7182dd10>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "tensor(0.6667, grad_fn=<RsubBackward1>)\n",
            "Epoch: 2/2... Training Loss: 0.6666945219039917... Validation Loss: 0.666683554649353...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_losses)\n",
        "print(validation_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0I2BsZrNHcj",
        "outputId": "84f1dcbc-dbd0-4721-d731-ed2d98119153"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6666945219039917, 0.6666945219039917]\n",
            "[0.666683554649353, 0.666683554649353]\n"
          ]
        }
      ]
    }
  ]
}