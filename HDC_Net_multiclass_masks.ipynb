{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OXG09_X81jA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Block(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    # my assumption was that if you wanted a convolution with 3x3x1, you couldn't have it be 3d and specify the kernel size like that\n",
        "    # however, looking at the code implementation, you can do that\n",
        "    self.one_one_one1 = nn.Conv3d(channels, channels, kernel_size=1, stride=1)\n",
        "    self.three_three_one = nn.Conv3d(8, 8, kernel_size=(3,3,1), padding=(1,1,0))\n",
        "    self.one_three_three = nn.Conv3d(channels, channels, kernel_size=(1,3,3), padding=(0,1,1))\n",
        "  def forward(self, x):\n",
        "    x1 = self.one_one_one1(x)\n",
        "    print(x1.shape)\n",
        "\n",
        "    # [2, 32, 64, 64, 64]\n",
        "\n",
        "    print(\"channel groups\")\n",
        "    channel_group1 = x1[:, 0:8, :, :, :] # one modality\n",
        "    print(channel_group1.shape)\n",
        "\n",
        "    channel_group2 = x1[:, 8:16, :, :, :]\n",
        "    print(channel_group2.shape)\n",
        "\n",
        "    channel_group3 = x1[:, 16:24, :, :, :]\n",
        "    print(channel_group3.shape)\n",
        "\n",
        "    channel_group4 = x1[:, 24:32, :, :, :]\n",
        "    print(channel_group4.shape)\n",
        "\n",
        "    x2 = self.three_three_one(channel_group2)\n",
        "    print(x2.shape)\n",
        "    x3 = self.three_three_one(channel_group3+x2)\n",
        "    print(x3.shape)\n",
        "    x4 = self.three_three_one(channel_group4+x3)\n",
        "    print(x4.shape)\n",
        "\n",
        "    end = torch.cat([channel_group1, x2, x3, x4], dim=1)\n",
        "    print(end.shape)\n",
        "\n",
        "    x5 = self.one_one_one1(end)\n",
        "    print(x5.shape)\n",
        "\n",
        "    out = self.one_three_three(x5)\n",
        "    print(out.shape)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5EfLQVgJ7r5n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 32, 64, 64, 64), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Block(32)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCTjnTjRKHJN",
        "outputId": "aaf09d85-e1c1-4900-8b2e-c94a95b013aa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 32, 64, 64, 64])\n",
            "HDC_Block(\n",
            "  (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "  (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Net(nn.Module):\n",
        "  def __init__(self, x):\n",
        "    super().__init__()\n",
        "    # self.pds = torch.nn.functional.interpolate(x)\n",
        "    self.conv1 = nn.Conv3d(in_channels=4, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
        "    self.downsample = nn.Conv3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.HDC = HDC_Block(32)\n",
        "    self.upsample = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.upinterpolate = nn.Upsample(scale_factor=2, mode='trilinear')\n",
        "    self.conv2 = nn.Conv3d(in_channels=32, out_channels=3, kernel_size=1, stride=1)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    nimages, channels, width, height, depth = x.shape\n",
        "    print(nimages, channels, width, height, depth)\n",
        "    print(x.type)\n",
        "    # x1 = torch.tensor(scipy.ndimage.zoom(x, [1, 8.0, 0.5, 0.5, 0.5])) # using this function took about 2 minutes and for many images, it's not reasonable\n",
        "    x1 = torch.nn.functional.interpolate(x, scale_factor=[0.5, 0.5, 0.5]) # PDS - interpolate only looks at dim 2,3,4... (doesn't regard for channel and number of images)\n",
        "    # instead, I used torch.nn.functional.interpolate to interpolate the spatial dimensions, but for the channels I used a 1x1x1 conv\n",
        "    # because they did want to avoid using 3x3x3 conv and it will work same\n",
        "    print(x1.shape)\n",
        "    x1 = self.conv1(x1)\n",
        "    print(x1.shape)\n",
        "\n",
        "    x2 = self.HDC(x1)\n",
        "    print(x2.shape)\n",
        "    print()\n",
        "    x3 = self.downsample(x2)\n",
        "    print(x3.shape)\n",
        "\n",
        "    x4 = self.HDC(x3)\n",
        "    print(x4.shape)\n",
        "    print()\n",
        "    x5 = self.downsample(x4)\n",
        "    print(x5.shape)\n",
        "\n",
        "    x6 = self.HDC(x5)\n",
        "    print(x6.shape)\n",
        "    print()\n",
        "    x7 = self.downsample(x6)\n",
        "    print(x7.shape)\n",
        "\n",
        "    x8 = self.HDC(x7)\n",
        "    print(x8.shape)\n",
        "    print()\n",
        "\n",
        "    print(\"decoder time\")\n",
        "\n",
        "    x9 = self.upsample(x8)\n",
        "    print(x9.shape)\n",
        "    x10 = torch.add(x9, x6)\n",
        "    print(x10.shape)\n",
        "    x11 = self.HDC(x10)\n",
        "    print(x11.shape)\n",
        "\n",
        "    x12 = self.upsample(x11)\n",
        "    print(x12.shape)\n",
        "    x13 = torch.add(x12, x4)\n",
        "    print(x13.shape)\n",
        "    x14 = self.HDC(x13)\n",
        "    print(x14.shape)\n",
        "\n",
        "    x15 = self.upsample(x14)\n",
        "    print(x15.shape)\n",
        "    x16 = torch.add(x15, x2)\n",
        "    print(x16.shape)\n",
        "    x17 = self.HDC(x16)\n",
        "    print(x17.shape)\n",
        "\n",
        "    print(\"\\nupsampling\\n\") # by this they meant interpolation\n",
        "\n",
        "    x18 = self.upinterpolate(x17)\n",
        "    print(x18.shape)\n",
        "\n",
        "    x19 = self.conv2(x18)\n",
        "    print(x19.shape)\n",
        "\n",
        "    out = self.softmax(x19)\n",
        "    print(out.shape)\n",
        "\n",
        "    return x19, out"
      ],
      "metadata": {
        "id": "FnUEVd9i3bS8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 4, 128, 128, 128), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Net(x)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bf1ybX73Wjd",
        "outputId": "d7474dd1-c91b-4ca5-e5a7-e2a1ca72318d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 128, 128, 128])\n",
            "HDC_Net(\n",
            "  (conv1): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (downsample): Conv3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (HDC): HDC_Block(\n",
            "    (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "    (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            "  )\n",
            "  (upsample): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (upinterpolate): Upsample(scale_factor=2.0, mode=trilinear)\n",
            "  (conv2): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f6f1fa25ef0>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, probability = out"
      ],
      "metadata": {
        "id": "Z4lqjhQl9QRF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "dX3XHUnj9SiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2889b8e-c367-40e9-ae9b-e690f25cc07b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor([[[[[ 8.7843e-02,  8.7234e-02,  8.6016e-02,  ...,  8.2627e-02,\n",
            "             7.3189e-02,  6.8470e-02],\n",
            "           [ 9.2754e-02,  9.0761e-02,  8.6776e-02,  ...,  8.1573e-02,\n",
            "             7.2789e-02,  6.8398e-02],\n",
            "           [ 1.0257e-01,  9.7816e-02,  8.8297e-02,  ...,  7.9464e-02,\n",
            "             7.1990e-02,  6.8253e-02],\n",
            "           ...,\n",
            "           [ 1.0986e-01,  1.0385e-01,  9.1842e-02,  ...,  8.0777e-02,\n",
            "             7.3132e-02,  6.9309e-02],\n",
            "           [ 1.1145e-01,  1.0424e-01,  8.9831e-02,  ...,  7.7969e-02,\n",
            "             6.9042e-02,  6.4579e-02],\n",
            "           [ 1.1225e-01,  1.0444e-01,  8.8826e-02,  ...,  7.6564e-02,\n",
            "             6.6998e-02,  6.2215e-02]],\n",
            "\n",
            "          [[ 8.8003e-02,  8.7243e-02,  8.5723e-02,  ...,  8.2546e-02,\n",
            "             7.3142e-02,  6.8440e-02],\n",
            "           [ 9.2851e-02,  9.0779e-02,  8.6636e-02,  ...,  8.1515e-02,\n",
            "             7.2794e-02,  6.8434e-02],\n",
            "           [ 1.0255e-01,  9.7852e-02,  8.8463e-02,  ...,  7.9453e-02,\n",
            "             7.2098e-02,  6.8420e-02],\n",
            "           ...,\n",
            "           [ 1.1044e-01,  1.0449e-01,  9.2585e-02,  ...,  8.1560e-02,\n",
            "             7.4068e-02,  7.0321e-02],\n",
            "           [ 1.1174e-01,  1.0467e-01,  9.0542e-02,  ...,  7.8516e-02,\n",
            "             6.9995e-02,  6.5735e-02],\n",
            "           [ 1.1238e-01,  1.0476e-01,  8.9520e-02,  ...,  7.6994e-02,\n",
            "             6.7959e-02,  6.3442e-02]],\n",
            "\n",
            "          [[ 8.8322e-02,  8.7260e-02,  8.5136e-02,  ...,  8.2383e-02,\n",
            "             7.3049e-02,  6.8381e-02],\n",
            "           [ 9.3045e-02,  9.0815e-02,  8.6356e-02,  ...,  8.1399e-02,\n",
            "             7.2803e-02,  6.8505e-02],\n",
            "           [ 1.0249e-01,  9.7925e-02,  8.8796e-02,  ...,  7.9432e-02,\n",
            "             7.2313e-02,  6.8754e-02],\n",
            "           ...,\n",
            "           [ 1.1162e-01,  1.0577e-01,  9.4072e-02,  ...,  8.3126e-02,\n",
            "             7.5939e-02,  7.2345e-02],\n",
            "           [ 1.1231e-01,  1.0553e-01,  9.1963e-02,  ...,  7.9611e-02,\n",
            "             7.1900e-02,  6.8045e-02],\n",
            "           [ 1.1265e-01,  1.0541e-01,  9.0909e-02,  ...,  7.7853e-02,\n",
            "             6.9881e-02,  6.5895e-02]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 8.8721e-02,  8.7989e-02,  8.6525e-02,  ...,  8.4748e-02,\n",
            "             7.5482e-02,  7.0849e-02],\n",
            "           [ 9.3248e-02,  9.1176e-02,  8.7033e-02,  ...,  8.3569e-02,\n",
            "             7.5116e-02,  7.0889e-02],\n",
            "           [ 1.0230e-01,  9.7549e-02,  8.8048e-02,  ...,  8.1211e-02,\n",
            "             7.4384e-02,  7.0970e-02],\n",
            "           ...,\n",
            "           [ 1.1009e-01,  1.0473e-01,  9.4008e-02,  ...,  8.5714e-02,\n",
            "             7.8759e-02,  7.5281e-02],\n",
            "           [ 1.1116e-01,  1.0459e-01,  9.1458e-02,  ...,  8.2085e-02,\n",
            "             7.3633e-02,  6.9407e-02],\n",
            "           [ 1.1169e-01,  1.0452e-01,  9.0183e-02,  ...,  8.0270e-02,\n",
            "             7.1070e-02,  6.6470e-02]],\n",
            "\n",
            "          [[ 9.2522e-02,  9.1846e-02,  9.0493e-02,  ...,  8.6649e-02,\n",
            "             7.7134e-02,  7.2376e-02],\n",
            "           [ 9.6349e-02,  9.4437e-02,  9.0613e-02,  ...,  8.5359e-02,\n",
            "             7.6779e-02,  7.2489e-02],\n",
            "           [ 1.0400e-01,  9.9620e-02,  9.0854e-02,  ...,  8.2780e-02,\n",
            "             7.6070e-02,  7.2714e-02],\n",
            "           ...,\n",
            "           [ 1.1152e-01,  1.0590e-01,  9.4654e-02,  ...,  8.5037e-02,\n",
            "             7.8042e-02,  7.4545e-02],\n",
            "           [ 1.1186e-01,  1.0545e-01,  9.2624e-02,  ...,  8.1954e-02,\n",
            "             7.3426e-02,  6.9162e-02],\n",
            "           [ 1.1203e-01,  1.0522e-01,  9.1609e-02,  ...,  8.0412e-02,\n",
            "             7.1118e-02,  6.6471e-02]],\n",
            "\n",
            "          [[ 9.4422e-02,  9.3774e-02,  9.2477e-02,  ...,  8.7599e-02,\n",
            "             7.7959e-02,  7.3140e-02],\n",
            "           [ 9.7899e-02,  9.6068e-02,  9.2404e-02,  ...,  8.6254e-02,\n",
            "             7.7611e-02,  7.3289e-02],\n",
            "           [ 1.0485e-01,  1.0065e-01,  9.2257e-02,  ...,  8.3565e-02,\n",
            "             7.6913e-02,  7.3586e-02],\n",
            "           ...,\n",
            "           [ 1.1224e-01,  1.0649e-01,  9.4977e-02,  ...,  8.4699e-02,\n",
            "             7.7684e-02,  7.4176e-02],\n",
            "           [ 1.1221e-01,  1.0588e-01,  9.3207e-02,  ...,  8.1888e-02,\n",
            "             7.3322e-02,  6.9040e-02],\n",
            "           [ 1.1220e-01,  1.0557e-01,  9.2322e-02,  ...,  8.0483e-02,\n",
            "             7.1142e-02,  6.6471e-02]]],\n",
            "\n",
            "\n",
            "         [[[ 1.1295e-01,  1.1175e-01,  1.0936e-01,  ...,  9.2782e-02,\n",
            "             6.0202e-02,  4.3912e-02],\n",
            "           [ 1.2159e-01,  1.1923e-01,  1.1452e-01,  ...,  9.5092e-02,\n",
            "             6.1278e-02,  4.4371e-02],\n",
            "           [ 1.3886e-01,  1.3418e-01,  1.2482e-01,  ...,  9.9713e-02,\n",
            "             6.3430e-02,  4.5288e-02],\n",
            "           ...,\n",
            "           [ 1.3990e-01,  1.3536e-01,  1.2629e-01,  ...,  1.0059e-01,\n",
            "             6.6174e-02,  4.8965e-02],\n",
            "           [ 1.1811e-01,  1.1624e-01,  1.1250e-01,  ...,  9.4717e-02,\n",
            "             7.0667e-02,  5.8641e-02],\n",
            "           [ 1.0722e-01,  1.0668e-01,  1.0560e-01,  ...,  9.1780e-02,\n",
            "             7.2913e-02,  6.3479e-02]],\n",
            "\n",
            "          [[ 1.1258e-01,  1.1140e-01,  1.0904e-01,  ...,  9.2519e-02,\n",
            "             6.0350e-02,  4.4265e-02],\n",
            "           [ 1.2131e-01,  1.1898e-01,  1.1430e-01,  ...,  9.4896e-02,\n",
            "             6.1261e-02,  4.4443e-02],\n",
            "           [ 1.3878e-01,  1.3413e-01,  1.2482e-01,  ...,  9.9649e-02,\n",
            "             6.3082e-02,  4.4799e-02],\n",
            "           ...,\n",
            "           [ 1.3972e-01,  1.3508e-01,  1.2580e-01,  ...,  9.9397e-02,\n",
            "             6.4626e-02,  4.7240e-02],\n",
            "           [ 1.1810e-01,  1.1617e-01,  1.1232e-01,  ...,  9.4084e-02,\n",
            "             6.9523e-02,  5.7243e-02],\n",
            "           [ 1.0728e-01,  1.0671e-01,  1.0557e-01,  ...,  9.1427e-02,\n",
            "             7.1972e-02,  6.2245e-02]],\n",
            "\n",
            "          [[ 1.1184e-01,  1.1069e-01,  1.0839e-01,  ...,  9.1994e-02,\n",
            "             6.0645e-02,  4.4971e-02],\n",
            "           [ 1.2077e-01,  1.1847e-01,  1.1387e-01,  ...,  9.4503e-02,\n",
            "             6.1226e-02,  4.4587e-02],\n",
            "           [ 1.3862e-01,  1.3403e-01,  1.2483e-01,  ...,  9.9522e-02,\n",
            "             6.2388e-02,  4.3821e-02],\n",
            "           ...,\n",
            "           [ 1.3936e-01,  1.3451e-01,  1.2482e-01,  ...,  9.7008e-02,\n",
            "             6.1528e-02,  4.3789e-02],\n",
            "           [ 1.1806e-01,  1.1602e-01,  1.1195e-01,  ...,  9.2817e-02,\n",
            "             6.7237e-02,  5.4447e-02],\n",
            "           [ 1.0741e-01,  1.0678e-01,  1.0552e-01,  ...,  9.0721e-02,\n",
            "             7.0092e-02,  5.9777e-02]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 1.0906e-01,  1.0816e-01,  1.0636e-01,  ...,  9.0357e-02,\n",
            "             6.0285e-02,  4.5249e-02],\n",
            "           [ 1.1857e-01,  1.1622e-01,  1.1151e-01,  ...,  9.3255e-02,\n",
            "             6.1104e-02,  4.5029e-02],\n",
            "           [ 1.3761e-01,  1.3234e-01,  1.2180e-01,  ...,  9.9052e-02,\n",
            "             6.2743e-02,  4.4588e-02],\n",
            "           ...,\n",
            "           [ 1.3465e-01,  1.2965e-01,  1.1966e-01,  ...,  9.4544e-02,\n",
            "             6.1039e-02,  4.4287e-02],\n",
            "           [ 1.1457e-01,  1.1263e-01,  1.0874e-01,  ...,  8.9835e-02,\n",
            "             6.4518e-02,  5.1859e-02],\n",
            "           [ 1.0453e-01,  1.0411e-01,  1.0329e-01,  ...,  8.7481e-02,\n",
            "             6.6257e-02,  5.5645e-02]],\n",
            "\n",
            "          [[ 1.0858e-01,  1.0749e-01,  1.0532e-01,  ...,  9.0214e-02,\n",
            "             5.9738e-02,  4.4500e-02],\n",
            "           [ 1.1751e-01,  1.1501e-01,  1.1002e-01,  ...,  9.2494e-02,\n",
            "             5.9992e-02,  4.3742e-02],\n",
            "           [ 1.3536e-01,  1.3005e-01,  1.1943e-01,  ...,  9.7053e-02,\n",
            "             6.0501e-02,  4.2225e-02],\n",
            "           ...,\n",
            "           [ 1.3426e-01,  1.2841e-01,  1.1670e-01,  ...,  9.0426e-02,\n",
            "             5.7124e-02,  4.0473e-02],\n",
            "           [ 1.1370e-01,  1.1052e-01,  1.0418e-01,  ...,  8.5423e-02,\n",
            "             6.0120e-02,  4.7469e-02],\n",
            "           [ 1.0342e-01,  1.0158e-01,  9.7917e-02,  ...,  8.2921e-02,\n",
            "             6.1618e-02,  5.0967e-02]],\n",
            "\n",
            "          [[ 1.0834e-01,  1.0716e-01,  1.0480e-01,  ...,  9.0142e-02,\n",
            "             5.9464e-02,  4.4125e-02],\n",
            "           [ 1.1697e-01,  1.1441e-01,  1.0928e-01,  ...,  9.2113e-02,\n",
            "             5.9436e-02,  4.3098e-02],\n",
            "           [ 1.3424e-01,  1.2891e-01,  1.1825e-01,  ...,  9.6053e-02,\n",
            "             5.9380e-02,  4.1044e-02],\n",
            "           ...,\n",
            "           [ 1.3406e-01,  1.2778e-01,  1.1523e-01,  ...,  8.8367e-02,\n",
            "             5.5166e-02,  3.8566e-02],\n",
            "           [ 1.1326e-01,  1.0947e-01,  1.0190e-01,  ...,  8.3216e-02,\n",
            "             5.7921e-02,  4.5274e-02],\n",
            "           [ 1.0286e-01,  1.0032e-01,  9.5232e-02,  ...,  8.0641e-02,\n",
            "             5.9299e-02,  4.8628e-02]]],\n",
            "\n",
            "\n",
            "         [[[ 4.6128e-03,  7.2755e-04, -7.0429e-03,  ..., -1.5564e-02,\n",
            "            -1.8632e-02, -2.0166e-02],\n",
            "           [ 5.5740e-03,  1.7316e-03, -5.9531e-03,  ..., -1.4781e-02,\n",
            "            -1.8712e-02, -2.0677e-02],\n",
            "           [ 7.4963e-03,  3.7398e-03, -3.7733e-03,  ..., -1.3215e-02,\n",
            "            -1.8870e-02, -2.1698e-02],\n",
            "           ...,\n",
            "           [ 2.2313e-03, -1.8248e-03, -9.9369e-03,  ..., -1.6661e-02,\n",
            "            -1.7883e-02, -1.8493e-02],\n",
            "           [-1.1967e-02, -1.5621e-02, -2.2931e-02,  ..., -2.5444e-02,\n",
            "            -2.3902e-02, -2.3131e-02],\n",
            "           [-1.9066e-02, -2.2520e-02, -2.9428e-02,  ..., -2.9836e-02,\n",
            "            -2.6911e-02, -2.5449e-02]],\n",
            "\n",
            "          [[ 6.0649e-03,  1.9805e-03, -6.1882e-03,  ..., -1.5519e-02,\n",
            "            -1.8981e-02, -2.0712e-02],\n",
            "           [ 6.8850e-03,  2.8386e-03, -5.2542e-03,  ..., -1.4599e-02,\n",
            "            -1.8924e-02, -2.1086e-02],\n",
            "           [ 8.5252e-03,  4.5547e-03, -3.3861e-03,  ..., -1.2757e-02,\n",
            "            -1.8809e-02, -2.1835e-02],\n",
            "           ...,\n",
            "           [ 2.7249e-03, -1.6030e-03, -1.0259e-02,  ..., -1.6027e-02,\n",
            "            -1.7545e-02, -1.8303e-02],\n",
            "           [-1.2074e-02, -1.5768e-02, -2.3155e-02,  ..., -2.5217e-02,\n",
            "            -2.3293e-02, -2.2331e-02],\n",
            "           [-1.9473e-02, -2.2850e-02, -2.9604e-02,  ..., -2.9812e-02,\n",
            "            -2.6167e-02, -2.4344e-02]],\n",
            "\n",
            "          [[ 8.9691e-03,  4.4865e-03, -4.4787e-03,  ..., -1.5430e-02,\n",
            "            -1.9679e-02, -2.1803e-02],\n",
            "           [ 9.5070e-03,  5.0526e-03, -3.8564e-03,  ..., -1.4234e-02,\n",
            "            -1.9348e-02, -2.1905e-02],\n",
            "           [ 1.0583e-02,  6.1847e-03, -2.6116e-03,  ..., -1.1841e-02,\n",
            "            -1.8686e-02, -2.2109e-02],\n",
            "           ...,\n",
            "           [ 3.7121e-03, -1.1594e-03, -1.0902e-02,  ..., -1.4760e-02,\n",
            "            -1.6869e-02, -1.7923e-02],\n",
            "           [-1.2287e-02, -1.6060e-02, -2.3605e-02,  ..., -2.4762e-02,\n",
            "            -2.2074e-02, -2.0730e-02],\n",
            "           [-2.0287e-02, -2.3510e-02, -2.9956e-02,  ..., -2.9763e-02,\n",
            "            -2.4677e-02, -2.2134e-02]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 8.0979e-03,  3.5138e-03, -5.6546e-03,  ..., -1.3900e-02,\n",
            "            -1.7505e-02, -1.9308e-02],\n",
            "           [ 7.8321e-03,  3.3542e-03, -5.6015e-03,  ..., -1.3849e-02,\n",
            "            -1.8689e-02, -2.1108e-02],\n",
            "           [ 7.3004e-03,  3.0352e-03, -5.4953e-03,  ..., -1.3748e-02,\n",
            "            -2.1056e-02, -2.4710e-02],\n",
            "           ...,\n",
            "           [ 3.4943e-04, -3.5807e-03, -1.1441e-02,  ..., -1.8203e-02,\n",
            "            -2.0521e-02, -2.1680e-02],\n",
            "           [-1.4081e-02, -1.7637e-02, -2.4748e-02,  ..., -2.8576e-02,\n",
            "            -2.6887e-02, -2.6043e-02],\n",
            "           [-2.1297e-02, -2.4665e-02, -3.1402e-02,  ..., -3.3763e-02,\n",
            "            -3.0070e-02, -2.8224e-02]],\n",
            "\n",
            "          [[ 6.6050e-03,  1.9686e-03, -7.3043e-03,  ..., -1.4602e-02,\n",
            "            -1.7981e-02, -1.9671e-02],\n",
            "           [ 5.5754e-03,  1.1555e-03, -7.6842e-03,  ..., -1.5272e-02,\n",
            "            -1.9701e-02, -2.1916e-02],\n",
            "           [ 3.5161e-03, -4.7064e-04, -8.4442e-03,  ..., -1.6611e-02,\n",
            "            -2.3141e-02, -2.6406e-02],\n",
            "           ...,\n",
            "           [-4.1001e-03, -8.4407e-03, -1.7122e-02,  ..., -2.2846e-02,\n",
            "            -2.4275e-02, -2.4989e-02],\n",
            "           [-1.8345e-02, -2.1703e-02, -2.8421e-02,  ..., -3.1444e-02,\n",
            "            -2.9510e-02, -2.8544e-02],\n",
            "           [-2.5467e-02, -2.8335e-02, -3.4070e-02,  ..., -3.5743e-02,\n",
            "            -3.2128e-02, -3.0321e-02]],\n",
            "\n",
            "          [[ 5.8586e-03,  1.1960e-03, -8.1291e-03,  ..., -1.4953e-02,\n",
            "            -1.8219e-02, -1.9853e-02],\n",
            "           [ 4.4471e-03,  5.6181e-05, -8.7256e-03,  ..., -1.5983e-02,\n",
            "            -2.0207e-02, -2.2320e-02],\n",
            "           [ 1.6240e-03, -2.2235e-03, -9.9186e-03,  ..., -1.8043e-02,\n",
            "            -2.4183e-02, -2.7253e-02],\n",
            "           ...,\n",
            "           [-6.3248e-03, -1.0871e-02, -1.9962e-02,  ..., -2.5168e-02,\n",
            "            -2.6152e-02, -2.6643e-02],\n",
            "           [-2.0476e-02, -2.3737e-02, -3.0257e-02,  ..., -3.2878e-02,\n",
            "            -3.0822e-02, -2.9794e-02],\n",
            "           [-2.7552e-02, -3.0169e-02, -3.5404e-02,  ..., -3.6734e-02,\n",
            "            -3.3157e-02, -3.1369e-02]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[ 8.9106e-02,  8.8272e-02,  8.6602e-02,  ...,  8.1987e-02,\n",
            "             7.2945e-02,  6.8425e-02],\n",
            "           [ 9.4070e-02,  9.1803e-02,  8.7270e-02,  ...,  8.1251e-02,\n",
            "             7.2673e-02,  6.8383e-02],\n",
            "           [ 1.0400e-01,  9.8865e-02,  8.8604e-02,  ...,  7.9779e-02,\n",
            "             7.2127e-02,  6.8301e-02],\n",
            "           ...,\n",
            "           [ 1.0916e-01,  1.0306e-01,  9.0871e-02,  ...,  8.0047e-02,\n",
            "             7.3389e-02,  7.0060e-02],\n",
            "           [ 1.0989e-01,  1.0302e-01,  8.9268e-02,  ...,  7.7987e-02,\n",
            "             6.9773e-02,  6.5666e-02],\n",
            "           [ 1.1026e-01,  1.0300e-01,  8.8467e-02,  ...,  7.6957e-02,\n",
            "             6.7965e-02,  6.3469e-02]],\n",
            "\n",
            "          [[ 8.8762e-02,  8.7856e-02,  8.6044e-02,  ...,  8.1637e-02,\n",
            "             7.2953e-02,  6.8610e-02],\n",
            "           [ 9.3687e-02,  9.1415e-02,  8.6869e-02,  ...,  8.1015e-02,\n",
            "             7.2763e-02,  6.8637e-02],\n",
            "           [ 1.0354e-01,  9.8532e-02,  8.8519e-02,  ...,  7.9772e-02,\n",
            "             7.2384e-02,  6.8690e-02],\n",
            "           ...,\n",
            "           [ 1.0988e-01,  1.0377e-01,  9.1563e-02,  ...,  8.1154e-02,\n",
            "             7.4414e-02,  7.1044e-02],\n",
            "           [ 1.1030e-01,  1.0358e-01,  9.0130e-02,  ...,  7.8606e-02,\n",
            "             7.0453e-02,  6.6377e-02],\n",
            "           [ 1.1051e-01,  1.0348e-01,  8.9413e-02,  ...,  7.7332e-02,\n",
            "             6.8473e-02,  6.4043e-02]],\n",
            "\n",
            "          [[ 8.8072e-02,  8.7024e-02,  8.4928e-02,  ...,  8.0937e-02,\n",
            "             7.2967e-02,  6.8982e-02],\n",
            "           [ 9.2923e-02,  9.0638e-02,  8.6068e-02,  ...,  8.0544e-02,\n",
            "             7.2945e-02,  6.9145e-02],\n",
            "           [ 1.0263e-01,  9.7866e-02,  8.8349e-02,  ...,  7.9757e-02,\n",
            "             7.2899e-02,  6.9470e-02],\n",
            "           ...,\n",
            "           [ 1.1132e-01,  1.0520e-01,  9.2948e-02,  ...,  8.3368e-02,\n",
            "             7.6464e-02,  7.3012e-02],\n",
            "           [ 1.1112e-01,  1.0470e-01,  9.1853e-02,  ...,  7.9845e-02,\n",
            "             7.1815e-02,  6.7799e-02],\n",
            "           [ 1.1102e-01,  1.0445e-01,  9.1306e-02,  ...,  7.8084e-02,\n",
            "             6.9490e-02,  6.5193e-02]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 8.7106e-02,  8.6630e-02,  8.5676e-02,  ...,  8.2925e-02,\n",
            "             7.3593e-02,  6.8927e-02],\n",
            "           [ 9.2113e-02,  9.0247e-02,  8.6515e-02,  ...,  8.1645e-02,\n",
            "             7.3047e-02,  6.8747e-02],\n",
            "           [ 1.0213e-01,  9.7483e-02,  8.8193e-02,  ...,  7.9085e-02,\n",
            "             7.1953e-02,  6.8387e-02],\n",
            "           ...,\n",
            "           [ 1.1073e-01,  1.0526e-01,  9.4317e-02,  ...,  8.5111e-02,\n",
            "             7.8377e-02,  7.5010e-02],\n",
            "           [ 1.1124e-01,  1.0469e-01,  9.1593e-02,  ...,  8.1298e-02,\n",
            "             7.3106e-02,  6.9010e-02],\n",
            "           [ 1.1150e-01,  1.0441e-01,  9.0232e-02,  ...,  7.9391e-02,\n",
            "             7.0470e-02,  6.6010e-02]],\n",
            "\n",
            "          [[ 9.2109e-02,  9.1373e-02,  8.9900e-02,  ...,  8.6925e-02,\n",
            "             7.6808e-02,  7.1750e-02],\n",
            "           [ 9.6120e-02,  9.4145e-02,  9.0194e-02,  ...,  8.5290e-02,\n",
            "             7.6281e-02,  7.1777e-02],\n",
            "           [ 1.0414e-01,  9.9688e-02,  9.0782e-02,  ...,  8.2020e-02,\n",
            "             7.5227e-02,  7.1831e-02],\n",
            "           ...,\n",
            "           [ 1.1113e-01,  1.0522e-01,  9.3420e-02,  ...,  8.5345e-02,\n",
            "             7.7850e-02,  7.4102e-02],\n",
            "           [ 1.1117e-01,  1.0465e-01,  9.1597e-02,  ...,  8.1797e-02,\n",
            "             7.3050e-02,  6.8677e-02],\n",
            "           [ 1.1120e-01,  1.0436e-01,  9.0685e-02,  ...,  8.0024e-02,\n",
            "             7.0651e-02,  6.5964e-02]],\n",
            "\n",
            "          [[ 9.4611e-02,  9.3745e-02,  9.2012e-02,  ...,  8.8925e-02,\n",
            "             7.8416e-02,  7.3162e-02],\n",
            "           [ 9.8123e-02,  9.6093e-02,  9.2033e-02,  ...,  8.7112e-02,\n",
            "             7.7899e-02,  7.3292e-02],\n",
            "           [ 1.0515e-01,  1.0079e-01,  9.2076e-02,  ...,  8.3488e-02,\n",
            "             7.6865e-02,  7.3553e-02],\n",
            "           ...,\n",
            "           [ 1.1133e-01,  1.0521e-01,  9.2971e-02,  ...,  8.5461e-02,\n",
            "             7.7586e-02,  7.3648e-02],\n",
            "           [ 1.1114e-01,  1.0463e-01,  9.1598e-02,  ...,  8.2047e-02,\n",
            "             7.3023e-02,  6.8511e-02],\n",
            "           [ 1.1105e-01,  1.0434e-01,  9.0912e-02,  ...,  8.0340e-02,\n",
            "             7.0741e-02,  6.5942e-02]]],\n",
            "\n",
            "\n",
            "         [[[ 1.1492e-01,  1.1350e-01,  1.1065e-01,  ...,  9.1811e-02,\n",
            "             6.0096e-02,  4.4238e-02],\n",
            "           [ 1.2319e-01,  1.2079e-01,  1.1598e-01,  ...,  9.4236e-02,\n",
            "             6.1351e-02,  4.4909e-02],\n",
            "           [ 1.3973e-01,  1.3537e-01,  1.2664e-01,  ...,  9.9085e-02,\n",
            "             6.3861e-02,  4.6249e-02],\n",
            "           ...,\n",
            "           [ 1.4029e-01,  1.3556e-01,  1.2609e-01,  ...,  1.0083e-01,\n",
            "             6.6458e-02,  4.9270e-02],\n",
            "           [ 1.1814e-01,  1.1622e-01,  1.1237e-01,  ...,  9.5380e-02,\n",
            "             7.0520e-02,  5.8090e-02],\n",
            "           [ 1.0706e-01,  1.0655e-01,  1.0552e-01,  ...,  9.2652e-02,\n",
            "             7.2551e-02,  6.2500e-02]],\n",
            "\n",
            "          [[ 1.1381e-01,  1.1258e-01,  1.1011e-01,  ...,  9.1545e-02,\n",
            "             6.0413e-02,  4.4847e-02],\n",
            "           [ 1.2244e-01,  1.2007e-01,  1.1532e-01,  ...,  9.4139e-02,\n",
            "             6.1563e-02,  4.5275e-02],\n",
            "           [ 1.3970e-01,  1.3505e-01,  1.2575e-01,  ...,  9.9327e-02,\n",
            "             6.3863e-02,  4.6131e-02],\n",
            "           ...,\n",
            "           [ 1.4034e-01,  1.3535e-01,  1.2536e-01,  ...,  1.0003e-01,\n",
            "             6.5133e-02,  4.7684e-02],\n",
            "           [ 1.1857e-01,  1.1643e-01,  1.1215e-01,  ...,  9.4954e-02,\n",
            "             6.9669e-02,  5.7027e-02],\n",
            "           [ 1.0769e-01,  1.0697e-01,  1.0554e-01,  ...,  9.2416e-02,\n",
            "             7.1937e-02,  6.1698e-02]],\n",
            "\n",
            "          [[ 1.1160e-01,  1.1074e-01,  1.0902e-01,  ...,  9.1012e-02,\n",
            "             6.1047e-02,  4.6065e-02],\n",
            "           [ 1.2095e-01,  1.1863e-01,  1.1400e-01,  ...,  9.3945e-02,\n",
            "             6.1987e-02,  4.6008e-02],\n",
            "           [ 1.3964e-01,  1.3441e-01,  1.2396e-01,  ...,  9.9812e-02,\n",
            "             6.3867e-02,  4.5895e-02],\n",
            "           ...,\n",
            "           [ 1.4043e-01,  1.3493e-01,  1.2391e-01,  ...,  9.8421e-02,\n",
            "             6.2482e-02,  4.4513e-02],\n",
            "           [ 1.1944e-01,  1.1686e-01,  1.1170e-01,  ...,  9.4103e-02,\n",
            "             6.7968e-02,  5.4900e-02],\n",
            "           [ 1.0894e-01,  1.0783e-01,  1.0560e-01,  ...,  9.1944e-02,\n",
            "             7.0710e-02,  6.0094e-02]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 1.0853e-01,  1.0726e-01,  1.0471e-01,  ...,  9.1863e-02,\n",
            "             6.0854e-02,  4.5350e-02],\n",
            "           [ 1.1792e-01,  1.1544e-01,  1.1048e-01,  ...,  9.3898e-02,\n",
            "             6.0972e-02,  4.4508e-02],\n",
            "           [ 1.3670e-01,  1.3180e-01,  1.2200e-01,  ...,  9.7970e-02,\n",
            "             6.1207e-02,  4.2825e-02],\n",
            "           ...,\n",
            "           [ 1.3557e-01,  1.3029e-01,  1.1972e-01,  ...,  9.5126e-02,\n",
            "             6.1125e-02,  4.4124e-02],\n",
            "           [ 1.1604e-01,  1.1313e-01,  1.0732e-01,  ...,  8.9799e-02,\n",
            "             6.3894e-02,  5.0941e-02],\n",
            "           [ 1.0627e-01,  1.0455e-01,  1.0112e-01,  ...,  8.7136e-02,\n",
            "             6.5278e-02,  5.4349e-02]],\n",
            "\n",
            "          [[ 1.0788e-01,  1.0660e-01,  1.0404e-01,  ...,  9.1082e-02,\n",
            "             6.0805e-02,  4.5667e-02],\n",
            "           [ 1.1711e-01,  1.1452e-01,  1.0933e-01,  ...,  9.2976e-02,\n",
            "             6.0641e-02,  4.4473e-02],\n",
            "           [ 1.3559e-01,  1.3036e-01,  1.1990e-01,  ...,  9.6764e-02,\n",
            "             6.0313e-02,  4.2087e-02],\n",
            "           ...,\n",
            "           [ 1.3367e-01,  1.2751e-01,  1.1519e-01,  ...,  9.1065e-02,\n",
            "             5.6917e-02,  3.9843e-02],\n",
            "           [ 1.1387e-01,  1.1028e-01,  1.0310e-01,  ...,  8.5784e-02,\n",
            "             5.9459e-02,  4.6296e-02],\n",
            "           [ 1.0397e-01,  1.0166e-01,  9.7050e-02,  ...,  8.3144e-02,\n",
            "             6.0730e-02,  4.9523e-02]],\n",
            "\n",
            "          [[ 1.0755e-01,  1.0627e-01,  1.0371e-01,  ...,  9.0692e-02,\n",
            "             6.0781e-02,  4.5825e-02],\n",
            "           [ 1.1671e-01,  1.1406e-01,  1.0875e-01,  ...,  9.2515e-02,\n",
            "             6.0476e-02,  4.4456e-02],\n",
            "           [ 1.3504e-01,  1.2964e-01,  1.1884e-01,  ...,  9.6162e-02,\n",
            "             5.9866e-02,  4.1718e-02],\n",
            "           ...,\n",
            "           [ 1.3272e-01,  1.2612e-01,  1.1293e-01,  ...,  8.9034e-02,\n",
            "             5.4813e-02,  3.7703e-02],\n",
            "           [ 1.1279e-01,  1.0885e-01,  1.0099e-01,  ...,  8.3777e-02,\n",
            "             5.7242e-02,  4.3974e-02],\n",
            "           [ 1.0282e-01,  1.0022e-01,  9.5018e-02,  ...,  8.1148e-02,\n",
            "             5.8456e-02,  4.7110e-02]]],\n",
            "\n",
            "\n",
            "         [[[ 5.0564e-03,  8.2947e-04, -7.6244e-03,  ..., -1.5046e-02,\n",
            "            -1.9207e-02, -2.1288e-02],\n",
            "           [ 5.8090e-03,  1.7015e-03, -6.5137e-03,  ..., -1.4788e-02,\n",
            "            -1.8995e-02, -2.1099e-02],\n",
            "           [ 7.3143e-03,  3.4455e-03, -4.2922e-03,  ..., -1.4273e-02,\n",
            "            -1.8572e-02, -2.0722e-02],\n",
            "           ...,\n",
            "           [ 1.0200e-03, -2.8750e-03, -1.0665e-02,  ..., -1.7335e-02,\n",
            "            -1.8194e-02, -1.8624e-02],\n",
            "           [-1.3315e-02, -1.6648e-02, -2.3315e-02,  ..., -2.7106e-02,\n",
            "            -2.4056e-02, -2.2531e-02],\n",
            "           [-2.0483e-02, -2.3535e-02, -2.9640e-02,  ..., -3.1991e-02,\n",
            "            -2.6987e-02, -2.4484e-02]],\n",
            "\n",
            "          [[ 6.3101e-03,  1.8745e-03, -6.9967e-03,  ..., -1.5444e-02,\n",
            "            -1.9634e-02, -2.1729e-02],\n",
            "           [ 7.1189e-03,  2.7756e-03, -5.9110e-03,  ..., -1.4839e-02,\n",
            "            -1.9262e-02, -2.1473e-02],\n",
            "           [ 8.7366e-03,  4.5778e-03, -3.7397e-03,  ..., -1.3628e-02,\n",
            "            -1.8517e-02, -2.0961e-02],\n",
            "           ...,\n",
            "           [ 2.1528e-03, -2.1105e-03, -1.0637e-02,  ..., -1.7168e-02,\n",
            "            -1.8184e-02, -1.8692e-02],\n",
            "           [-1.2981e-02, -1.6428e-02, -2.3322e-02,  ..., -2.6586e-02,\n",
            "            -2.3795e-02, -2.2400e-02],\n",
            "           [-2.0547e-02, -2.3586e-02, -2.9664e-02,  ..., -3.1295e-02,\n",
            "            -2.6601e-02, -2.4254e-02]],\n",
            "\n",
            "          [[ 8.8174e-03,  3.9645e-03, -5.7414e-03,  ..., -1.6242e-02,\n",
            "            -2.0488e-02, -2.2612e-02],\n",
            "           [ 9.7386e-03,  4.9238e-03, -4.7058e-03,  ..., -1.4940e-02,\n",
            "            -1.9794e-02, -2.2221e-02],\n",
            "           [ 1.1581e-02,  6.8425e-03, -2.6346e-03,  ..., -1.2337e-02,\n",
            "            -1.8406e-02, -2.1440e-02],\n",
            "           ...,\n",
            "           [ 4.4185e-03, -5.8169e-04, -1.0582e-02,  ..., -1.6833e-02,\n",
            "            -1.8164e-02, -1.8829e-02],\n",
            "           [-1.2312e-02, -1.5987e-02, -2.3336e-02,  ..., -2.5546e-02,\n",
            "            -2.3274e-02, -2.2139e-02],\n",
            "           [-2.0677e-02, -2.3689e-02, -2.9713e-02,  ..., -2.9902e-02,\n",
            "            -2.5830e-02, -2.3794e-02]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 8.8498e-03,  4.0929e-03, -5.4209e-03,  ..., -1.5815e-02,\n",
            "            -1.8806e-02, -2.0302e-02],\n",
            "           [ 8.6626e-03,  4.0477e-03, -5.1821e-03,  ..., -1.5288e-02,\n",
            "            -1.9874e-02, -2.2167e-02],\n",
            "           [ 8.2882e-03,  3.9573e-03, -4.7046e-03,  ..., -1.4234e-02,\n",
            "            -2.2009e-02, -2.5897e-02],\n",
            "           ...,\n",
            "           [ 8.5586e-04, -3.4667e-03, -1.2112e-02,  ..., -1.9484e-02,\n",
            "            -2.0201e-02, -2.0560e-02],\n",
            "           [-1.4296e-02, -1.7998e-02, -2.5404e-02,  ..., -2.9059e-02,\n",
            "            -2.6905e-02, -2.5828e-02],\n",
            "           [-2.1872e-02, -2.5264e-02, -3.2049e-02,  ..., -3.3846e-02,\n",
            "            -3.0257e-02, -2.8462e-02]],\n",
            "\n",
            "          [[ 7.1877e-03,  2.5096e-03, -6.8464e-03,  ..., -1.5290e-02,\n",
            "            -1.8163e-02, -1.9600e-02],\n",
            "           [ 6.2231e-03,  1.7251e-03, -7.2710e-03,  ..., -1.5634e-02,\n",
            "            -1.9828e-02, -2.1926e-02],\n",
            "           [ 4.2940e-03,  1.5597e-04, -8.1201e-03,  ..., -1.6321e-02,\n",
            "            -2.3158e-02, -2.6577e-02],\n",
            "           ...,\n",
            "           [-4.6369e-03, -8.5719e-03, -1.6442e-02,  ..., -2.2454e-02,\n",
            "            -2.4184e-02, -2.5049e-02],\n",
            "           [-1.8445e-02, -2.1517e-02, -2.7660e-02,  ..., -3.0949e-02,\n",
            "            -2.9428e-02, -2.8668e-02],\n",
            "           [-2.5349e-02, -2.7989e-02, -3.3269e-02,  ..., -3.5197e-02,\n",
            "            -3.2051e-02, -3.0477e-02]],\n",
            "\n",
            "          [[ 6.3566e-03,  1.7180e-03, -7.5592e-03,  ..., -1.5028e-02,\n",
            "            -1.7842e-02, -1.9249e-02],\n",
            "           [ 5.0034e-03,  5.6380e-04, -8.3154e-03,  ..., -1.5807e-02,\n",
            "            -1.9806e-02, -2.1805e-02],\n",
            "           [ 2.2969e-03, -1.7447e-03, -9.8279e-03,  ..., -1.7364e-02,\n",
            "            -2.3733e-02, -2.6918e-02],\n",
            "           ...,\n",
            "           [-7.3833e-03, -1.1125e-02, -1.8607e-02,  ..., -2.3939e-02,\n",
            "            -2.6175e-02, -2.7293e-02],\n",
            "           [-2.0520e-02, -2.3276e-02, -2.8788e-02,  ..., -3.1895e-02,\n",
            "            -3.0690e-02, -3.0088e-02],\n",
            "           [-2.7088e-02, -2.9352e-02, -3.3879e-02,  ..., -3.5872e-02,\n",
            "            -3.2947e-02, -3.1485e-02]]]]], grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probability.shape)\n",
        "print(probability)"
      ],
      "metadata": {
        "id": "3NRhxzDM9Z8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c8a9cfd-cc9f-4cfb-c283-665c5f43eea5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor([[[[[0.3395, 0.3399, 0.3407,  ..., 0.3429, 0.3449, 0.3459],\n",
            "           [0.3395, 0.3397, 0.3402,  ..., 0.3423, 0.3447, 0.3459],\n",
            "           [0.3394, 0.3393, 0.3391,  ..., 0.3411, 0.3443, 0.3459],\n",
            "           ...,\n",
            "           [0.3415, 0.3411, 0.3403,  ..., 0.3416, 0.3441, 0.3453],\n",
            "           [0.3460, 0.3449, 0.3429,  ..., 0.3426, 0.3433, 0.3436],\n",
            "           [0.3482, 0.3469, 0.3442,  ..., 0.3431, 0.3429, 0.3428]],\n",
            "\n",
            "          [[0.3394, 0.3398, 0.3406,  ..., 0.3429, 0.3449, 0.3459],\n",
            "           [0.3394, 0.3396, 0.3401,  ..., 0.3423, 0.3447, 0.3459],\n",
            "           [0.3393, 0.3392, 0.3391,  ..., 0.3410, 0.3443, 0.3460],\n",
            "           ...,\n",
            "           [0.3416, 0.3413, 0.3406,  ..., 0.3419, 0.3445, 0.3457],\n",
            "           [0.3460, 0.3451, 0.3431,  ..., 0.3428, 0.3436, 0.3440],\n",
            "           [0.3483, 0.3470, 0.3444,  ..., 0.3433, 0.3431, 0.3431]],\n",
            "\n",
            "          [[0.3393, 0.3396, 0.3404,  ..., 0.3429, 0.3449, 0.3459],\n",
            "           [0.3392, 0.3395, 0.3399,  ..., 0.3422, 0.3448, 0.3460],\n",
            "           [0.3391, 0.3391, 0.3391,  ..., 0.3409, 0.3445, 0.3462],\n",
            "           ...,\n",
            "           [0.3418, 0.3416, 0.3411,  ..., 0.3424, 0.3452, 0.3466],\n",
            "           [0.3462, 0.3453, 0.3435,  ..., 0.3431, 0.3442, 0.3446],\n",
            "           [0.3484, 0.3472, 0.3447,  ..., 0.3435, 0.3436, 0.3437]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3398, 0.3402, 0.3411,  ..., 0.3434, 0.3453, 0.3462],\n",
            "           [0.3397, 0.3400, 0.3406,  ..., 0.3428, 0.3452, 0.3464],\n",
            "           [0.3395, 0.3395, 0.3396,  ..., 0.3416, 0.3451, 0.3469],\n",
            "           ...,\n",
            "           [0.3424, 0.3422, 0.3418,  ..., 0.3436, 0.3463, 0.3476],\n",
            "           [0.3465, 0.3457, 0.3439,  ..., 0.3445, 0.3454, 0.3458],\n",
            "           [0.3486, 0.3474, 0.3450,  ..., 0.3449, 0.3449, 0.3450]],\n",
            "\n",
            "          [[0.3408, 0.3413, 0.3423,  ..., 0.3440, 0.3458, 0.3467],\n",
            "           [0.3408, 0.3411, 0.3418,  ..., 0.3435, 0.3459, 0.3470],\n",
            "           [0.3406, 0.3406, 0.3408,  ..., 0.3425, 0.3460, 0.3478],\n",
            "           ...,\n",
            "           [0.3432, 0.3431, 0.3429,  ..., 0.3445, 0.3470, 0.3482],\n",
            "           [0.3473, 0.3465, 0.3451,  ..., 0.3453, 0.3461, 0.3466],\n",
            "           [0.3493, 0.3483, 0.3462,  ..., 0.3457, 0.3457, 0.3457]],\n",
            "\n",
            "          [[0.3414, 0.3419, 0.3429,  ..., 0.3442, 0.3460, 0.3469],\n",
            "           [0.3413, 0.3417, 0.3424,  ..., 0.3438, 0.3462, 0.3473],\n",
            "           [0.3411, 0.3412, 0.3414,  ..., 0.3429, 0.3464, 0.3482],\n",
            "           ...,\n",
            "           [0.3436, 0.3435, 0.3434,  ..., 0.3449, 0.3473, 0.3485],\n",
            "           [0.3476, 0.3470, 0.3457,  ..., 0.3457, 0.3465, 0.3469],\n",
            "           [0.3496, 0.3487, 0.3469,  ..., 0.3461, 0.3461, 0.3461]]],\n",
            "\n",
            "\n",
            "         [[[0.3481, 0.3483, 0.3488,  ..., 0.3464, 0.3405, 0.3375],\n",
            "           [0.3494, 0.3495, 0.3498,  ..., 0.3469, 0.3407, 0.3377],\n",
            "           [0.3520, 0.3519, 0.3517,  ..., 0.3480, 0.3413, 0.3380],\n",
            "           ...,\n",
            "           [0.3519, 0.3520, 0.3523,  ..., 0.3485, 0.3417, 0.3384],\n",
            "           [0.3483, 0.3491, 0.3508,  ..., 0.3484, 0.3439, 0.3416],\n",
            "           [0.3465, 0.3476, 0.3500,  ..., 0.3484, 0.3449, 0.3432]],\n",
            "\n",
            "          [[0.3479, 0.3481, 0.3487,  ..., 0.3463, 0.3405, 0.3377],\n",
            "           [0.3492, 0.3493, 0.3496,  ..., 0.3469, 0.3408, 0.3377],\n",
            "           [0.3518, 0.3518, 0.3516,  ..., 0.3480, 0.3412, 0.3379],\n",
            "           ...,\n",
            "           [0.3517, 0.3518, 0.3521,  ..., 0.3480, 0.3412, 0.3378],\n",
            "           [0.3482, 0.3490, 0.3507,  ..., 0.3482, 0.3434, 0.3411],\n",
            "           [0.3465, 0.3476, 0.3499,  ..., 0.3483, 0.3445, 0.3427]],\n",
            "\n",
            "          [[0.3473, 0.3477, 0.3484,  ..., 0.3462, 0.3407, 0.3379],\n",
            "           [0.3488, 0.3490, 0.3494,  ..., 0.3467, 0.3408, 0.3379],\n",
            "           [0.3516, 0.3516, 0.3515,  ..., 0.3479, 0.3411, 0.3377],\n",
            "           ...,\n",
            "           [0.3514, 0.3515, 0.3518,  ..., 0.3472, 0.3402, 0.3368],\n",
            "           [0.3482, 0.3489, 0.3505,  ..., 0.3477, 0.3426, 0.3400],\n",
            "           [0.3466, 0.3476, 0.3498,  ..., 0.3480, 0.3437, 0.3416]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3468, 0.3471, 0.3479,  ..., 0.3454, 0.3401, 0.3374],\n",
            "           [0.3484, 0.3486, 0.3490,  ..., 0.3462, 0.3404, 0.3376],\n",
            "           [0.3517, 0.3516, 0.3512,  ..., 0.3477, 0.3411, 0.3379],\n",
            "           ...,\n",
            "           [0.3509, 0.3508, 0.3507,  ..., 0.3467, 0.3402, 0.3370],\n",
            "           [0.3477, 0.3484, 0.3499,  ..., 0.3471, 0.3423, 0.3398],\n",
            "           [0.3461, 0.3473, 0.3495,  ..., 0.3474, 0.3433, 0.3412]],\n",
            "\n",
            "          [[0.3464, 0.3467, 0.3474,  ..., 0.3452, 0.3398, 0.3371],\n",
            "           [0.3480, 0.3482, 0.3485,  ..., 0.3459, 0.3401, 0.3372],\n",
            "           [0.3514, 0.3512, 0.3507,  ..., 0.3474, 0.3407, 0.3373],\n",
            "           ...,\n",
            "           [0.3511, 0.3509, 0.3505,  ..., 0.3463, 0.3398, 0.3366],\n",
            "           [0.3479, 0.3483, 0.3491,  ..., 0.3465, 0.3416, 0.3391],\n",
            "           [0.3463, 0.3470, 0.3484,  ..., 0.3465, 0.3425, 0.3404]],\n",
            "\n",
            "          [[0.3462, 0.3465, 0.3471,  ..., 0.3451, 0.3397, 0.3370],\n",
            "           [0.3479, 0.3480, 0.3482,  ..., 0.3458, 0.3399, 0.3370],\n",
            "           [0.3513, 0.3510, 0.3504,  ..., 0.3473, 0.3404, 0.3370],\n",
            "           ...,\n",
            "           [0.3512, 0.3509, 0.3504,  ..., 0.3461, 0.3396, 0.3363],\n",
            "           [0.3480, 0.3482, 0.3487,  ..., 0.3461, 0.3412, 0.3388],\n",
            "           [0.3464, 0.3469, 0.3479,  ..., 0.3461, 0.3420, 0.3400]]],\n",
            "\n",
            "\n",
            "         [[[0.3124, 0.3117, 0.3105,  ..., 0.3108, 0.3146, 0.3166],\n",
            "           [0.3111, 0.3108, 0.3101,  ..., 0.3108, 0.3146, 0.3164],\n",
            "           [0.3086, 0.3088, 0.3092,  ..., 0.3109, 0.3144, 0.3161],\n",
            "           ...,\n",
            "           [0.3066, 0.3069, 0.3074,  ..., 0.3099, 0.3142, 0.3163],\n",
            "           [0.3058, 0.3060, 0.3063,  ..., 0.3090, 0.3128, 0.3148],\n",
            "           [0.3053, 0.3055, 0.3058,  ..., 0.3085, 0.3122, 0.3140]],\n",
            "\n",
            "          [[0.3127, 0.3120, 0.3107,  ..., 0.3108, 0.3146, 0.3164],\n",
            "           [0.3114, 0.3110, 0.3102,  ..., 0.3109, 0.3145, 0.3163],\n",
            "           [0.3089, 0.3090, 0.3093,  ..., 0.3110, 0.3144, 0.3161],\n",
            "           ...,\n",
            "           [0.3067, 0.3069, 0.3073,  ..., 0.3101, 0.3143, 0.3164],\n",
            "           [0.3057, 0.3059, 0.3062,  ..., 0.3090, 0.3130, 0.3150],\n",
            "           [0.3052, 0.3054, 0.3057,  ..., 0.3085, 0.3123, 0.3142]],\n",
            "\n",
            "          [[0.3134, 0.3127, 0.3112,  ..., 0.3109, 0.3144, 0.3161],\n",
            "           [0.3120, 0.3116, 0.3106,  ..., 0.3110, 0.3144, 0.3161],\n",
            "           [0.3093, 0.3094, 0.3094,  ..., 0.3112, 0.3145, 0.3161],\n",
            "           ...,\n",
            "           [0.3068, 0.3069, 0.3071,  ..., 0.3105, 0.3146, 0.3166],\n",
            "           [0.3056, 0.3058, 0.3060,  ..., 0.3091, 0.3133, 0.3154],\n",
            "           [0.3050, 0.3052, 0.3055,  ..., 0.3085, 0.3126, 0.3147]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3135, 0.3127, 0.3110,  ..., 0.3112, 0.3146, 0.3164],\n",
            "           [0.3119, 0.3114, 0.3104,  ..., 0.3110, 0.3143, 0.3160],\n",
            "           [0.3088, 0.3089, 0.3092,  ..., 0.3107, 0.3137, 0.3152],\n",
            "           ...,\n",
            "           [0.3068, 0.3070, 0.3076,  ..., 0.3097, 0.3135, 0.3155],\n",
            "           [0.3057, 0.3059, 0.3062,  ..., 0.3084, 0.3124, 0.3143],\n",
            "           [0.3052, 0.3053, 0.3055,  ..., 0.3077, 0.3118, 0.3138]],\n",
            "\n",
            "          [[0.3128, 0.3120, 0.3104,  ..., 0.3108, 0.3144, 0.3162],\n",
            "           [0.3112, 0.3107, 0.3098,  ..., 0.3106, 0.3140, 0.3158],\n",
            "           [0.3080, 0.3082, 0.3086,  ..., 0.3101, 0.3133, 0.3149],\n",
            "           ...,\n",
            "           [0.3057, 0.3060, 0.3066,  ..., 0.3092, 0.3132, 0.3152],\n",
            "           [0.3049, 0.3052, 0.3058,  ..., 0.3083, 0.3123, 0.3143],\n",
            "           [0.3044, 0.3047, 0.3053,  ..., 0.3078, 0.3118, 0.3138]],\n",
            "\n",
            "          [[0.3124, 0.3116, 0.3100,  ..., 0.3107, 0.3143, 0.3161],\n",
            "           [0.3108, 0.3104, 0.3094,  ..., 0.3104, 0.3139, 0.3157],\n",
            "           [0.3076, 0.3078, 0.3082,  ..., 0.3098, 0.3131, 0.3148],\n",
            "           ...,\n",
            "           [0.3052, 0.3055, 0.3061,  ..., 0.3090, 0.3131, 0.3151],\n",
            "           [0.3044, 0.3048, 0.3056,  ..., 0.3082, 0.3123, 0.3143],\n",
            "           [0.3040, 0.3044, 0.3053,  ..., 0.3078, 0.3118, 0.3139]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.3395, 0.3399, 0.3408,  ..., 0.3428, 0.3449, 0.3460],\n",
            "           [0.3396, 0.3398, 0.3402,  ..., 0.3423, 0.3447, 0.3459],\n",
            "           [0.3396, 0.3394, 0.3390,  ..., 0.3413, 0.3442, 0.3457],\n",
            "           ...,\n",
            "           [0.3414, 0.3410, 0.3402,  ..., 0.3415, 0.3442, 0.3455],\n",
            "           [0.3457, 0.3448, 0.3428,  ..., 0.3427, 0.3435, 0.3439],\n",
            "           [0.3479, 0.3467, 0.3441,  ..., 0.3433, 0.3432, 0.3431]],\n",
            "\n",
            "          [[0.3394, 0.3398, 0.3407,  ..., 0.3428, 0.3449, 0.3460],\n",
            "           [0.3394, 0.3396, 0.3401,  ..., 0.3423, 0.3447, 0.3459],\n",
            "           [0.3394, 0.3393, 0.3390,  ..., 0.3412, 0.3443, 0.3458],\n",
            "           ...,\n",
            "           [0.3414, 0.3411, 0.3405,  ..., 0.3418, 0.3446, 0.3459],\n",
            "           [0.3457, 0.3448, 0.3431,  ..., 0.3429, 0.3437, 0.3441],\n",
            "           [0.3479, 0.3467, 0.3444,  ..., 0.3434, 0.3433, 0.3433]],\n",
            "\n",
            "          [[0.3393, 0.3396, 0.3404,  ..., 0.3428, 0.3450, 0.3460],\n",
            "           [0.3391, 0.3394, 0.3400,  ..., 0.3422, 0.3448, 0.3460],\n",
            "           [0.3389, 0.3390, 0.3391,  ..., 0.3410, 0.3444, 0.3460],\n",
            "           ...,\n",
            "           [0.3415, 0.3413, 0.3409,  ..., 0.3425, 0.3453, 0.3467],\n",
            "           [0.3458, 0.3450, 0.3435,  ..., 0.3431, 0.3442, 0.3447],\n",
            "           [0.3479, 0.3468, 0.3448,  ..., 0.3435, 0.3436, 0.3437]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3394, 0.3399, 0.3410,  ..., 0.3431, 0.3449, 0.3459],\n",
            "           [0.3394, 0.3398, 0.3405,  ..., 0.3425, 0.3449, 0.3461],\n",
            "           [0.3395, 0.3395, 0.3395,  ..., 0.3413, 0.3449, 0.3466],\n",
            "           ...,\n",
            "           [0.3423, 0.3422, 0.3419,  ..., 0.3436, 0.3461, 0.3474],\n",
            "           [0.3464, 0.3457, 0.3442,  ..., 0.3443, 0.3453, 0.3458],\n",
            "           [0.3484, 0.3474, 0.3453,  ..., 0.3447, 0.3449, 0.3450]],\n",
            "\n",
            "          [[0.3408, 0.3413, 0.3422,  ..., 0.3440, 0.3456, 0.3464],\n",
            "           [0.3407, 0.3410, 0.3417,  ..., 0.3434, 0.3457, 0.3468],\n",
            "           [0.3405, 0.3406, 0.3407,  ..., 0.3423, 0.3458, 0.3476],\n",
            "           ...,\n",
            "           [0.3432, 0.3431, 0.3427,  ..., 0.3444, 0.3469, 0.3482],\n",
            "           [0.3471, 0.3464, 0.3449,  ..., 0.3451, 0.3461, 0.3466],\n",
            "           [0.3490, 0.3480, 0.3460,  ..., 0.3455, 0.3457, 0.3458]],\n",
            "\n",
            "          [[0.3415, 0.3419, 0.3428,  ..., 0.3445, 0.3459, 0.3466],\n",
            "           [0.3413, 0.3416, 0.3423,  ..., 0.3439, 0.3461, 0.3471],\n",
            "           [0.3410, 0.3411, 0.3413,  ..., 0.3428, 0.3463, 0.3481],\n",
            "           ...,\n",
            "           [0.3437, 0.3435, 0.3431,  ..., 0.3448, 0.3474, 0.3486],\n",
            "           [0.3474, 0.3467, 0.3453,  ..., 0.3455, 0.3465, 0.3470],\n",
            "           [0.3493, 0.3483, 0.3464,  ..., 0.3459, 0.3461, 0.3462]]],\n",
            "\n",
            "\n",
            "         [[[0.3484, 0.3486, 0.3491,  ..., 0.3462, 0.3405, 0.3377],\n",
            "           [0.3496, 0.3498, 0.3501,  ..., 0.3468, 0.3408, 0.3379],\n",
            "           [0.3520, 0.3520, 0.3521,  ..., 0.3480, 0.3414, 0.3381],\n",
            "           ...,\n",
            "           [0.3522, 0.3523, 0.3524,  ..., 0.3487, 0.3418, 0.3384],\n",
            "           [0.3486, 0.3493, 0.3508,  ..., 0.3487, 0.3438, 0.3413],\n",
            "           [0.3468, 0.3479, 0.3501,  ..., 0.3488, 0.3447, 0.3427]],\n",
            "\n",
            "          [[0.3480, 0.3483, 0.3490,  ..., 0.3462, 0.3406, 0.3379],\n",
            "           [0.3493, 0.3495, 0.3499,  ..., 0.3468, 0.3409, 0.3379],\n",
            "           [0.3519, 0.3519, 0.3519,  ..., 0.3480, 0.3414, 0.3381],\n",
            "           ...,\n",
            "           [0.3520, 0.3521, 0.3522,  ..., 0.3483, 0.3414, 0.3379],\n",
            "           [0.3486, 0.3493, 0.3507,  ..., 0.3485, 0.3435, 0.3409],\n",
            "           [0.3469, 0.3479, 0.3500,  ..., 0.3486, 0.3445, 0.3425]],\n",
            "\n",
            "          [[0.3473, 0.3478, 0.3487,  ..., 0.3462, 0.3409, 0.3382],\n",
            "           [0.3488, 0.3491, 0.3496,  ..., 0.3468, 0.3410, 0.3381],\n",
            "           [0.3517, 0.3516, 0.3514,  ..., 0.3479, 0.3413, 0.3380],\n",
            "           ...,\n",
            "           [0.3516, 0.3516, 0.3517,  ..., 0.3477, 0.3405, 0.3370],\n",
            "           [0.3486, 0.3492, 0.3504,  ..., 0.3481, 0.3429, 0.3403],\n",
            "           [0.3472, 0.3480, 0.3497,  ..., 0.3482, 0.3440, 0.3419]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3467, 0.3470, 0.3476,  ..., 0.3461, 0.3406, 0.3378],\n",
            "           [0.3483, 0.3485, 0.3488,  ..., 0.3467, 0.3408, 0.3378],\n",
            "           [0.3514, 0.3513, 0.3512,  ..., 0.3478, 0.3412, 0.3379],\n",
            "           ...,\n",
            "           [0.3509, 0.3509, 0.3507,  ..., 0.3470, 0.3402, 0.3368],\n",
            "           [0.3481, 0.3486, 0.3496,  ..., 0.3473, 0.3422, 0.3396],\n",
            "           [0.3466, 0.3474, 0.3491,  ..., 0.3474, 0.3432, 0.3410]],\n",
            "\n",
            "          [[0.3462, 0.3465, 0.3471,  ..., 0.3454, 0.3401, 0.3375],\n",
            "           [0.3479, 0.3480, 0.3483,  ..., 0.3461, 0.3403, 0.3374],\n",
            "           [0.3514, 0.3512, 0.3507,  ..., 0.3474, 0.3407, 0.3374],\n",
            "           ...,\n",
            "           [0.3511, 0.3508, 0.3502,  ..., 0.3464, 0.3398, 0.3365],\n",
            "           [0.3480, 0.3483, 0.3489,  ..., 0.3465, 0.3415, 0.3389],\n",
            "           [0.3465, 0.3471, 0.3483,  ..., 0.3466, 0.3423, 0.3402]],\n",
            "\n",
            "          [[0.3459, 0.3462, 0.3469,  ..., 0.3451, 0.3399, 0.3373],\n",
            "           [0.3477, 0.3478, 0.3481,  ..., 0.3458, 0.3401, 0.3373],\n",
            "           [0.3513, 0.3511, 0.3505,  ..., 0.3472, 0.3405, 0.3372],\n",
            "           ...,\n",
            "           [0.3511, 0.3507, 0.3500,  ..., 0.3461, 0.3395, 0.3363],\n",
            "           [0.3480, 0.3482, 0.3486,  ..., 0.3461, 0.3411, 0.3386],\n",
            "           [0.3464, 0.3469, 0.3478,  ..., 0.3462, 0.3419, 0.3397]]],\n",
            "\n",
            "\n",
            "         [[[0.3121, 0.3115, 0.3101,  ..., 0.3111, 0.3146, 0.3163],\n",
            "           [0.3109, 0.3105, 0.3097,  ..., 0.3109, 0.3145, 0.3163],\n",
            "           [0.3083, 0.3085, 0.3089,  ..., 0.3107, 0.3144, 0.3162],\n",
            "           ...,\n",
            "           [0.3064, 0.3067, 0.3074,  ..., 0.3098, 0.3140, 0.3162],\n",
            "           [0.3057, 0.3059, 0.3063,  ..., 0.3085, 0.3127, 0.3148],\n",
            "           [0.3053, 0.3055, 0.3058,  ..., 0.3079, 0.3121, 0.3142]],\n",
            "\n",
            "          [[0.3126, 0.3118, 0.3104,  ..., 0.3111, 0.3144, 0.3161],\n",
            "           [0.3113, 0.3108, 0.3100,  ..., 0.3110, 0.3144, 0.3161],\n",
            "           [0.3087, 0.3088, 0.3091,  ..., 0.3108, 0.3144, 0.3161],\n",
            "           ...,\n",
            "           [0.3066, 0.3068, 0.3074,  ..., 0.3098, 0.3141, 0.3162],\n",
            "           [0.3056, 0.3058, 0.3063,  ..., 0.3086, 0.3128, 0.3149],\n",
            "           [0.3052, 0.3053, 0.3057,  ..., 0.3080, 0.3122, 0.3143]],\n",
            "\n",
            "          [[0.3134, 0.3126, 0.3109,  ..., 0.3110, 0.3142, 0.3158],\n",
            "           [0.3121, 0.3115, 0.3105,  ..., 0.3110, 0.3142, 0.3158],\n",
            "           [0.3094, 0.3095, 0.3096,  ..., 0.3110, 0.3143, 0.3160],\n",
            "           ...,\n",
            "           [0.3069, 0.3071, 0.3074,  ..., 0.3098, 0.3141, 0.3163],\n",
            "           [0.3056, 0.3058, 0.3061,  ..., 0.3088, 0.3130, 0.3150],\n",
            "           [0.3050, 0.3051, 0.3055,  ..., 0.3083, 0.3124, 0.3144]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3139, 0.3130, 0.3114,  ..., 0.3108, 0.3145, 0.3163],\n",
            "           [0.3123, 0.3117, 0.3107,  ..., 0.3108, 0.3143, 0.3160],\n",
            "           [0.3091, 0.3092, 0.3094,  ..., 0.3109, 0.3139, 0.3155],\n",
            "           ...,\n",
            "           [0.3067, 0.3069, 0.3074,  ..., 0.3094, 0.3136, 0.3157],\n",
            "           [0.3055, 0.3057, 0.3062,  ..., 0.3084, 0.3125, 0.3145],\n",
            "           [0.3049, 0.3051, 0.3056,  ..., 0.3078, 0.3119, 0.3139]],\n",
            "\n",
            "          [[0.3130, 0.3122, 0.3107,  ..., 0.3106, 0.3143, 0.3161],\n",
            "           [0.3114, 0.3109, 0.3100,  ..., 0.3105, 0.3140, 0.3158],\n",
            "           [0.3081, 0.3083, 0.3086,  ..., 0.3103, 0.3134, 0.3150],\n",
            "           ...,\n",
            "           [0.3057, 0.3062, 0.3070,  ..., 0.3092, 0.3133, 0.3153],\n",
            "           [0.3049, 0.3053, 0.3062,  ..., 0.3083, 0.3124, 0.3145],\n",
            "           [0.3045, 0.3049, 0.3057,  ..., 0.3079, 0.3120, 0.3140]],\n",
            "\n",
            "          [[0.3126, 0.3119, 0.3103,  ..., 0.3105, 0.3142, 0.3161],\n",
            "           [0.3110, 0.3105, 0.3096,  ..., 0.3103, 0.3139, 0.3156],\n",
            "           [0.3077, 0.3078, 0.3082,  ..., 0.3099, 0.3132, 0.3148],\n",
            "           ...,\n",
            "           [0.3052, 0.3058, 0.3069,  ..., 0.3091, 0.3131, 0.3151],\n",
            "           [0.3046, 0.3051, 0.3061,  ..., 0.3083, 0.3124, 0.3144],\n",
            "           [0.3042, 0.3048, 0.3058,  ..., 0.3079, 0.3120, 0.3141]]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KYmHvHW0gvIB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_images = []\n",
        "for i in range(2):\n",
        "  newx = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_images.append(newx)"
      ],
      "metadata": {
        "id": "lRm-uxBpgzku"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_images))\n",
        "print(randomized_training_images[0].shape)\n",
        "# print(randomized_training_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOFYVukkg0wi",
        "outputId": "ad08aca7-5d90-428a-863d-4f4de390b86a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "lLHd0_Jlg2D8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_segmentations))\n",
        "print(randomized_training_segmentations[0].shape)\n",
        "# print(randomized_training_segmentations[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Lpq1Yeg3ta",
        "outputId": "a3f755b2-2f10-4392-d6fd-707f53115df4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_data = list(zip(randomized_training_images, randomized_training_segmentations))"
      ],
      "metadata": {
        "id": "nO6zxE6rg48U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset=randomized_training_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "tm7kwmsHg6F4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVib00lgg7UU",
        "outputId": "49275536-40ad-4020-b4e3-7a48a7994b4b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_images.append(newy)"
      ],
      "metadata": {
        "id": "0OhQ4jPeg9NF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_images))\n",
        "print(randomized_validation_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQD263Dg_F-",
        "outputId": "6396081d-9256-4f8f-cad1-f796d1adb2bc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "gRq6qPWAhBSd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_segmentations))\n",
        "print(randomized_validation_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsV3ZlvFhCrk",
        "outputId": "7a3b4fef-caaa-4f8e-f249-386d980433da"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_data = list(zip(randomized_validation_images, randomized_validation_segmentations))"
      ],
      "metadata": {
        "id": "2jXVLmIvhDxh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationloader = torch.utils.data.DataLoader(dataset=randomized_validation_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "-PjukyAkhFP3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validationloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPI6wgumhGZA",
        "outputId": "57686fcf-d5d2-45d2-ffaf-2c1d6d521606"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_images.append(newy)"
      ],
      "metadata": {
        "id": "ggGc5XCNhHu4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_images))\n",
        "print(randomized_testing_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcPrDJhhJHS",
        "outputId": "25107b91-ce32-46ce-ee1f-b1baefb12e35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "YKFnOHG0hKsv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_segmentations))\n",
        "print(randomized_testing_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wkfD4POhMQU",
        "outputId": "18e4a6b4-00bb-4aa9-85f3-a578557e5e69"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_data = list(zip(randomized_testing_images, randomized_testing_segmentations))"
      ],
      "metadata": {
        "id": "qnIpezVFhNt8"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testingloader = torch.utils.data.DataLoader(dataset=randomized_testing_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "zvIhDCEchQii"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training + Validation:\n",
        "multi-class soft Dice function as the loss function\n",
        "\n",
        "Testing:\n",
        "mean accuracy\n",
        "dice coefficient\n",
        "hausdorff implementation\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "njyI0anWCXzA",
        "outputId": "d4dcb172-2762-4e01-f69c-f0f3f27ffe6b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTraining + Validation:\\nmulti-class soft Dice function as the loss function\\n\\nTesting:\\nmean accuracy\\ndice coefficient\\nhausdorff implementation\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chose to make this a class because when you call dice loss in criterion, you don't have anything to input, but when u run the prediction through inside the training, then you have params\n",
        "# also because most sources I saw used a class\n",
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.smooth = 1\n",
        "  def forward(self, true, pred):\n",
        "    # flatten to easily do it pixel by pixel\n",
        "    true = true.view(-1)\n",
        "    pred = pred.view(-1)\n",
        "    numerator = 2*(true*pred).sum()\n",
        "    denominator = true.sum() + pred.sum()\n",
        "    dice_loss = 1 - (numerator + self.smooth) / (denominator + self.smooth)\n",
        "    return dice_loss"
      ],
      "metadata": {
        "id": "j1mhy3eKdCM9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim"
      ],
      "metadata": {
        "id": "kvtMJWXLgeJl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs\n",
        "epochs = 2 # should be 800\n",
        "# loss\n",
        "criterion = DiceLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=10**-3, weight_decay=10**-5)"
      ],
      "metadata": {
        "id": "2__9J37GgnAq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  training_loss = 0\n",
        "  validation_loss = 0\n",
        "  print(\"training time\")\n",
        "  for images, segs in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "\n",
        "    # arg_outputs = outputs.argmax(dim=1)\n",
        "    # print(arg_outputs.shape)\n",
        "    # print(arg_outputs)\n",
        "    # print(segs.shape)\n",
        "    print()\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    \n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    training_loss += loss.item()\n",
        "    print()\n",
        "  print(\"validation time\")\n",
        "  for images, segs in validationloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    validation_loss += loss.item()\n",
        "  training_losses.append(training_loss/len(trainloader))\n",
        "  validation_losses.append(validation_loss/len(validationloader))\n",
        "  print(\"Epoch: {}/{}... Training Loss: {}... Validation Loss: {}...\".format(i+1,epochs, training_losses[-1], validation_losses[-1]))\n",
        "  if validation_loss < min(validation_losses):\n",
        "    print(\"Validation loss has decreased...saving model\")\n",
        "    torch.save(model.state_dict(), \"fcn.pth\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F02PVic5gpXT",
        "outputId": "7a2004f1-8a01-4ec5-c4f0-75498d0c1710"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f6f1d243f50>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f6f1d2434d0>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "Epoch: 1/2... Training Loss: 0.599981963634491... Validation Loss: 0.5999563932418823...\n",
            "\n",
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f6f1e3f0170>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f6f1d2b7e90>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "Epoch: 2/2... Training Loss: 0.5999820232391357... Validation Loss: 0.5999563932418823...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_losses)\n",
        "print(validation_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0I2BsZrNHcj",
        "outputId": "ae5ef7c4-8dca-4625-b000-a9ccdb352202"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.599981963634491, 0.5999820232391357]\n",
            "[0.5999563932418823, 0.5999563932418823]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(outputs, segmentations): # they find individual\n",
        "  # outputs = torch.Size([2, 3, 128, 128, 128])\n",
        "  # segmentations = torch.Size([2, 3, 128, 128, 128])\n",
        "  # print(output.shape)\n",
        "  # print(segmentations.shape)\n",
        "  n_classes = segmentations.shape[1]\n",
        "  region_scores = []\n",
        "  for i in range(n_classes):\n",
        "    outputs = outputs.view(-1)\n",
        "    segmentations = segmentations.view(-1)\n",
        "    numerator = 2*(outputs*segmentations).sum()\n",
        "    denominator = outputs.sum() + segmentations.sum()\n",
        "    dice = (numerator) / (denominator)\n",
        "    region_scores.append(dice)\n",
        "  return region_scores"
      ],
      "metadata": {
        "id": "c8DSrR2MXfHC"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1 NECROTIC TUMOUR CORE (NCR — label 1) - index 0\n",
        "\n",
        "2 GD-ENHANCING TUMOUR (ET — label 2) - index 1\n",
        "\n",
        "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3) - index 2\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "liYRO6MtW-H4",
        "outputId": "e9627048-3c39-41d2-dbf1-a9b0f39446e5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1 NECROTIC TUMOUR CORE (NCR — label 1) - index 0\\n\\n2 GD-ENHANCING TUMOUR (ET — label 2) - index 1\\n\\n3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3) - index 2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, segs in testingloader:\n",
        "    with torch.no_grad():\n",
        "      print(len(images), len(segs))\n",
        "      print(images.shape)\n",
        "      print(segs.shape)\n",
        "      images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "      # segs = segs.long() - no\n",
        "      segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "      print(images.shape)\n",
        "      print(segs.shape)\n",
        "      outputs, softmax_outputs = model(images)\n",
        "      print(outputs.shape)\n",
        "      print(softmax_outputs.shape)\n",
        "      print()\n",
        "\n",
        "      print(\".......\"*5)\n",
        "\n",
        "      region_scores = dice_score(softmax_outputs, segs)\n",
        "\n",
        "      print(len(region_scores))\n",
        "      print(region_scores)\n",
        "      print()\n",
        "\n",
        "      print(\"1 NECROTIC TUMOUR CORE (NCR — label 1)\")\n",
        "      print(region_scores[0].item())\n",
        "      print()\n",
        "\n",
        "      print(\"2 GD-ENHANCING TUMOUR (ET — label 2)\")\n",
        "      print(region_scores[1].item())\n",
        "      print()\n",
        "\n",
        "      print(\"3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\")\n",
        "      print(region_scores[2].item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI2kt2CTXcnm",
        "outputId": "2045008d-99c1-4f6c-a5de-84fa869d0e2b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7f6f1d241230>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "...................................\n",
            "3\n",
            "[tensor(0.4000), tensor(0.4000), tensor(0.4000)]\n",
            "\n",
            "1 NECROTIC TUMOUR CORE (NCR — label 1)\n",
            "0.3999752402305603\n",
            "\n",
            "2 GD-ENHANCING TUMOUR (ET — label 2)\n",
            "0.3999752402305603\n",
            "\n",
            "3 PERITUMORAL EDEMATOUS/INVADED TISSUE (ED — label 3)\n",
            "0.3999752402305603\n"
          ]
        }
      ]
    }
  ]
}