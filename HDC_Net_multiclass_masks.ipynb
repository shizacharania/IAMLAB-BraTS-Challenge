{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OXG09_X81jA7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import scipy.ndimage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Block(nn.Module):\n",
        "  def __init__(self, channels):\n",
        "    super().__init__()\n",
        "    # my assumption was that if you wanted a convolution with 3x3x1, you couldn't have it be 3d and specify the kernel size like that\n",
        "    # however, looking at the code implementation, you can do that\n",
        "    self.one_one_one1 = nn.Conv3d(channels, channels, kernel_size=1, stride=1)\n",
        "    self.three_three_one = nn.Conv3d(8, 8, kernel_size=(3,3,1), padding=(1,1,0))\n",
        "    self.one_three_three = nn.Conv3d(channels, channels, kernel_size=(1,3,3), padding=(0,1,1))\n",
        "  def forward(self, x):\n",
        "    x1 = self.one_one_one1(x)\n",
        "    print(x1.shape)\n",
        "\n",
        "    # [2, 32, 64, 64, 64]\n",
        "\n",
        "    print(\"channel groups\")\n",
        "    channel_group1 = x1[:, 0:8, :, :, :] # one modality\n",
        "    print(channel_group1.shape)\n",
        "\n",
        "    channel_group2 = x1[:, 8:16, :, :, :]\n",
        "    print(channel_group2.shape)\n",
        "\n",
        "    channel_group3 = x1[:, 16:24, :, :, :]\n",
        "    print(channel_group3.shape)\n",
        "\n",
        "    channel_group4 = x1[:, 24:32, :, :, :]\n",
        "    print(channel_group4.shape)\n",
        "\n",
        "    x2 = self.three_three_one(channel_group2)\n",
        "    print(x2.shape)\n",
        "    x3 = self.three_three_one(channel_group3+x2)\n",
        "    print(x3.shape)\n",
        "    x4 = self.three_three_one(channel_group4+x3)\n",
        "    print(x4.shape)\n",
        "\n",
        "    end = torch.cat([channel_group1, x2, x3, x4], dim=1)\n",
        "    print(end.shape)\n",
        "\n",
        "    x5 = self.one_one_one1(end)\n",
        "    print(x5.shape)\n",
        "\n",
        "    out = self.one_three_three(x5)\n",
        "    print(out.shape)\n",
        "    return out"
      ],
      "metadata": {
        "id": "5EfLQVgJ7r5n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 32, 64, 64, 64), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Block(32)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCTjnTjRKHJN",
        "outputId": "30319e56-6ccb-41e1-d54e-b6a8438ed32d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 32, 64, 64, 64])\n",
            "HDC_Block(\n",
            "  (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "  (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class HDC_Net(nn.Module):\n",
        "  def __init__(self, x):\n",
        "    super().__init__()\n",
        "    # self.pds = torch.nn.functional.interpolate(x)\n",
        "    self.conv1 = nn.Conv3d(in_channels=4, out_channels=32, kernel_size=3, padding=1, stride=1)\n",
        "    self.downsample = nn.Conv3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.HDC = HDC_Block(32)\n",
        "    self.upsample = nn.ConvTranspose3d(32, 32, kernel_size=2, stride=2)\n",
        "    self.upinterpolate = nn.Upsample(scale_factor=2, mode='trilinear')\n",
        "    self.conv2 = nn.Conv3d(in_channels=32, out_channels=3, kernel_size=1, stride=1)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    nimages, channels, width, height, depth = x.shape\n",
        "    print(nimages, channels, width, height, depth)\n",
        "    print(x.type)\n",
        "    # x1 = torch.tensor(scipy.ndimage.zoom(x, [1, 8.0, 0.5, 0.5, 0.5])) # using this function took about 2 minutes and for many images, it's not reasonable\n",
        "    x1 = torch.nn.functional.interpolate(x, scale_factor=[0.5, 0.5, 0.5]) # PDS - interpolate only looks at dim 2,3,4... (doesn't regard for channel and number of images)\n",
        "    # instead, I used torch.nn.functional.interpolate to interpolate the spatial dimensions, but for the channels I used a 1x1x1 conv\n",
        "    # because they did want to avoid using 3x3x3 conv and it will work same\n",
        "    print(x1.shape)\n",
        "    x1 = self.conv1(x1)\n",
        "    print(x1.shape)\n",
        "\n",
        "    x2 = self.HDC(x1)\n",
        "    print(x2.shape)\n",
        "    print()\n",
        "    x3 = self.downsample(x2)\n",
        "    print(x3.shape)\n",
        "\n",
        "    x4 = self.HDC(x3)\n",
        "    print(x4.shape)\n",
        "    print()\n",
        "    x5 = self.downsample(x4)\n",
        "    print(x5.shape)\n",
        "\n",
        "    x6 = self.HDC(x5)\n",
        "    print(x6.shape)\n",
        "    print()\n",
        "    x7 = self.downsample(x6)\n",
        "    print(x7.shape)\n",
        "\n",
        "    x8 = self.HDC(x7)\n",
        "    print(x8.shape)\n",
        "    print()\n",
        "\n",
        "    print(\"decoder time\")\n",
        "\n",
        "    x9 = self.upsample(x8)\n",
        "    print(x9.shape)\n",
        "    x10 = torch.add(x9, x6)\n",
        "    print(x10.shape)\n",
        "    x11 = self.HDC(x10)\n",
        "    print(x11.shape)\n",
        "\n",
        "    x12 = self.upsample(x11)\n",
        "    print(x12.shape)\n",
        "    x13 = torch.add(x12, x4)\n",
        "    print(x13.shape)\n",
        "    x14 = self.HDC(x13)\n",
        "    print(x14.shape)\n",
        "\n",
        "    x15 = self.upsample(x14)\n",
        "    print(x15.shape)\n",
        "    x16 = torch.add(x15, x2)\n",
        "    print(x16.shape)\n",
        "    x17 = self.HDC(x16)\n",
        "    print(x17.shape)\n",
        "\n",
        "    print(\"\\nupsampling\\n\") # by this they meant interpolation\n",
        "\n",
        "    x18 = self.upinterpolate(x17)\n",
        "    print(x18.shape)\n",
        "\n",
        "    x19 = self.conv2(x18)\n",
        "    print(x19.shape)\n",
        "\n",
        "    out = self.softmax(x19)\n",
        "    print(out.shape)\n",
        "\n",
        "    return x19, out"
      ],
      "metadata": {
        "id": "FnUEVd9i3bS8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(2, 4, 128, 128, 128), dtype=torch.float32)\n",
        "print(x.shape)\n",
        "\n",
        "model = HDC_Net(x)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Bf1ybX73Wjd",
        "outputId": "0a3d22a2-2e35-431a-b1fa-5f0f931c84a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 4, 128, 128, 128])\n",
            "HDC_Net(\n",
            "  (conv1): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (downsample): Conv3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (HDC): HDC_Block(\n",
            "    (one_one_one1): Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (three_three_one): Conv3d(8, 8, kernel_size=(3, 3, 1), stride=(1, 1, 1), padding=(1, 1, 0))\n",
            "    (one_three_three): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
            "  )\n",
            "  (upsample): ConvTranspose3d(32, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (upinterpolate): Upsample(scale_factor=2.0, mode=trilinear)\n",
            "  (conv2): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7efc191f3f50>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, probability = out"
      ],
      "metadata": {
        "id": "Z4lqjhQl9QRF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "id": "dX3XHUnj9SiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8249f8b-e01d-4e82-fd7c-06cbef33b668"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor([[[[[-0.1710, -0.1734, -0.1781,  ..., -0.1799, -0.1769, -0.1755],\n",
            "           [-0.1669, -0.1691, -0.1735,  ..., -0.1756, -0.1736, -0.1726],\n",
            "           [-0.1585, -0.1605, -0.1644,  ..., -0.1671, -0.1671, -0.1670],\n",
            "           ...,\n",
            "           [-0.1465, -0.1468, -0.1474,  ..., -0.1511, -0.1562, -0.1587],\n",
            "           [-0.1432, -0.1427, -0.1417,  ..., -0.1432, -0.1475, -0.1497],\n",
            "           [-0.1415, -0.1406, -0.1388,  ..., -0.1392, -0.1432, -0.1452]],\n",
            "\n",
            "          [[-0.1695, -0.1718, -0.1763,  ..., -0.1781, -0.1753, -0.1739],\n",
            "           [-0.1652, -0.1674, -0.1717,  ..., -0.1738, -0.1719, -0.1709],\n",
            "           [-0.1566, -0.1586, -0.1626,  ..., -0.1651, -0.1651, -0.1651],\n",
            "           ...,\n",
            "           [-0.1450, -0.1454, -0.1463,  ..., -0.1499, -0.1551, -0.1577],\n",
            "           [-0.1417, -0.1412, -0.1402,  ..., -0.1418, -0.1468, -0.1492],\n",
            "           [-0.1400, -0.1390, -0.1371,  ..., -0.1378, -0.1426, -0.1450]],\n",
            "\n",
            "          [[-0.1663, -0.1685, -0.1728,  ..., -0.1746, -0.1720, -0.1707],\n",
            "           [-0.1619, -0.1640, -0.1682,  ..., -0.1701, -0.1684, -0.1675],\n",
            "           [-0.1529, -0.1549, -0.1589,  ..., -0.1611, -0.1612, -0.1612],\n",
            "           ...,\n",
            "           [-0.1421, -0.1427, -0.1440,  ..., -0.1476, -0.1530, -0.1557],\n",
            "           [-0.1386, -0.1381, -0.1372,  ..., -0.1392, -0.1452, -0.1483],\n",
            "           [-0.1369, -0.1358, -0.1337,  ..., -0.1350, -0.1414, -0.1445]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.1584, -0.1608, -0.1654,  ..., -0.1686, -0.1663, -0.1652],\n",
            "           [-0.1547, -0.1569, -0.1615,  ..., -0.1656, -0.1638, -0.1630],\n",
            "           [-0.1471, -0.1493, -0.1535,  ..., -0.1596, -0.1589, -0.1586],\n",
            "           ...,\n",
            "           [-0.1409, -0.1414, -0.1424,  ..., -0.1463, -0.1521, -0.1551],\n",
            "           [-0.1368, -0.1365, -0.1358,  ..., -0.1376, -0.1443, -0.1477],\n",
            "           [-0.1348, -0.1340, -0.1325,  ..., -0.1333, -0.1404, -0.1440]],\n",
            "\n",
            "          [[-0.1557, -0.1578, -0.1620,  ..., -0.1645, -0.1635, -0.1630],\n",
            "           [-0.1527, -0.1547, -0.1587,  ..., -0.1620, -0.1615, -0.1613],\n",
            "           [-0.1467, -0.1486, -0.1523,  ..., -0.1570, -0.1577, -0.1580],\n",
            "           ...,\n",
            "           [-0.1412, -0.1422, -0.1440,  ..., -0.1479, -0.1525, -0.1548],\n",
            "           [-0.1367, -0.1367, -0.1366,  ..., -0.1388, -0.1446, -0.1475],\n",
            "           [-0.1345, -0.1339, -0.1328,  ..., -0.1343, -0.1407, -0.1439]],\n",
            "\n",
            "          [[-0.1544, -0.1563, -0.1602,  ..., -0.1624, -0.1621, -0.1619],\n",
            "           [-0.1517, -0.1536, -0.1574,  ..., -0.1602, -0.1604, -0.1605],\n",
            "           [-0.1465, -0.1482, -0.1517,  ..., -0.1557, -0.1571, -0.1578],\n",
            "           ...,\n",
            "           [-0.1414, -0.1425, -0.1449,  ..., -0.1486, -0.1526, -0.1546],\n",
            "           [-0.1367, -0.1368, -0.1369,  ..., -0.1394, -0.1448, -0.1475],\n",
            "           [-0.1343, -0.1339, -0.1330,  ..., -0.1348, -0.1409, -0.1439]]],\n",
            "\n",
            "\n",
            "         [[[-0.1027, -0.1029, -0.1031,  ..., -0.1027, -0.1015, -0.1009],\n",
            "           [-0.0992, -0.0992, -0.0991,  ..., -0.0994, -0.1007, -0.1013],\n",
            "           [-0.0922, -0.0918, -0.0912,  ..., -0.0928, -0.0991, -0.1022],\n",
            "           ...,\n",
            "           [-0.0940, -0.0951, -0.0973,  ..., -0.0992, -0.1057, -0.1090],\n",
            "           [-0.0964, -0.0987, -0.1031,  ..., -0.1074, -0.1139, -0.1172],\n",
            "           [-0.0976, -0.1004, -0.1061,  ..., -0.1114, -0.1180, -0.1213]],\n",
            "\n",
            "          [[-0.1026, -0.1029, -0.1034,  ..., -0.1022, -0.1011, -0.1005],\n",
            "           [-0.0990, -0.0991, -0.0993,  ..., -0.0990, -0.1003, -0.1010],\n",
            "           [-0.0916, -0.0914, -0.0911,  ..., -0.0926, -0.0989, -0.1020],\n",
            "           ...,\n",
            "           [-0.0924, -0.0935, -0.0957,  ..., -0.0975, -0.1042, -0.1076],\n",
            "           [-0.0949, -0.0971, -0.1015,  ..., -0.1056, -0.1125, -0.1159],\n",
            "           [-0.0962, -0.0989, -0.1044,  ..., -0.1097, -0.1166, -0.1201]],\n",
            "\n",
            "          [[-0.1025, -0.1030, -0.1040,  ..., -0.1013, -0.1003, -0.0999],\n",
            "           [-0.0985, -0.0989, -0.0996,  ..., -0.0982, -0.0997, -0.1005],\n",
            "           [-0.0905, -0.0907, -0.0909,  ..., -0.0920, -0.0984, -0.1016],\n",
            "           ...,\n",
            "           [-0.0892, -0.0903, -0.0927,  ..., -0.0940, -0.1013, -0.1049],\n",
            "           [-0.0919, -0.0940, -0.0983,  ..., -0.1022, -0.1096, -0.1134],\n",
            "           [-0.0933, -0.0959, -0.1011,  ..., -0.1063, -0.1138, -0.1176]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.1037, -0.1044, -0.1060,  ..., -0.1049, -0.1022, -0.1008],\n",
            "           [-0.0995, -0.1002, -0.1016,  ..., -0.1018, -0.1015, -0.1014],\n",
            "           [-0.0913, -0.0917, -0.0926,  ..., -0.0956, -0.1002, -0.1024],\n",
            "           ...,\n",
            "           [-0.0836, -0.0838, -0.0843,  ..., -0.0873, -0.0959, -0.1001],\n",
            "           [-0.0862, -0.0873, -0.0895,  ..., -0.0936, -0.1027, -0.1073],\n",
            "           [-0.0876, -0.0891, -0.0920,  ..., -0.0968, -0.1062, -0.1109]],\n",
            "\n",
            "          [[-0.1046, -0.1054, -0.1071,  ..., -0.1057, -0.1025, -0.1010],\n",
            "           [-0.1000, -0.1008, -0.1026,  ..., -0.1028, -0.1023, -0.1021],\n",
            "           [-0.0908, -0.0917, -0.0934,  ..., -0.0969, -0.1018, -0.1042],\n",
            "           ...,\n",
            "           [-0.0818, -0.0822, -0.0829,  ..., -0.0864, -0.0943, -0.0983],\n",
            "           [-0.0829, -0.0843, -0.0871,  ..., -0.0914, -0.1002, -0.1046],\n",
            "           [-0.0835, -0.0854, -0.0893,  ..., -0.0939, -0.1031, -0.1077]],\n",
            "\n",
            "          [[-0.1050, -0.1059, -0.1077,  ..., -0.1061, -0.1027, -0.1011],\n",
            "           [-0.1002, -0.1012, -0.1031,  ..., -0.1032, -0.1027, -0.1024],\n",
            "           [-0.0905, -0.0916, -0.0938,  ..., -0.0976, -0.1026, -0.1051],\n",
            "           ...,\n",
            "           [-0.0809, -0.0813, -0.0822,  ..., -0.0859, -0.0936, -0.0974],\n",
            "           [-0.0812, -0.0828, -0.0860,  ..., -0.0903, -0.0989, -0.1032],\n",
            "           [-0.0814, -0.0836, -0.0879,  ..., -0.0925, -0.1016, -0.1061]]],\n",
            "\n",
            "\n",
            "         [[[ 0.1003,  0.0985,  0.0948,  ...,  0.0885,  0.0816,  0.0781],\n",
            "           [ 0.0934,  0.0915,  0.0878,  ...,  0.0836,  0.0795,  0.0774],\n",
            "           [ 0.0795,  0.0776,  0.0740,  ...,  0.0739,  0.0753,  0.0760],\n",
            "           ...,\n",
            "           [ 0.0842,  0.0824,  0.0790,  ...,  0.0767,  0.0773,  0.0776],\n",
            "           [ 0.0988,  0.0957,  0.0895,  ...,  0.0867,  0.0859,  0.0856],\n",
            "           [ 0.1061,  0.1023,  0.0948,  ...,  0.0917,  0.0903,  0.0895]],\n",
            "\n",
            "          [[ 0.0992,  0.0976,  0.0944,  ...,  0.0889,  0.0829,  0.0799],\n",
            "           [ 0.0925,  0.0909,  0.0875,  ...,  0.0841,  0.0808,  0.0792],\n",
            "           [ 0.0792,  0.0773,  0.0737,  ...,  0.0745,  0.0767,  0.0778],\n",
            "           ...,\n",
            "           [ 0.0836,  0.0820,  0.0789,  ...,  0.0774,  0.0790,  0.0798],\n",
            "           [ 0.0988,  0.0957,  0.0896,  ...,  0.0870,  0.0870,  0.0871],\n",
            "           [ 0.1064,  0.1026,  0.0950,  ...,  0.0918,  0.0911,  0.0907]],\n",
            "\n",
            "          [[ 0.0971,  0.0960,  0.0937,  ...,  0.0898,  0.0855,  0.0834],\n",
            "           [ 0.0909,  0.0896,  0.0868,  ...,  0.0851,  0.0835,  0.0827],\n",
            "           [ 0.0786,  0.0767,  0.0730,  ...,  0.0757,  0.0794,  0.0813],\n",
            "           ...,\n",
            "           [ 0.0825,  0.0812,  0.0786,  ...,  0.0788,  0.0824,  0.0843],\n",
            "           [ 0.0988,  0.0958,  0.0897,  ...,  0.0876,  0.0892,  0.0901],\n",
            "           [ 0.1069,  0.1030,  0.0953,  ...,  0.0920,  0.0927,  0.0930]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 0.1006,  0.0999,  0.0986,  ...,  0.0941,  0.0900,  0.0880],\n",
            "           [ 0.0950,  0.0941,  0.0923,  ...,  0.0898,  0.0882,  0.0874],\n",
            "           [ 0.0839,  0.0825,  0.0798,  ...,  0.0811,  0.0844,  0.0861],\n",
            "           ...,\n",
            "           [ 0.0867,  0.0853,  0.0823,  ...,  0.0826,  0.0855,  0.0869],\n",
            "           [ 0.1021,  0.0988,  0.0921,  ...,  0.0911,  0.0919,  0.0924],\n",
            "           [ 0.1098,  0.1055,  0.0970,  ...,  0.0953,  0.0952,  0.0951]],\n",
            "\n",
            "          [[ 0.1031,  0.1026,  0.1017,  ...,  0.0981,  0.0933,  0.0909],\n",
            "           [ 0.0976,  0.0970,  0.0959,  ...,  0.0936,  0.0912,  0.0900],\n",
            "           [ 0.0866,  0.0858,  0.0842,  ...,  0.0847,  0.0870,  0.0882],\n",
            "           ...,\n",
            "           [ 0.0881,  0.0868,  0.0843,  ...,  0.0849,  0.0880,  0.0896],\n",
            "           [ 0.1031,  0.1003,  0.0947,  ...,  0.0937,  0.0946,  0.0950],\n",
            "           [ 0.1105,  0.1070,  0.1000,  ...,  0.0980,  0.0978,  0.0977]],\n",
            "\n",
            "          [[ 0.1043,  0.1040,  0.1032,  ...,  0.1001,  0.0949,  0.0924],\n",
            "           [ 0.0988,  0.0984,  0.0976,  ...,  0.0956,  0.0927,  0.0913],\n",
            "           [ 0.0879,  0.0874,  0.0864,  ...,  0.0865,  0.0883,  0.0892],\n",
            "           ...,\n",
            "           [ 0.0888,  0.0876,  0.0853,  ...,  0.0861,  0.0893,  0.0909],\n",
            "           [ 0.1035,  0.1010,  0.0961,  ...,  0.0949,  0.0959,  0.0963],\n",
            "           [ 0.1109,  0.1078,  0.1015,  ...,  0.0994,  0.0992,  0.0990]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[-0.1714, -0.1735, -0.1777,  ..., -0.1798, -0.1767, -0.1751],\n",
            "           [-0.1673, -0.1693, -0.1732,  ..., -0.1755, -0.1734, -0.1723],\n",
            "           [-0.1591, -0.1608, -0.1642,  ..., -0.1667, -0.1668, -0.1669],\n",
            "           ...,\n",
            "           [-0.1440, -0.1448, -0.1465,  ..., -0.1507, -0.1560, -0.1587],\n",
            "           [-0.1422, -0.1418, -0.1411,  ..., -0.1441, -0.1490, -0.1514],\n",
            "           [-0.1413, -0.1404, -0.1384,  ..., -0.1408, -0.1454, -0.1478]],\n",
            "\n",
            "          [[-0.1697, -0.1719, -0.1764,  ..., -0.1782, -0.1750, -0.1734],\n",
            "           [-0.1655, -0.1676, -0.1718,  ..., -0.1737, -0.1716, -0.1705],\n",
            "           [-0.1572, -0.1590, -0.1626,  ..., -0.1647, -0.1647, -0.1647],\n",
            "           ...,\n",
            "           [-0.1433, -0.1439, -0.1452,  ..., -0.1496, -0.1551, -0.1578],\n",
            "           [-0.1410, -0.1406, -0.1397,  ..., -0.1426, -0.1481, -0.1509],\n",
            "           [-0.1399, -0.1389, -0.1369,  ..., -0.1391, -0.1447, -0.1474]],\n",
            "\n",
            "          [[-0.1663, -0.1688, -0.1738,  ..., -0.1749, -0.1718, -0.1702],\n",
            "           [-0.1620, -0.1643, -0.1689,  ..., -0.1702, -0.1680, -0.1669],\n",
            "           [-0.1532, -0.1552, -0.1592,  ..., -0.1606, -0.1604, -0.1603],\n",
            "           ...,\n",
            "           [-0.1420, -0.1422, -0.1424,  ..., -0.1475, -0.1532, -0.1561],\n",
            "           [-0.1386, -0.1380, -0.1368,  ..., -0.1396, -0.1465, -0.1499],\n",
            "           [-0.1369, -0.1359, -0.1340,  ..., -0.1357, -0.1431, -0.1468]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.1591, -0.1615, -0.1663,  ..., -0.1683, -0.1664, -0.1655],\n",
            "           [-0.1548, -0.1573, -0.1622,  ..., -0.1650, -0.1639, -0.1633],\n",
            "           [-0.1462, -0.1488, -0.1539,  ..., -0.1583, -0.1589, -0.1591],\n",
            "           ...,\n",
            "           [-0.1406, -0.1410, -0.1417,  ..., -0.1459, -0.1515, -0.1544],\n",
            "           [-0.1374, -0.1366, -0.1349,  ..., -0.1377, -0.1438, -0.1469],\n",
            "           [-0.1358, -0.1344, -0.1315,  ..., -0.1336, -0.1399, -0.1431]],\n",
            "\n",
            "          [[-0.1565, -0.1584, -0.1621,  ..., -0.1638, -0.1634, -0.1632],\n",
            "           [-0.1529, -0.1549, -0.1589,  ..., -0.1613, -0.1614, -0.1615],\n",
            "           [-0.1455, -0.1478, -0.1524,  ..., -0.1562, -0.1574, -0.1580],\n",
            "           ...,\n",
            "           [-0.1412, -0.1421, -0.1439,  ..., -0.1481, -0.1522, -0.1543],\n",
            "           [-0.1369, -0.1367, -0.1364,  ..., -0.1392, -0.1447, -0.1475],\n",
            "           [-0.1348, -0.1341, -0.1327,  ..., -0.1348, -0.1410, -0.1441]],\n",
            "\n",
            "          [[-0.1553, -0.1568, -0.1600,  ..., -0.1615, -0.1619, -0.1621],\n",
            "           [-0.1519, -0.1537, -0.1572,  ..., -0.1594, -0.1601, -0.1605],\n",
            "           [-0.1451, -0.1473, -0.1516,  ..., -0.1552, -0.1566, -0.1574],\n",
            "           ...,\n",
            "           [-0.1415, -0.1426, -0.1449,  ..., -0.1493, -0.1526, -0.1542],\n",
            "           [-0.1367, -0.1368, -0.1372,  ..., -0.1400, -0.1452, -0.1478],\n",
            "           [-0.1343, -0.1339, -0.1333,  ..., -0.1354, -0.1415, -0.1446]]],\n",
            "\n",
            "\n",
            "         [[[-0.1040, -0.1039, -0.1037,  ..., -0.1015, -0.1007, -0.1003],\n",
            "           [-0.1000, -0.0999, -0.0995,  ..., -0.0981, -0.0997, -0.1005],\n",
            "           [-0.0921, -0.0918, -0.0912,  ..., -0.0911, -0.0977, -0.1010],\n",
            "           ...,\n",
            "           [-0.0938, -0.0947, -0.0966,  ..., -0.0990, -0.1057, -0.1090],\n",
            "           [-0.0962, -0.0985, -0.1031,  ..., -0.1072, -0.1139, -0.1173],\n",
            "           [-0.0974, -0.1004, -0.1064,  ..., -0.1113, -0.1181, -0.1214]],\n",
            "\n",
            "          [[-0.1033, -0.1033, -0.1034,  ..., -0.1012, -0.1004, -0.1000],\n",
            "           [-0.0994, -0.0994, -0.0993,  ..., -0.0980, -0.0995, -0.1003],\n",
            "           [-0.0916, -0.0914, -0.0910,  ..., -0.0915, -0.0977, -0.1008],\n",
            "           ...,\n",
            "           [-0.0924, -0.0933, -0.0951,  ..., -0.0972, -0.1042, -0.1077],\n",
            "           [-0.0947, -0.0969, -0.1014,  ..., -0.1056, -0.1126, -0.1161],\n",
            "           [-0.0958, -0.0987, -0.1046,  ..., -0.1098, -0.1168, -0.1203]],\n",
            "\n",
            "          [[-0.1018, -0.1021, -0.1029,  ..., -0.1005, -0.0997, -0.0993],\n",
            "           [-0.0981, -0.0983, -0.0989,  ..., -0.0978, -0.0991, -0.0997],\n",
            "           [-0.0906, -0.0907, -0.0908,  ..., -0.0924, -0.0978, -0.1005],\n",
            "           ...,\n",
            "           [-0.0897, -0.0905, -0.0922,  ..., -0.0936, -0.1012, -0.1051],\n",
            "           [-0.0917, -0.0938, -0.0980,  ..., -0.1023, -0.1100, -0.1138],\n",
            "           [-0.0927, -0.0954, -0.1009,  ..., -0.1067, -0.1144, -0.1182]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.1043, -0.1048, -0.1059,  ..., -0.1047, -0.1028, -0.1019],\n",
            "           [-0.0998, -0.1004, -0.1016,  ..., -0.1012, -0.1020, -0.1023],\n",
            "           [-0.0907, -0.0914, -0.0929,  ..., -0.0943, -0.1002, -0.1032],\n",
            "           ...,\n",
            "           [-0.0841, -0.0841, -0.0843,  ..., -0.0876, -0.0963, -0.1007],\n",
            "           [-0.0868, -0.0877, -0.0896,  ..., -0.0937, -0.1028, -0.1073],\n",
            "           [-0.0882, -0.0895, -0.0922,  ..., -0.0968, -0.1060, -0.1107]],\n",
            "\n",
            "          [[-0.1051, -0.1057, -0.1069,  ..., -0.1046, -0.1027, -0.1018],\n",
            "           [-0.1002, -0.1009, -0.1024,  ..., -0.1015, -0.1022, -0.1025],\n",
            "           [-0.0905, -0.0915, -0.0933,  ..., -0.0955, -0.1012, -0.1040],\n",
            "           ...,\n",
            "           [-0.0830, -0.0830, -0.0831,  ..., -0.0868, -0.0945, -0.0983],\n",
            "           [-0.0841, -0.0850, -0.0867,  ..., -0.0915, -0.1000, -0.1043],\n",
            "           [-0.0847, -0.0860, -0.0885,  ..., -0.0938, -0.1028, -0.1073]],\n",
            "\n",
            "          [[-0.1055, -0.1061, -0.1074,  ..., -0.1045, -0.1026, -0.1017],\n",
            "           [-0.1005, -0.1012, -0.1028,  ..., -0.1017, -0.1023, -0.1026],\n",
            "           [-0.0905, -0.0915, -0.0935,  ..., -0.0961, -0.1017, -0.1045],\n",
            "           ...,\n",
            "           [-0.0825, -0.0825, -0.0825,  ..., -0.0864, -0.0935, -0.0971],\n",
            "           [-0.0828, -0.0836, -0.0853,  ..., -0.0903, -0.0986, -0.1028],\n",
            "           [-0.0830, -0.0842, -0.0867,  ..., -0.0923, -0.1012, -0.1056]]],\n",
            "\n",
            "\n",
            "         [[[ 0.0998,  0.0982,  0.0950,  ...,  0.0884,  0.0816,  0.0782],\n",
            "           [ 0.0932,  0.0914,  0.0879,  ...,  0.0835,  0.0795,  0.0775],\n",
            "           [ 0.0800,  0.0779,  0.0739,  ...,  0.0737,  0.0752,  0.0760],\n",
            "           ...,\n",
            "           [ 0.0852,  0.0833,  0.0793,  ...,  0.0765,  0.0777,  0.0782],\n",
            "           [ 0.0990,  0.0960,  0.0899,  ...,  0.0866,  0.0854,  0.0848],\n",
            "           [ 0.1059,  0.1023,  0.0951,  ...,  0.0916,  0.0893,  0.0881]],\n",
            "\n",
            "          [[ 0.0988,  0.0973,  0.0944,  ...,  0.0890,  0.0830,  0.0800],\n",
            "           [ 0.0923,  0.0906,  0.0874,  ...,  0.0842,  0.0809,  0.0793],\n",
            "           [ 0.0792,  0.0773,  0.0733,  ...,  0.0745,  0.0767,  0.0778],\n",
            "           ...,\n",
            "           [ 0.0848,  0.0828,  0.0788,  ...,  0.0771,  0.0793,  0.0804],\n",
            "           [ 0.0991,  0.0960,  0.0898,  ...,  0.0870,  0.0867,  0.0865],\n",
            "           [ 0.1063,  0.1026,  0.0952,  ...,  0.0920,  0.0904,  0.0896]],\n",
            "\n",
            "          [[ 0.0968,  0.0956,  0.0933,  ...,  0.0903,  0.0858,  0.0836],\n",
            "           [ 0.0905,  0.0891,  0.0863,  ...,  0.0856,  0.0838,  0.0829],\n",
            "           [ 0.0778,  0.0760,  0.0723,  ...,  0.0762,  0.0797,  0.0815],\n",
            "           ...,\n",
            "           [ 0.0838,  0.0818,  0.0778,  ...,  0.0783,  0.0826,  0.0847],\n",
            "           [ 0.0992,  0.0960,  0.0896,  ...,  0.0879,  0.0893,  0.0900],\n",
            "           [ 0.1069,  0.1031,  0.0954,  ...,  0.0928,  0.0927,  0.0926]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 0.1007,  0.0999,  0.0981,  ...,  0.0960,  0.0908,  0.0881],\n",
            "           [ 0.0951,  0.0942,  0.0923,  ...,  0.0913,  0.0887,  0.0874],\n",
            "           [ 0.0839,  0.0829,  0.0808,  ...,  0.0817,  0.0845,  0.0859],\n",
            "           ...,\n",
            "           [ 0.0862,  0.0848,  0.0819,  ...,  0.0832,  0.0863,  0.0879],\n",
            "           [ 0.1018,  0.0986,  0.0924,  ...,  0.0915,  0.0927,  0.0933],\n",
            "           [ 0.1096,  0.1056,  0.0976,  ...,  0.0957,  0.0960,  0.0961]],\n",
            "\n",
            "          [[ 0.1029,  0.1026,  0.1020,  ...,  0.0989,  0.0935,  0.0908],\n",
            "           [ 0.0974,  0.0970,  0.0961,  ...,  0.0944,  0.0915,  0.0901],\n",
            "           [ 0.0864,  0.0857,  0.0842,  ...,  0.0854,  0.0876,  0.0887],\n",
            "           ...,\n",
            "           [ 0.0875,  0.0863,  0.0839,  ...,  0.0854,  0.0882,  0.0895],\n",
            "           [ 0.1026,  0.0998,  0.0942,  ...,  0.0933,  0.0945,  0.0952],\n",
            "           [ 0.1101,  0.1066,  0.0994,  ...,  0.0972,  0.0977,  0.0980]],\n",
            "\n",
            "          [[ 0.1040,  0.1040,  0.1040,  ...,  0.1003,  0.0948,  0.0921],\n",
            "           [ 0.0985,  0.0983,  0.0980,  ...,  0.0959,  0.0929,  0.0914],\n",
            "           [ 0.0877,  0.0871,  0.0859,  ...,  0.0872,  0.0891,  0.0901],\n",
            "           ...,\n",
            "           [ 0.0881,  0.0870,  0.0849,  ...,  0.0866,  0.0891,  0.0903],\n",
            "           [ 0.1030,  0.1004,  0.0952,  ...,  0.0942,  0.0954,  0.0961],\n",
            "           [ 0.1104,  0.1071,  0.1003,  ...,  0.0980,  0.0986,  0.0989]]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probability.shape)\n",
        "print(probability)"
      ],
      "metadata": {
        "id": "3NRhxzDM9Z8n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b14997b7-c4d0-4f8f-ce74-a63851419ba5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor([[[[[0.2956, 0.2954, 0.2949,  ..., 0.2951, 0.2964, 0.2971],\n",
            "           [0.2970, 0.2967, 0.2962,  ..., 0.2963, 0.2973, 0.2978],\n",
            "           [0.2997, 0.2994, 0.2989,  ..., 0.2985, 0.2990, 0.2992],\n",
            "           ...,\n",
            "           [0.3018, 0.3021, 0.3025,  ..., 0.3022, 0.3017, 0.3014],\n",
            "           [0.3011, 0.3017, 0.3031,  ..., 0.3035, 0.3033, 0.3032],\n",
            "           [0.3007, 0.3016, 0.3034,  ..., 0.3041, 0.3041, 0.3041]],\n",
            "\n",
            "          [[0.2961, 0.2958, 0.2953,  ..., 0.2954, 0.2966, 0.2972],\n",
            "           [0.2974, 0.2971, 0.2966,  ..., 0.2966, 0.2975, 0.2979],\n",
            "           [0.3000, 0.2998, 0.2994,  ..., 0.2989, 0.2992, 0.2994],\n",
            "           ...,\n",
            "           [0.3020, 0.3022, 0.3026,  ..., 0.3022, 0.3016, 0.3013],\n",
            "           [0.3012, 0.3019, 0.3032,  ..., 0.3036, 0.3032, 0.3030],\n",
            "           [0.3008, 0.3017, 0.3035,  ..., 0.3043, 0.3040, 0.3039]],\n",
            "\n",
            "          [[0.2970, 0.2967, 0.2961,  ..., 0.2960, 0.2969, 0.2974],\n",
            "           [0.2982, 0.2980, 0.2975,  ..., 0.2972, 0.2978, 0.2982],\n",
            "           [0.3008, 0.3006, 0.3002,  ..., 0.2995, 0.2997, 0.2998],\n",
            "           ...,\n",
            "           [0.3025, 0.3026, 0.3028,  ..., 0.3022, 0.3013, 0.3009],\n",
            "           [0.3016, 0.3022, 0.3036,  ..., 0.3037, 0.3030, 0.3026],\n",
            "           [0.3012, 0.3021, 0.3039,  ..., 0.3045, 0.3038, 0.3034]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.2983, 0.2980, 0.2973,  ..., 0.2971, 0.2978, 0.2981],\n",
            "           [0.2994, 0.2991, 0.2985,  ..., 0.2979, 0.2984, 0.2987],\n",
            "           [0.3014, 0.3012, 0.3007,  ..., 0.2996, 0.2998, 0.2999],\n",
            "           ...,\n",
            "           [0.3017, 0.3018, 0.3020,  ..., 0.3014, 0.3006, 0.3003],\n",
            "           [0.3010, 0.3016, 0.3027,  ..., 0.3029, 0.3022, 0.3019],\n",
            "           [0.3007, 0.3015, 0.3031,  ..., 0.3036, 0.3030, 0.3027]],\n",
            "\n",
            "          [[0.2987, 0.2984, 0.2978,  ..., 0.2975, 0.2980, 0.2982],\n",
            "           [0.2995, 0.2993, 0.2987,  ..., 0.2983, 0.2986, 0.2988],\n",
            "           [0.3012, 0.3010, 0.3005,  ..., 0.2998, 0.2999, 0.2999],\n",
            "           ...,\n",
            "           [0.3013, 0.3013, 0.3012,  ..., 0.3007, 0.3001, 0.2999],\n",
            "           [0.3006, 0.3011, 0.3020,  ..., 0.3021, 0.3016, 0.3013],\n",
            "           [0.3003, 0.3010, 0.3024,  ..., 0.3028, 0.3023, 0.3021]],\n",
            "\n",
            "          [[0.2989, 0.2986, 0.2980,  ..., 0.2978, 0.2981, 0.2983],\n",
            "           [0.2996, 0.2994, 0.2988,  ..., 0.2985, 0.2987, 0.2988],\n",
            "           [0.3011, 0.3009, 0.3004,  ..., 0.2999, 0.2999, 0.2999],\n",
            "           ...,\n",
            "           [0.3011, 0.3010, 0.3009,  ..., 0.3004, 0.2999, 0.2997],\n",
            "           [0.3004, 0.3009, 0.3017,  ..., 0.3017, 0.3013, 0.3011],\n",
            "           [0.3001, 0.3008, 0.3021,  ..., 0.3024, 0.3020, 0.3018]]],\n",
            "\n",
            "\n",
            "         [[[0.3165, 0.3170, 0.3178,  ..., 0.3189, 0.3197, 0.3201],\n",
            "           [0.3178, 0.3182, 0.3191,  ..., 0.3198, 0.3198, 0.3198],\n",
            "           [0.3202, 0.3207, 0.3217,  ..., 0.3216, 0.3200, 0.3193],\n",
            "           ...,\n",
            "           [0.3181, 0.3181, 0.3181,  ..., 0.3183, 0.3173, 0.3168],\n",
            "           [0.3155, 0.3153, 0.3150,  ..., 0.3146, 0.3137, 0.3132],\n",
            "           [0.3142, 0.3139, 0.3135,  ..., 0.3127, 0.3118, 0.3114]],\n",
            "\n",
            "          [[0.3166, 0.3169, 0.3176,  ..., 0.3187, 0.3194, 0.3198],\n",
            "           [0.3178, 0.3182, 0.3189,  ..., 0.3196, 0.3195, 0.3195],\n",
            "           [0.3202, 0.3206, 0.3215,  ..., 0.3214, 0.3197, 0.3189],\n",
            "           ...,\n",
            "           [0.3183, 0.3183, 0.3183,  ..., 0.3185, 0.3173, 0.3167],\n",
            "           [0.3156, 0.3155, 0.3152,  ..., 0.3148, 0.3138, 0.3133],\n",
            "           [0.3143, 0.3141, 0.3136,  ..., 0.3129, 0.3120, 0.3115]],\n",
            "\n",
            "          [[0.3166, 0.3168, 0.3173,  ..., 0.3185, 0.3190, 0.3192],\n",
            "           [0.3177, 0.3180, 0.3186,  ..., 0.3193, 0.3190, 0.3189],\n",
            "           [0.3201, 0.3205, 0.3213,  ..., 0.3209, 0.3191, 0.3182],\n",
            "           ...,\n",
            "           [0.3189, 0.3189, 0.3188,  ..., 0.3188, 0.3173, 0.3166],\n",
            "           [0.3160, 0.3159, 0.3156,  ..., 0.3152, 0.3140, 0.3133],\n",
            "           [0.3146, 0.3144, 0.3140,  ..., 0.3134, 0.3123, 0.3117]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3151, 0.3153, 0.3155,  ..., 0.3166, 0.3175, 0.3179],\n",
            "           [0.3163, 0.3165, 0.3169,  ..., 0.3175, 0.3176, 0.3177],\n",
            "           [0.3188, 0.3190, 0.3196,  ..., 0.3194, 0.3179, 0.3172],\n",
            "           ...,\n",
            "           [0.3195, 0.3197, 0.3200,  ..., 0.3197, 0.3181, 0.3172],\n",
            "           [0.3167, 0.3168, 0.3171,  ..., 0.3165, 0.3150, 0.3143],\n",
            "           [0.3152, 0.3154, 0.3156,  ..., 0.3149, 0.3135, 0.3129]],\n",
            "\n",
            "          [[0.3144, 0.3144, 0.3146,  ..., 0.3156, 0.3167, 0.3173],\n",
            "           [0.3158, 0.3158, 0.3160,  ..., 0.3165, 0.3169, 0.3170],\n",
            "           [0.3185, 0.3186, 0.3188,  ..., 0.3184, 0.3171, 0.3165],\n",
            "           ...,\n",
            "           [0.3197, 0.3199, 0.3202,  ..., 0.3198, 0.3181, 0.3173],\n",
            "           [0.3173, 0.3173, 0.3173,  ..., 0.3168, 0.3153, 0.3146],\n",
            "           [0.3160, 0.3160, 0.3159,  ..., 0.3153, 0.3139, 0.3132]],\n",
            "\n",
            "          [[0.3140, 0.3140, 0.3141,  ..., 0.3150, 0.3164, 0.3170],\n",
            "           [0.3155, 0.3155, 0.3155,  ..., 0.3160, 0.3165, 0.3167],\n",
            "           [0.3184, 0.3184, 0.3183,  ..., 0.3179, 0.3167, 0.3161],\n",
            "           ...,\n",
            "           [0.3199, 0.3200, 0.3203,  ..., 0.3198, 0.3181, 0.3173],\n",
            "           [0.3176, 0.3175, 0.3175,  ..., 0.3169, 0.3154, 0.3147],\n",
            "           [0.3164, 0.3163, 0.3160,  ..., 0.3154, 0.3141, 0.3134]]],\n",
            "\n",
            "\n",
            "         [[[0.3878, 0.3877, 0.3873,  ..., 0.3860, 0.3839, 0.3828],\n",
            "           [0.3852, 0.3851, 0.3847,  ..., 0.3840, 0.3829, 0.3824],\n",
            "           [0.3802, 0.3799, 0.3794,  ..., 0.3799, 0.3810, 0.3815],\n",
            "           ...,\n",
            "           [0.3801, 0.3799, 0.3794,  ..., 0.3795, 0.3810, 0.3818],\n",
            "           [0.3835, 0.3830, 0.3819,  ..., 0.3819, 0.3831, 0.3836],\n",
            "           [0.3852, 0.3845, 0.3832,  ..., 0.3831, 0.3841, 0.3845]],\n",
            "\n",
            "          [[0.3874, 0.3873, 0.3871,  ..., 0.3858, 0.3840, 0.3830],\n",
            "           [0.3848, 0.3847, 0.3844,  ..., 0.3838, 0.3830, 0.3826],\n",
            "           [0.3798, 0.3796, 0.3791,  ..., 0.3798, 0.3811, 0.3817],\n",
            "           ...,\n",
            "           [0.3796, 0.3794, 0.3790,  ..., 0.3793, 0.3811, 0.3820],\n",
            "           [0.3831, 0.3826, 0.3816,  ..., 0.3816, 0.3831, 0.3838],\n",
            "           [0.3849, 0.3842, 0.3828,  ..., 0.3828, 0.3840, 0.3846]],\n",
            "\n",
            "          [[0.3865, 0.3865, 0.3866,  ..., 0.3855, 0.3841, 0.3834],\n",
            "           [0.3840, 0.3840, 0.3839,  ..., 0.3835, 0.3831, 0.3830],\n",
            "           [0.3791, 0.3789, 0.3785,  ..., 0.3795, 0.3812, 0.3821],\n",
            "           ...,\n",
            "           [0.3786, 0.3785, 0.3783,  ..., 0.3790, 0.3813, 0.3825],\n",
            "           [0.3824, 0.3819, 0.3809,  ..., 0.3811, 0.3830, 0.3840],\n",
            "           [0.3843, 0.3836, 0.3821,  ..., 0.3821, 0.3839, 0.3848]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3865, 0.3867, 0.3872,  ..., 0.3863, 0.3848, 0.3840],\n",
            "           [0.3843, 0.3844, 0.3847,  ..., 0.3846, 0.3840, 0.3836],\n",
            "           [0.3798, 0.3798, 0.3797,  ..., 0.3811, 0.3823, 0.3830],\n",
            "           ...,\n",
            "           [0.3788, 0.3786, 0.3780,  ..., 0.3789, 0.3813, 0.3825],\n",
            "           [0.3823, 0.3816, 0.3802,  ..., 0.3807, 0.3828, 0.3838],\n",
            "           [0.3840, 0.3831, 0.3813,  ..., 0.3816, 0.3835, 0.3844]],\n",
            "\n",
            "          [[0.3869, 0.3872, 0.3876,  ..., 0.3869, 0.3853, 0.3844],\n",
            "           [0.3847, 0.3849, 0.3853,  ..., 0.3852, 0.3845, 0.3842],\n",
            "           [0.3803, 0.3804, 0.3807,  ..., 0.3818, 0.3830, 0.3836],\n",
            "           ...,\n",
            "           [0.3790, 0.3788, 0.3785,  ..., 0.3795, 0.3818, 0.3829],\n",
            "           [0.3821, 0.3816, 0.3806,  ..., 0.3812, 0.3831, 0.3841],\n",
            "           [0.3837, 0.3830, 0.3817,  ..., 0.3820, 0.3838, 0.3847]],\n",
            "\n",
            "          [[0.3871, 0.3874, 0.3879,  ..., 0.3872, 0.3855, 0.3847],\n",
            "           [0.3849, 0.3852, 0.3856,  ..., 0.3855, 0.3848, 0.3844],\n",
            "           [0.3806, 0.3808, 0.3812,  ..., 0.3822, 0.3833, 0.3839],\n",
            "           ...,\n",
            "           [0.3790, 0.3789, 0.3788,  ..., 0.3798, 0.3820, 0.3830],\n",
            "           [0.3820, 0.3816, 0.3809,  ..., 0.3814, 0.3833, 0.3842],\n",
            "           [0.3835, 0.3830, 0.3819,  ..., 0.3822, 0.3839, 0.3848]]]],\n",
            "\n",
            "\n",
            "\n",
            "        [[[[0.2958, 0.2955, 0.2950,  ..., 0.2951, 0.2964, 0.2971],\n",
            "           [0.2970, 0.2968, 0.2963,  ..., 0.2962, 0.2972, 0.2978],\n",
            "           [0.2995, 0.2993, 0.2990,  ..., 0.2985, 0.2989, 0.2991],\n",
            "           ...,\n",
            "           [0.3022, 0.3023, 0.3026,  ..., 0.3023, 0.3017, 0.3014],\n",
            "           [0.3012, 0.3019, 0.3032,  ..., 0.3033, 0.3031, 0.3029],\n",
            "           [0.3007, 0.3016, 0.3034,  ..., 0.3038, 0.3037, 0.3037]],\n",
            "\n",
            "          [[0.2962, 0.2959, 0.2953,  ..., 0.2953, 0.2966, 0.2972],\n",
            "           [0.2974, 0.2972, 0.2966,  ..., 0.2965, 0.2974, 0.2979],\n",
            "           [0.2999, 0.2997, 0.2994,  ..., 0.2988, 0.2992, 0.2994],\n",
            "           ...,\n",
            "           [0.3023, 0.3024, 0.3028,  ..., 0.3023, 0.3015, 0.3012],\n",
            "           [0.3013, 0.3020, 0.3033,  ..., 0.3034, 0.3030, 0.3027],\n",
            "           [0.3008, 0.3017, 0.3036,  ..., 0.3040, 0.3037, 0.3035]],\n",
            "\n",
            "          [[0.2969, 0.2966, 0.2959,  ..., 0.2958, 0.2969, 0.2974],\n",
            "           [0.2982, 0.2979, 0.2973,  ..., 0.2970, 0.2978, 0.2982],\n",
            "           [0.3008, 0.3006, 0.3002,  ..., 0.2996, 0.2998, 0.2998],\n",
            "           ...,\n",
            "           [0.3024, 0.3027, 0.3032,  ..., 0.3022, 0.3013, 0.3008],\n",
            "           [0.3015, 0.3022, 0.3036,  ..., 0.3036, 0.3028, 0.3023],\n",
            "           [0.3011, 0.3020, 0.3038,  ..., 0.3043, 0.3035, 0.3031]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.2982, 0.2979, 0.2972,  ..., 0.2969, 0.2977, 0.2981],\n",
            "           [0.2994, 0.2990, 0.2983,  ..., 0.2978, 0.2984, 0.2987],\n",
            "           [0.3016, 0.3012, 0.3005,  ..., 0.2996, 0.2998, 0.2998],\n",
            "           ...,\n",
            "           [0.3019, 0.3020, 0.3021,  ..., 0.3014, 0.3007, 0.3004],\n",
            "           [0.3010, 0.3016, 0.3029,  ..., 0.3028, 0.3022, 0.3019],\n",
            "           [0.3006, 0.3015, 0.3033,  ..., 0.3035, 0.3030, 0.3027]],\n",
            "\n",
            "          [[0.2986, 0.2983, 0.2977,  ..., 0.2975, 0.2980, 0.2983],\n",
            "           [0.2995, 0.2992, 0.2986,  ..., 0.2983, 0.2986, 0.2988],\n",
            "           [0.3014, 0.3011, 0.3005,  ..., 0.2998, 0.2998, 0.2998],\n",
            "           ...,\n",
            "           [0.3015, 0.3014, 0.3013,  ..., 0.3006, 0.3002, 0.3000],\n",
            "           [0.3008, 0.3012, 0.3021,  ..., 0.3020, 0.3016, 0.3013],\n",
            "           [0.3004, 0.3011, 0.3024,  ..., 0.3028, 0.3022, 0.3020]],\n",
            "\n",
            "          [[0.2988, 0.2985, 0.2980,  ..., 0.2978, 0.2982, 0.2984],\n",
            "           [0.2996, 0.2994, 0.2988,  ..., 0.2985, 0.2987, 0.2988],\n",
            "           [0.3014, 0.3011, 0.3005,  ..., 0.2998, 0.2998, 0.2998],\n",
            "           ...,\n",
            "           [0.3013, 0.3012, 0.3009,  ..., 0.3002, 0.2999, 0.2998],\n",
            "           [0.3006, 0.3010, 0.3017,  ..., 0.3017, 0.3012, 0.3010],\n",
            "           [0.3003, 0.3009, 0.3020,  ..., 0.3024, 0.3019, 0.3016]]],\n",
            "\n",
            "\n",
            "         [[[0.3164, 0.3168, 0.3176,  ..., 0.3191, 0.3198, 0.3202],\n",
            "           [0.3177, 0.3181, 0.3190,  ..., 0.3200, 0.3200, 0.3199],\n",
            "           [0.3202, 0.3207, 0.3216,  ..., 0.3219, 0.3203, 0.3195],\n",
            "           ...,\n",
            "           [0.3178, 0.3179, 0.3181,  ..., 0.3183, 0.3172, 0.3167],\n",
            "           [0.3154, 0.3152, 0.3149,  ..., 0.3147, 0.3139, 0.3134],\n",
            "           [0.3142, 0.3139, 0.3133,  ..., 0.3129, 0.3122, 0.3118]],\n",
            "\n",
            "          [[0.3165, 0.3169, 0.3176,  ..., 0.3189, 0.3196, 0.3199],\n",
            "           [0.3177, 0.3181, 0.3189,  ..., 0.3198, 0.3197, 0.3196],\n",
            "           [0.3202, 0.3207, 0.3216,  ..., 0.3215, 0.3199, 0.3191],\n",
            "           ...,\n",
            "           [0.3180, 0.3182, 0.3184,  ..., 0.3185, 0.3173, 0.3166],\n",
            "           [0.3156, 0.3155, 0.3151,  ..., 0.3149, 0.3139, 0.3134],\n",
            "           [0.3144, 0.3141, 0.3135,  ..., 0.3130, 0.3122, 0.3118]],\n",
            "\n",
            "          [[0.3167, 0.3170, 0.3176,  ..., 0.3186, 0.3190, 0.3193],\n",
            "           [0.3179, 0.3182, 0.3189,  ..., 0.3193, 0.3191, 0.3189],\n",
            "           [0.3202, 0.3206, 0.3215,  ..., 0.3208, 0.3191, 0.3183],\n",
            "           ...,\n",
            "           [0.3186, 0.3187, 0.3188,  ..., 0.3190, 0.3173, 0.3165],\n",
            "           [0.3160, 0.3159, 0.3156,  ..., 0.3152, 0.3140, 0.3134],\n",
            "           [0.3147, 0.3145, 0.3140,  ..., 0.3133, 0.3123, 0.3119]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3150, 0.3153, 0.3157,  ..., 0.3164, 0.3173, 0.3177],\n",
            "           [0.3163, 0.3165, 0.3169,  ..., 0.3174, 0.3175, 0.3175],\n",
            "           [0.3188, 0.3190, 0.3194,  ..., 0.3194, 0.3179, 0.3171],\n",
            "           ...,\n",
            "           [0.3194, 0.3196, 0.3200,  ..., 0.3195, 0.3178, 0.3169],\n",
            "           [0.3166, 0.3167, 0.3169,  ..., 0.3164, 0.3149, 0.3141],\n",
            "           [0.3152, 0.3153, 0.3154,  ..., 0.3148, 0.3134, 0.3127]],\n",
            "\n",
            "          [[0.3144, 0.3144, 0.3146,  ..., 0.3156, 0.3167, 0.3172],\n",
            "           [0.3157, 0.3158, 0.3160,  ..., 0.3166, 0.3168, 0.3169],\n",
            "           [0.3185, 0.3186, 0.3188,  ..., 0.3185, 0.3171, 0.3164],\n",
            "           ...,\n",
            "           [0.3196, 0.3198, 0.3202,  ..., 0.3196, 0.3180, 0.3172],\n",
            "           [0.3171, 0.3172, 0.3175,  ..., 0.3168, 0.3154, 0.3146],\n",
            "           [0.3158, 0.3159, 0.3161,  ..., 0.3154, 0.3140, 0.3133]],\n",
            "\n",
            "          [[0.3140, 0.3140, 0.3141,  ..., 0.3153, 0.3164, 0.3169],\n",
            "           [0.3154, 0.3155, 0.3155,  ..., 0.3162, 0.3165, 0.3167],\n",
            "           [0.3183, 0.3183, 0.3185,  ..., 0.3181, 0.3168, 0.3161],\n",
            "           ...,\n",
            "           [0.3196, 0.3199, 0.3203,  ..., 0.3197, 0.3182, 0.3174],\n",
            "           [0.3173, 0.3174, 0.3177,  ..., 0.3170, 0.3156, 0.3149],\n",
            "           [0.3161, 0.3162, 0.3164,  ..., 0.3157, 0.3143, 0.3136]]],\n",
            "\n",
            "\n",
            "         [[[0.3879, 0.3877, 0.3874,  ..., 0.3858, 0.3838, 0.3827],\n",
            "           [0.3854, 0.3851, 0.3847,  ..., 0.3838, 0.3828, 0.3823],\n",
            "           [0.3803, 0.3800, 0.3794,  ..., 0.3796, 0.3808, 0.3814],\n",
            "           ...,\n",
            "           [0.3800, 0.3798, 0.3793,  ..., 0.3794, 0.3811, 0.3819],\n",
            "           [0.3834, 0.3829, 0.3819,  ..., 0.3820, 0.3831, 0.3836],\n",
            "           [0.3851, 0.3845, 0.3833,  ..., 0.3833, 0.3841, 0.3845]],\n",
            "\n",
            "          [[0.3874, 0.3873, 0.3871,  ..., 0.3858, 0.3839, 0.3829],\n",
            "           [0.3849, 0.3847, 0.3844,  ..., 0.3837, 0.3829, 0.3825],\n",
            "           [0.3799, 0.3796, 0.3790,  ..., 0.3796, 0.3809, 0.3815],\n",
            "           ...,\n",
            "           [0.3797, 0.3794, 0.3788,  ..., 0.3792, 0.3812, 0.3822],\n",
            "           [0.3831, 0.3826, 0.3815,  ..., 0.3817, 0.3831, 0.3838],\n",
            "           [0.3848, 0.3842, 0.3829,  ..., 0.3830, 0.3841, 0.3847]],\n",
            "\n",
            "          [[0.3863, 0.3864, 0.3865,  ..., 0.3856, 0.3841, 0.3833],\n",
            "           [0.3839, 0.3838, 0.3838,  ..., 0.3836, 0.3831, 0.3828],\n",
            "           [0.3790, 0.3788, 0.3784,  ..., 0.3797, 0.3811, 0.3819],\n",
            "           ...,\n",
            "           [0.3790, 0.3786, 0.3779,  ..., 0.3788, 0.3814, 0.3827],\n",
            "           [0.3825, 0.3819, 0.3807,  ..., 0.3812, 0.3832, 0.3843],\n",
            "           [0.3842, 0.3835, 0.3822,  ..., 0.3824, 0.3842, 0.3851]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3867, 0.3869, 0.3871,  ..., 0.3867, 0.3850, 0.3842],\n",
            "           [0.3844, 0.3845, 0.3848,  ..., 0.3848, 0.3841, 0.3838],\n",
            "           [0.3796, 0.3798, 0.3800,  ..., 0.3809, 0.3824, 0.3831],\n",
            "           ...,\n",
            "           [0.3787, 0.3784, 0.3778,  ..., 0.3790, 0.3815, 0.3827],\n",
            "           [0.3823, 0.3816, 0.3802,  ..., 0.3808, 0.3829, 0.3839],\n",
            "           [0.3842, 0.3832, 0.3813,  ..., 0.3817, 0.3836, 0.3845]],\n",
            "\n",
            "          [[0.3870, 0.3873, 0.3877,  ..., 0.3869, 0.3853, 0.3845],\n",
            "           [0.3847, 0.3849, 0.3854,  ..., 0.3851, 0.3846, 0.3843],\n",
            "           [0.3801, 0.3803, 0.3807,  ..., 0.3817, 0.3830, 0.3837],\n",
            "           ...,\n",
            "           [0.3789, 0.3788, 0.3784,  ..., 0.3797, 0.3818, 0.3828],\n",
            "           [0.3822, 0.3816, 0.3804,  ..., 0.3811, 0.3831, 0.3841],\n",
            "           [0.3838, 0.3830, 0.3815,  ..., 0.3818, 0.3837, 0.3847]],\n",
            "\n",
            "          [[0.3872, 0.3875, 0.3880,  ..., 0.3869, 0.3854, 0.3847],\n",
            "           [0.3849, 0.3852, 0.3857,  ..., 0.3853, 0.3848, 0.3845],\n",
            "           [0.3804, 0.3806, 0.3811,  ..., 0.3821, 0.3834, 0.3840],\n",
            "           ...,\n",
            "           [0.3791, 0.3789, 0.3787,  ..., 0.3801, 0.3819, 0.3828],\n",
            "           [0.3821, 0.3816, 0.3806,  ..., 0.3813, 0.3832, 0.3841],\n",
            "           [0.3836, 0.3829, 0.3815,  ..., 0.3819, 0.3838, 0.3848]]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "KYmHvHW0gvIB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_images = []\n",
        "for i in range(2):\n",
        "  newx = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_images.append(newx)"
      ],
      "metadata": {
        "id": "lRm-uxBpgzku"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_images))\n",
        "print(randomized_training_images[0].shape)\n",
        "# print(randomized_training_images[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOFYVukkg0wi",
        "outputId": "53c7d1b9-a2bd-4ea0-9180-697aafb9e089"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_training_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "lLHd0_Jlg2D8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_training_segmentations))\n",
        "print(randomized_training_segmentations[0].shape)\n",
        "# print(randomized_training_segmentations[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-Lpq1Yeg3ta",
        "outputId": "36e23dd4-5243-4831-cb61-d90ab49249ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_training_data = list(zip(randomized_training_images, randomized_training_segmentations))"
      ],
      "metadata": {
        "id": "nO6zxE6rg48U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(dataset=randomized_training_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "tm7kwmsHg6F4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVib00lgg7UU",
        "outputId": "5b19c5e7-c4a2-4634-c245-c3cbf49fbec1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_images.append(newy)"
      ],
      "metadata": {
        "id": "0OhQ4jPeg9NF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_images))\n",
        "print(randomized_validation_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRQD263Dg_F-",
        "outputId": "a95bec6b-f715-4cf1-d39d-f41b88d35513"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_validation_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "gRq6qPWAhBSd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_validation_segmentations))\n",
        "print(randomized_validation_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsV3ZlvFhCrk",
        "outputId": "ac31b4d6-006a-4374-a507-2e815b84361b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_validation_data = list(zip(randomized_validation_images, randomized_validation_segmentations))"
      ],
      "metadata": {
        "id": "2jXVLmIvhDxh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validationloader = torch.utils.data.DataLoader(dataset=randomized_validation_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "-PjukyAkhFP3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(validationloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPI6wgumhGZA",
        "outputId": "e4595eff-c666-404d-8ead-bc2f91e18cd0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_images = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_images.append(newy)"
      ],
      "metadata": {
        "id": "ggGc5XCNhHu4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_images))\n",
        "print(randomized_testing_images[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VcPrDJhhJHS",
        "outputId": "08574eff-f49b-4d35-fb25-d8c06f10bff1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 4, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_segmentations = []\n",
        "for i in range(2):\n",
        "  newy = torch.rand(size=(1, 3, 128, 128, 128), dtype=torch.float32)\n",
        "  randomized_testing_segmentations.append(newy)"
      ],
      "metadata": {
        "id": "YKFnOHG0hKsv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(randomized_testing_segmentations))\n",
        "print(randomized_testing_segmentations[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wkfD4POhMQU",
        "outputId": "2dc0cac6-fae5-4cce-bc50-d06eb5fed706"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "randomized_testing_data = list(zip(randomized_testing_segmentations, randomized_testing_segmentations))"
      ],
      "metadata": {
        "id": "qnIpezVFhNt8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testingloader = torch.utils.data.DataLoader(dataset=randomized_testing_data, batch_size=2, shuffle=True) # batch size should be 10"
      ],
      "metadata": {
        "id": "zvIhDCEchQii"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Training + Validation:\n",
        "multi-class soft Dice function as the loss function\n",
        "\n",
        "Testing:\n",
        "mean accuracy\n",
        "dice coefficient\n",
        "hausdorff implementation\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "njyI0anWCXzA",
        "outputId": "f5524c6d-7f76-4df4-d8f9-cb6239ec75d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nTraining + Validation:\\nmulti-class soft Dice function as the loss function\\n\\nTesting:\\nmean accuracy\\ndice coefficient\\nhausdorff implementation\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# chose to make this a class because when you call dice loss in criterion, you don't have anything to input, but when u run the prediction through inside the training, then you have params\n",
        "# also because most sources I saw used a class\n",
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.smooth = 1\n",
        "  def forward(self, true, pred):\n",
        "    # flatten to easily do it pixel by pixel\n",
        "    true = true.view(-1)\n",
        "    pred = pred.view(-1)\n",
        "    numerator = 2*(true*pred).sum()\n",
        "    denominator = true.sum() + pred.sum()\n",
        "    dice_loss = 1 - (numerator + self.smooth) / (denominator + self.smooth)\n",
        "    return dice_loss"
      ],
      "metadata": {
        "id": "j1mhy3eKdCM9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim"
      ],
      "metadata": {
        "id": "kvtMJWXLgeJl"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs\n",
        "epochs = 2 # should be 800\n",
        "# loss\n",
        "criterion = DiceLoss()\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=10**-3, weight_decay=10**-5)"
      ],
      "metadata": {
        "id": "2__9J37GgnAq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_losses = []\n",
        "validation_losses = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  training_loss = 0\n",
        "  validation_loss = 0\n",
        "  print(\"training time\")\n",
        "  for images, segs in trainloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "\n",
        "    # arg_outputs = outputs.argmax(dim=1)\n",
        "    # print(arg_outputs.shape)\n",
        "    # print(arg_outputs)\n",
        "    # print(segs.shape)\n",
        "    print()\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    \n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    training_loss += loss.item()\n",
        "    print()\n",
        "  print(\"validation time\")\n",
        "  for images, segs in validationloader:\n",
        "    optimizer.zero_grad()\n",
        "    print(len(images), len(segs))\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    images = images.squeeze().clone().detach().requires_grad_(True)\n",
        "    # segs = segs.long() - no\n",
        "    segs = segs.squeeze().clone().detach().requires_grad_(True)\n",
        "    print(images.shape)\n",
        "    print(segs.shape)\n",
        "    outputs, softmax_outputs = model(images)\n",
        "    print(outputs.shape)\n",
        "    print(softmax_outputs.shape)\n",
        "    loss = criterion(softmax_outputs.float(), segs)\n",
        "    print(loss) # loss with random tensors will be really high because none of the tensors are related to each other\n",
        "    # loss can be > 1 - https://ai.stackexchange.com/questions/24685/can-the-sparse-categorical-cross-entropy-be-greater-than-one, https://stats.stackexchange.com/questions/392681/cross-entropy-loss-max-value\n",
        "    loss.backward()\n",
        "    validation_loss += loss.item()\n",
        "  training_losses.append(training_loss/len(trainloader))\n",
        "  validation_losses.append(validation_loss/len(validationloader))\n",
        "  print(\"Epoch: {}/{}... Training Loss: {}... Validation Loss: {}...\".format(i+1,epochs, training_losses[-1], validation_losses[-1]))\n",
        "  if validation_loss < min(validation_losses):\n",
        "    print(\"Validation loss has decreased...saving model\")\n",
        "    torch.save(model.state_dict(), \"fcn.pth\")\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F02PVic5gpXT",
        "outputId": "4525c8ae-205e-47bc-91a1-195e5d25e584"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7efc191b7530>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7efc191b7290>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "Epoch: 1/2... Training Loss: 0.6000197529792786... Validation Loss: 0.6000275015830994...\n",
            "\n",
            "training time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7efc18f7fa70>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "\n",
            "validation time\n",
            "2 2\n",
            "torch.Size([2, 1, 4, 128, 128, 128])\n",
            "torch.Size([2, 1, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 4, 128, 128, 128])\n",
            "2 4 128 128 128\n",
            "<built-in method type of Tensor object at 0x7efc191de950>\n",
            "torch.Size([2, 4, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "channel groups\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 8, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "torch.Size([2, 32, 8, 8, 8])\n",
            "\n",
            "decoder time\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "channel groups\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 8, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 16, 16, 16])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "channel groups\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 8, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 32, 32, 32])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "channel groups\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 8, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "torch.Size([2, 32, 64, 64, 64])\n",
            "\n",
            "upsampling\n",
            "\n",
            "torch.Size([2, 32, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "torch.Size([2, 3, 128, 128, 128])\n",
            "tensor(0.6000, grad_fn=<RsubBackward1>)\n",
            "Epoch: 2/2... Training Loss: 0.6000197529792786... Validation Loss: 0.6000275611877441...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_losses)\n",
        "print(validation_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0I2BsZrNHcj",
        "outputId": "19058e9d-6967-4b14-ac5e-91d2026286dc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6000197529792786, 0.6000197529792786]\n",
            "[0.6000275015830994, 0.6000275611877441]\n"
          ]
        }
      ]
    }
  ]
}