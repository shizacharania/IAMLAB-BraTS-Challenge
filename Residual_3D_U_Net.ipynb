{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Residual 3D U-Net.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_MbWzdtmbBU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules import conv\n",
        "class Layer1(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    # nn.Sequential doesn't work\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # block 1\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x2) # concatenate this before 2nd ReLU in res block\n",
        "    # print(x3.shape)\n",
        "\n",
        "    # block 2\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    x6 = self.relu(x5)\n",
        "    x7 = self.conv(x6)\n",
        "    x8 = self.instnorm(x7) # concatenate this before 2nd ReLU in res block\n",
        "    # print(x8.shape)\n",
        "\n",
        "    # element wise add\n",
        "    x9 = torch.add(x3, x8)\n",
        "\n",
        "    # relu\n",
        "    x10 = self.relu(x9)\n",
        "    return x10"
      ],
      "metadata": {
        "id": "7kCncP7WoiQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer2(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # block 1\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x2)\n",
        "\n",
        "    # block 2\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    x6 = self.relu(x5)\n",
        "    x7 = self.conv(x6)\n",
        "    x8 = self.instnorm(x7) # concat\n",
        "    x9 = torch.add(x8, x3)\n",
        "    x10 = self.relu(x9)\n",
        "    return x10"
      ],
      "metadata": {
        "id": "uXDYAroiRJ8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer3(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # block 1\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x2)\n",
        "\n",
        "    # block 2 x1\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    x6 = self.relu(x5)\n",
        "    x7 = self.conv(x6)\n",
        "    x8 = self.instnorm(x7) # concat\n",
        "    x9 = torch.add(x8, x3)\n",
        "    x10 = self.relu(x9)\n",
        "\n",
        "    # block 2 x2\n",
        "    x11 = self.conv(x10)\n",
        "    x12 = self.instnorm(x11)\n",
        "    x13 = self.relu(x12)\n",
        "    x14 = self.conv(x13)\n",
        "    x15 = self.instnorm(x14) # concat\n",
        "    x16 = torch.add(x10, x15)\n",
        "    x17 = self.relu(x16)\n",
        "    return x17"
      ],
      "metadata": {
        "id": "cjt8QRpBO80p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer4(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # block 1\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x2)\n",
        "\n",
        "    # block 2 x1\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    x6 = self.relu(x5)\n",
        "    x7 = self.conv(x6)\n",
        "    x8 = self.instnorm(x7) \n",
        "    x9 = torch.add(x8, x3)\n",
        "    x10 = self.relu(x9)\n",
        "\n",
        "    # block 2 x2\n",
        "    x11 = self.conv(x10)\n",
        "    x12 = self.instnorm(x11)\n",
        "    x13 = self.relu(x12)\n",
        "    x14 = self.conv(x13)\n",
        "    x15 = self.instnorm(x14)\n",
        "    x16 = torch.add(x10, x15)\n",
        "    x17 = self.relu(x16)\n",
        "\n",
        "    # block 2 x3\n",
        "    x18 = self.conv(x17)\n",
        "    x19 = self.instnorm(x18)\n",
        "    x20 = self.relu(x19)\n",
        "    x21 = self.conv(x20)\n",
        "    x22 = self.instnorm(x21)\n",
        "    x23 = torch.add(x17, x22)\n",
        "    x24 = self.relu(x23)\n",
        "    return x24"
      ],
      "metadata": {
        "id": "wyTA3AkiPopy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer5(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # block 1\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x2)\n",
        "\n",
        "    # block 2 x1\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    x6 = self.relu(x5)\n",
        "    x7 = self.conv(x6)\n",
        "    x8 = self.instnorm(x7) \n",
        "    x9 = torch.add(x8, x3)\n",
        "    x10 = self.relu(x9)\n",
        "\n",
        "    # block 2 x2\n",
        "    x11 = self.conv(x10)\n",
        "    x12 = self.instnorm(x11)\n",
        "    x13 = self.relu(x12)\n",
        "    x14 = self.conv(x13)\n",
        "    x15 = self.instnorm(x14)\n",
        "    x16 = torch.add(x10, x15)\n",
        "    x17 = self.relu(x16)\n",
        "\n",
        "    # block 2 x3\n",
        "    x18 = self.conv(x17)\n",
        "    x19 = self.instnorm(x18)\n",
        "    x20 = self.relu(x19)\n",
        "    x21 = self.conv(x20)\n",
        "    x22 = self.instnorm(x21)\n",
        "    x23 = torch.add(x17, x22)\n",
        "    x24 = self.relu(x23)\n",
        "\n",
        "    # block 2 x4\n",
        "    x25 = self.conv(x24)\n",
        "    x26 = self.instnorm(x25)\n",
        "    x27 = self.relu(x26)\n",
        "    x28 = self.conv(x27)\n",
        "    x29 = self.instnorm(x28)\n",
        "    x30 = torch.add(x24, x29)\n",
        "    x31 = self.relu(x30)\n",
        "    return x31"
      ],
      "metadata": {
        "id": "B0BUmRhkRshf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer6(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.conv = nn.Conv3d(in_channels=output_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # block 1\n",
        "    x1 = self.conv1(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x2)\n",
        "\n",
        "    # block 2 x1\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    x6 = self.relu(x5)\n",
        "    x7 = self.conv(x6)\n",
        "    x8 = self.instnorm(x7) \n",
        "    x9 = torch.add(x8, x3)\n",
        "    x10 = self.relu(x9)\n",
        "\n",
        "    # block 2 x2\n",
        "    x11 = self.conv(x10)\n",
        "    x12 = self.instnorm(x11)\n",
        "    x13 = self.relu(x12)\n",
        "    x14 = self.conv(x13)\n",
        "    x15 = self.instnorm(x14)\n",
        "    x16 = torch.add(x10, x15)\n",
        "    x17 = self.relu(x16)\n",
        "\n",
        "    # block 2 x3\n",
        "    x18 = self.conv(x17)\n",
        "    x19 = self.instnorm(x18)\n",
        "    x20 = self.relu(x19)\n",
        "    x21 = self.conv(x20)\n",
        "    x22 = self.instnorm(x21)\n",
        "    x23 = torch.add(x17, x22)\n",
        "    x24 = self.relu(x23)\n",
        "\n",
        "    # block 2 x4\n",
        "    x25 = self.conv(x24)\n",
        "    x26 = self.instnorm(x25)\n",
        "    x27 = self.relu(x26)\n",
        "    x28 = self.conv(x27)\n",
        "    x29 = self.instnorm(x28)\n",
        "    x30 = torch.add(x24, x29)\n",
        "    x31 = self.relu(x30)\n",
        "\n",
        "    # block 2 x5\n",
        "    x32 = self.conv(x31)\n",
        "    x33 = self.instnorm(x32)\n",
        "    x34 = self.relu(x33)\n",
        "    x35 = self.conv(x34)\n",
        "    x36 = self.instnorm(x35)\n",
        "    x37 = torch.add(x31, x36)\n",
        "    x38 = self.relu(x37)\n",
        "    return x38"
      ],
      "metadata": {
        "id": "B8f_Cz09Sxdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlockDecoder(nn.Module):\n",
        "  def __init__(self, input_channels, output_channels):\n",
        "    super().__init__()\n",
        "    self.transcov = nn.ConvTranspose3d(in_channels=input_channels, out_channels=input_channels, kernel_size=2, stride=2)\n",
        "    self.conv = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(output_channels)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "  def forward(self, x, concat_tensor):\n",
        "    x1 = self.transcov(x)\n",
        "    x2 = torch.add(x1, concat_tensor)\n",
        "    x3 = self.conv(x2)\n",
        "    x4 = self.instnorm(x3)\n",
        "    x5 = self.relu(x4)\n",
        "    return x5"
      ],
      "metadata": {
        "id": "6njHhcTiT8kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualUNet(nn.Module):\n",
        "  def __init__(self, input_shape):\n",
        "    super().__init__()\n",
        "    self.layer1 = Layer1(4, 24)\n",
        "    self.layer2 = Layer2(24, 48)\n",
        "    self.layer3 = Layer3(48, 96)\n",
        "    self.layer4 = Layer4(96, 192)\n",
        "    self.layer5 = Layer5(192, 320)\n",
        "    self.layer6 = Layer6(320, 320)\n",
        "    self.layer7 = ConvBlockDecoder(320, 192)\n",
        "    self.layer8 = ConvBlockDecoder(192, 96)\n",
        "    self.layer9 = ConvBlockDecoder(96, 48)\n",
        "    self.layer10 = ConvBlockDecoder(48, 24)\n",
        "    self.layer11 = ConvBlockDecoder(24, 24)\n",
        "    self.conv1x1x1 = nn.Conv3d(in_channels=24, out_channels=3, kernel_size=1, stride=1)\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x.shape) # [1, 4, 128, 128, 128]\n",
        "    x1 = self.layer1(x)\n",
        "    print(x1.shape) # [1, 24, 128, 128, 128]\n",
        "\n",
        "    x2 = self.layer2(x1)\n",
        "    print(x2.shape) # [1, 48, 64, 64, 64]\n",
        "\n",
        "    x3 = self.layer3(x2)\n",
        "    print(x3.shape) # [1, 96, 32, 32, 32]\n",
        "\n",
        "    x4 = self.layer4(x3)\n",
        "    print(x4.shape) # [1, 192, 16, 16, 16])\n",
        "\n",
        "    x5 = self.layer5(x4)\n",
        "    print(x5.shape) # [1, 320, 8, 8, 8]\n",
        "\n",
        "    x6 = self.layer6(x5)\n",
        "    print(x6.shape) # [1, 320, 4, 4, 4]\n",
        "\n",
        "    x7 = self.layer7(x6, x5)\n",
        "    print(x7.shape) # [1, 320, 4, 4, 4]\n",
        "\n",
        "    x8 = self.layer8(x7, x4)\n",
        "    print(x8.shape) # [1, 192, 8, 8, 8]\n",
        "\n",
        "    x9 = self.layer9(x8, x3)\n",
        "    print(x9.shape) # [1, 96, 16, 16, 16]\n",
        "\n",
        "    x10 = self.layer10(x9, x2)\n",
        "    print(x10.shape) # [1, 48, 32, 32, 32]\n",
        "\n",
        "    x11 = self.layer11(x10, x1)\n",
        "    print(x11.shape) # [1, 24, 64, 64, 64]\n",
        "\n",
        "    x12 = self.conv1x1x1(x11)\n",
        "    print(x12.shape) # [1, 24, 128, 128, 128]\n",
        "\n",
        "    prob = self.softmax(x12) # [1, 3, 128, 128, 128]\n",
        "\n",
        "    return x12, prob"
      ],
      "metadata": {
        "id": "tJpWDC3oRgAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(size=(1, 4, 128, 128, 128), dtype=torch.float32)\n",
        "# print(x.shape)\n",
        "\n",
        "model = ResidualUNet(x.shape)\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(x)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7zsz3sFtFMZ",
        "outputId": "ab128e03-1319-45dd-d8c0-400ef98c9c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResidualUNet(\n",
            "  (layer1): Layer1(\n",
            "    (conv1): Conv3d(4, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layer2): Layer2(\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layer3): Layer3(\n",
            "    (conv1): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layer4): Layer4(\n",
            "    (conv1): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layer5): Layer5(\n",
            "    (conv1): Conv3d(192, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layer6): Layer6(\n",
            "    (conv1): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  )\n",
            "  (layer7): ConvBlockDecoder(\n",
            "    (transcov): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv): Conv3d(320, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (layer8): ConvBlockDecoder(\n",
            "    (transcov): ConvTranspose3d(192, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (layer9): ConvBlockDecoder(\n",
            "    (transcov): ConvTranspose3d(96, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (layer10): ConvBlockDecoder(\n",
            "    (transcov): ConvTranspose3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (layer11): ConvBlockDecoder(\n",
            "    (transcov): ConvTranspose3d(24, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "    (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "  )\n",
            "  (conv1x1x1): Conv3d(24, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "torch.Size([1, 4, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 320, 8, 8, 8])\n",
            "torch.Size([1, 320, 4, 4, 4])\n",
            "torch.Size([1, 192, 8, 8, 8])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:57: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, probability = out"
      ],
      "metadata": {
        "id": "6uIe4jxJd_40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output.shape)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spnR9HzFelYy",
        "outputId": "206091b6-8edf-4e11-bfd9-431887ad18f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n",
            "tensor([[[[[ 0.3602,  0.1844,  0.3652,  ...,  0.1221,  0.5244,  0.3558],\n",
            "           [ 0.9086,  0.1166,  0.2256,  ...,  0.0929,  0.2228,  0.1085],\n",
            "           [ 0.4354,  0.1410,  0.3573,  ..., -0.1633,  0.5540,  0.2071],\n",
            "           ...,\n",
            "           [ 0.5004,  0.2470, -0.1720,  ...,  0.0800, -0.0228,  0.1403],\n",
            "           [ 0.0982,  0.5464,  0.3332,  ...,  0.6819,  0.0423,  0.2113],\n",
            "           [ 0.6684,  0.2299,  0.0670,  ...,  0.2828,  0.2991,  0.2259]],\n",
            "\n",
            "          [[ 0.2891,  0.1468,  0.7275,  ...,  0.4471,  0.4107,  0.1801],\n",
            "           [ 0.1449,  0.0174,  0.4402,  ...,  0.1534,  0.0289,  0.2174],\n",
            "           [-0.1998,  0.4861,  0.2981,  ..., -0.1011,  0.3637,  0.1635],\n",
            "           ...,\n",
            "           [-0.0254,  0.3631, -0.0889,  ...,  0.1321,  0.0576,  0.3282],\n",
            "           [-0.2441, -0.1029,  0.6604,  ...,  0.2950,  0.6670,  0.2430],\n",
            "           [ 0.1377, -0.2047,  0.1267,  ...,  0.1465,  0.0680, -0.0531]],\n",
            "\n",
            "          [[ 0.4591,  0.0387,  0.2690,  ...,  0.3396,  0.2336,  0.2287],\n",
            "           [ 0.3782,  0.3196,  0.2798,  ...,  0.1090, -0.3078,  0.1697],\n",
            "           [ 0.2653, -0.2909,  0.4318,  ...,  0.0571, -0.2479, -0.2327],\n",
            "           ...,\n",
            "           [ 0.0662, -0.2049, -0.0148,  ...,  0.5328,  0.5601,  0.5011],\n",
            "           [-0.0597, -0.4546,  0.6246,  ..., -0.0583,  0.6464,  0.4210],\n",
            "           [ 0.4225,  0.2439, -0.1439,  ...,  0.1428, -0.0213, -0.0049]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 0.4025,  0.0329,  0.2507,  ...,  0.2060,  0.6162, -0.0843],\n",
            "           [ 0.6623, -0.0044, -0.0755,  ...,  0.1409,  0.0371, -0.1059],\n",
            "           [-0.0748, -0.0155,  0.0582,  ..., -0.2211,  0.2459, -0.4106],\n",
            "           ...,\n",
            "           [-0.1259,  0.7637,  0.5049,  ..., -0.0262, -0.0878, -0.1863],\n",
            "           [ 0.3484,  0.0096,  0.1851,  ..., -0.6060,  0.7577, -0.1499],\n",
            "           [ 0.5481, -0.0425, -0.2891,  ...,  0.3217, -0.3866, -0.2521]],\n",
            "\n",
            "          [[ 0.4206,  0.1805,  0.0520,  ...,  0.7262,  0.2920,  0.0761],\n",
            "           [ 0.7140, -0.1018, -0.1736,  ...,  0.4260, -0.1912,  0.0384],\n",
            "           [ 0.5123, -0.0963,  0.3007,  ..., -0.0797, -0.2609, -0.4138],\n",
            "           ...,\n",
            "           [ 0.0442, -0.1822, -0.3037,  ...,  0.2727, -0.1194, -0.1698],\n",
            "           [ 0.0543,  0.2206,  0.3040,  ...,  0.1631,  0.0864,  0.0773],\n",
            "           [-0.0120, -0.0129,  0.2510,  ...,  0.0167, -0.0148, -0.0729]],\n",
            "\n",
            "          [[ 0.4326,  0.2644,  0.4136,  ...,  0.7253,  0.0332,  0.4416],\n",
            "           [ 0.1543,  0.3651,  0.6473,  ...,  0.1064,  0.3988,  0.6117],\n",
            "           [-0.1846,  0.1363,  0.1375,  ..., -0.2722,  0.4063,  0.1515],\n",
            "           ...,\n",
            "           [-0.1042,  0.0989,  0.8625,  ..., -0.0282,  0.0439,  0.4568],\n",
            "           [-0.0188,  0.6551,  0.6880,  ...,  0.5539,  0.0920,  0.2669],\n",
            "           [-0.1413,  0.2418, -0.0222,  ..., -0.1398,  0.1207,  0.1874]]],\n",
            "\n",
            "\n",
            "         [[[ 0.0437,  0.0258,  0.0433,  ...,  0.0895,  0.0840, -0.1096],\n",
            "           [-0.3250, -0.3335,  0.2568,  ...,  0.2463,  0.2762, -0.0910],\n",
            "           [-0.0974, -0.4259, -0.1813,  ...,  0.2405, -0.3991, -0.5221],\n",
            "           ...,\n",
            "           [-0.2427, -0.1102, -0.0092,  ..., -0.3681,  0.1291,  0.0620],\n",
            "           [-0.0789, -0.4879, -0.0245,  ..., -0.1891, -0.0275,  0.1164],\n",
            "           [-0.2795, -0.6111, -0.0118,  ..., -0.2980, -0.2563, -0.0246]],\n",
            "\n",
            "          [[-0.0583, -0.2906,  0.0339,  ..., -0.4190, -0.2790,  0.0940],\n",
            "           [-0.3598, -0.3109,  0.1029,  ...,  0.1524,  0.0069, -0.0592],\n",
            "           [-0.0118, -0.6362,  0.0987,  ..., -0.3972, -0.5024,  0.0234],\n",
            "           ...,\n",
            "           [ 0.1189, -0.7046,  0.0418,  ..., -0.1929, -0.6733, -0.0868],\n",
            "           [-0.0887, -0.0723, -0.0955,  ...,  0.2595, -0.3898,  0.3383],\n",
            "           [-0.1289, -0.3606, -0.2311,  ..., -0.2222, -0.7336,  0.2353]],\n",
            "\n",
            "          [[-0.0199, -0.5951, -0.2687,  ..., -0.2401, -0.0058, -0.0518],\n",
            "           [-0.1636, -0.1073, -0.1600,  ..., -0.2173,  0.0994, -0.0749],\n",
            "           [-0.0068,  0.0436, -0.2228,  ..., -0.6242, -0.3717, -0.3568],\n",
            "           ...,\n",
            "           [-0.0135, -0.2760,  0.0498,  ..., -0.3745, -0.5973, -0.4830],\n",
            "           [ 0.0966, -0.1903,  0.1171,  ...,  0.3632, -0.1862,  0.1335],\n",
            "           [-0.3072, -0.5541,  0.2451,  ..., -0.7326, -0.3411, -0.3305]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[-0.0571, -0.1853, -0.1733,  ..., -0.1291, -0.6403,  0.0534],\n",
            "           [-0.1371, -0.2625, -0.1311,  ..., -0.1595, -0.2601, -0.1972],\n",
            "           [-0.3978, -0.5814, -0.1302,  ..., -0.4223,  0.1421,  0.3845],\n",
            "           ...,\n",
            "           [-0.0855, -0.7545, -0.4740,  ..., -0.1088,  0.1553, -0.2870],\n",
            "           [-0.1460,  0.3635,  0.4483,  ...,  0.6887, -0.4194,  0.8295],\n",
            "           [-0.4090, -0.8065, -0.2588,  ..., -0.5068, -0.1756,  0.4305]],\n",
            "\n",
            "          [[-0.1537, -0.0110,  0.0200,  ..., -0.4710, -0.1128, -0.0357],\n",
            "           [-0.3746, -0.1082,  0.3111,  ..., -0.1248,  0.1516, -0.1832],\n",
            "           [-0.3396, -0.3083, -0.5165,  ..., -0.0535, -0.1790,  0.1214],\n",
            "           ...,\n",
            "           [-0.2589, -0.5375, -0.1949,  ...,  0.0555, -0.1375, -0.1594],\n",
            "           [ 0.0947, -0.3998, -0.1345,  ...,  0.0504, -0.2501,  0.0723],\n",
            "           [-0.1674, -0.4847, -0.4255,  ..., -0.2550, -0.6290,  0.4296]],\n",
            "\n",
            "          [[-0.1567, -0.2995, -0.3871,  ..., -0.7293, -0.1636, -0.3621],\n",
            "           [ 0.0583, -0.1359,  0.1131,  ...,  0.3817, -0.4346, -0.0382],\n",
            "           [ 0.1584, -0.2186, -0.1039,  ...,  0.4924, -0.1916,  0.0645],\n",
            "           ...,\n",
            "           [ 0.0826, -0.2543, -0.5677,  ...,  0.2094, -0.1833,  0.1686],\n",
            "           [ 0.2193, -0.4405, -0.0100,  ...,  0.0962, -0.0689,  0.2286],\n",
            "           [-0.2005, -0.6230, -0.0966,  ..., -0.0713, -0.4419,  0.0112]]],\n",
            "\n",
            "\n",
            "         [[[-0.2426, -0.1682, -0.3182,  ..., -0.3340, -0.3608, -0.3717],\n",
            "           [ 0.2881, -0.6233, -0.0307,  ..., -0.0583,  0.5026, -0.3293],\n",
            "           [ 0.2072, -0.6075, -0.2211,  ...,  0.5860, -0.2367, -0.9536],\n",
            "           ...,\n",
            "           [ 0.4969, -0.4757,  0.3242,  ..., -0.1964,  0.0021, -0.0867],\n",
            "           [-0.1178, -0.3513, -0.5699,  ..., -0.6737, -0.1139, -0.5605],\n",
            "           [-0.1028, -0.0396, -0.1742,  ..., -0.0022,  0.1896, -0.1823]],\n",
            "\n",
            "          [[ 0.0596,  0.2868,  0.5636,  ...,  0.2392,  0.0485, -0.0251],\n",
            "           [ 0.0294,  0.4980,  0.4682,  ...,  0.4833,  1.0370, -0.0512],\n",
            "           [-0.0082, -0.2798, -0.1517,  ..., -0.0476,  0.7459, -0.0898],\n",
            "           ...,\n",
            "           [ 0.8246, -0.0080,  0.6434,  ..., -0.5890,  0.4798,  0.1490],\n",
            "           [ 0.6324,  0.6003,  0.3693,  ...,  0.5980, -0.1092,  0.2091],\n",
            "           [ 0.0439,  0.0576,  0.8548,  ...,  0.5862, -0.2674,  0.0843]],\n",
            "\n",
            "          [[ 0.0158, -0.1978, -0.6093,  ..., -0.6881,  0.1203,  0.5058],\n",
            "           [ 0.1687, -0.1520, -0.6729,  ..., -0.2554,  0.2693, -0.1008],\n",
            "           [ 0.1260,  0.0294, -0.2620,  ..., -0.3455,  0.1595, -0.7174],\n",
            "           ...,\n",
            "           [ 0.3337, -0.2218, -0.1180,  ...,  0.4626,  0.0135, -0.8224],\n",
            "           [ 0.2913,  0.1695,  0.4872,  ...,  0.6121,  0.8704,  0.2601],\n",
            "           [ 0.1570, -0.2332,  0.5395,  ..., -0.4507, -0.3042, -0.2122]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[ 0.2038, -0.0140, -0.1937,  ...,  0.0244,  0.1935,  0.6845],\n",
            "           [ 0.0982,  0.0932,  0.2071,  ..., -0.4960,  0.7599,  0.1374],\n",
            "           [-0.3086, -0.2478,  0.0377,  ..., -0.0465,  1.2639,  0.5346],\n",
            "           ...,\n",
            "           [ 0.1012, -0.1232, -0.2937,  ..., -0.3205,  0.3119, -0.2622],\n",
            "           [ 0.4811, -0.2232,  0.3526,  ...,  1.3698,  1.1918,  0.3277],\n",
            "           [ 0.4081, -0.4863, -0.0914,  ...,  0.5591,  0.6067,  0.1646]],\n",
            "\n",
            "          [[ 0.1663, -0.3241,  0.2310,  ..., -0.3976, -0.1601,  0.1211],\n",
            "           [ 0.2721,  0.1607,  0.7427,  ...,  0.6989,  0.4531,  0.3796],\n",
            "           [ 0.0133, -0.0637, -0.6058,  ...,  0.0129,  0.4115,  0.6218],\n",
            "           ...,\n",
            "           [-0.0984, -0.2719,  0.4766,  ...,  1.2780,  0.3129,  0.4453],\n",
            "           [-0.0302,  0.9072,  0.5384,  ...,  0.3397,  0.5919,  0.1777],\n",
            "           [ 0.1959, -0.0473,  0.0057,  ...,  0.2050,  0.2473,  0.4038]],\n",
            "\n",
            "          [[-0.0633, -0.1077, -0.3070,  ..., -0.0717, -0.2194,  0.3715],\n",
            "           [ 0.1135, -0.1213,  0.3040,  ...,  1.0255,  0.2093,  0.6131],\n",
            "           [ 0.4224,  0.3367, -0.0807,  ...,  0.4378,  0.5656,  0.4454],\n",
            "           ...,\n",
            "           [ 0.1118,  0.4091,  0.2784,  ...,  0.0600,  0.1477,  0.5192],\n",
            "           [-0.0402,  0.7762,  0.0777,  ...,  0.8755,  0.6927,  0.3441],\n",
            "           [ 0.0874,  0.1143, -0.2120,  ...,  0.6035, -0.0093,  0.3452]]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(probability.shape)\n",
        "print(probability)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxBKEIIneFRa",
        "outputId": "2b3bf177-8d2c-4744-8e18-c415643779df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n",
            "tensor([[[[[0.4394, 0.3912, 0.4485,  ..., 0.3844, 0.4863, 0.4737],\n",
            "           [0.5468, 0.4729, 0.3564,  ..., 0.3305, 0.2961, 0.4057],\n",
            "           [0.4196, 0.4901, 0.4663,  ..., 0.2168, 0.5437, 0.5569],\n",
            "           ...,\n",
            "           [0.4045, 0.4576, 0.2618,  ..., 0.4171, 0.3136, 0.3674],\n",
            "           [0.3783, 0.5672, 0.4751,  ..., 0.5965, 0.3587, 0.4216],\n",
            "           [0.5406, 0.4556, 0.3690,  ..., 0.4326, 0.4048, 0.4093]],\n",
            "\n",
            "          [[0.3998, 0.3577, 0.4258,  ..., 0.4478, 0.4550, 0.3660],\n",
            "           [0.4009, 0.2996, 0.3647,  ..., 0.2950, 0.2119, 0.3964],\n",
            "           [0.2926, 0.5585, 0.4070,  ..., 0.3573, 0.3465, 0.3780],\n",
            "           ...,\n",
            "           [0.2225, 0.4917, 0.2370,  ..., 0.4528, 0.3326, 0.4006],\n",
            "           [0.2188, 0.2468, 0.4511,  ..., 0.3013, 0.5532, 0.3261],\n",
            "           [0.3736, 0.3169, 0.2652,  ..., 0.3083, 0.4622, 0.2872]],\n",
            "\n",
            "          [[0.4422, 0.4310, 0.5001,  ..., 0.5214, 0.3731, 0.3252],\n",
            "           [0.4179, 0.4393, 0.4926,  ..., 0.4139, 0.2335, 0.3928],\n",
            "           [0.3800, 0.2649, 0.4952,  ..., 0.4599, 0.2953, 0.4001],\n",
            "           ...,\n",
            "           [0.3096, 0.3431, 0.3368,  ..., 0.4281, 0.5282, 0.6098],\n",
            "           [0.2786, 0.2399, 0.4043,  ..., 0.2232, 0.3723, 0.3844],\n",
            "           [0.4447, 0.4829, 0.2244,  ..., 0.5079, 0.4032, 0.3945]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.4079, 0.3626, 0.4356,  ..., 0.3923, 0.5155, 0.2323],\n",
            "           [0.4954, 0.3478, 0.3056,  ..., 0.4406, 0.2629, 0.3137],\n",
            "           [0.3975, 0.4236, 0.3561,  ..., 0.3324, 0.2142, 0.1728],\n",
            "           ...,\n",
            "           [0.3034, 0.6131, 0.5477,  ..., 0.3751, 0.2655, 0.3532],\n",
            "           [0.3634, 0.3109, 0.2871,  ..., 0.0843, 0.3507, 0.1896],\n",
            "           [0.4438, 0.4745, 0.3078,  ..., 0.3697, 0.2026, 0.2224]],\n",
            "\n",
            "          [[0.4276, 0.4116, 0.3160,  ..., 0.6146, 0.4341, 0.3401],\n",
            "           [0.5052, 0.3036, 0.1952,  ..., 0.3460, 0.2318, 0.3117],\n",
            "           [0.4917, 0.3519, 0.5418,  ..., 0.3201, 0.2473, 0.1810],\n",
            "           ...,\n",
            "           [0.3838, 0.3824, 0.2327,  ..., 0.2204, 0.2839, 0.2590],\n",
            "           [0.3378, 0.2837, 0.3437,  ..., 0.3240, 0.2966, 0.3225],\n",
            "           [0.3239, 0.3861, 0.4365,  ..., 0.3368, 0.3520, 0.2345]],\n",
            "\n",
            "          [[0.4622, 0.4428, 0.5167,  ..., 0.5938, 0.3849, 0.4202],\n",
            "           [0.3486, 0.4503, 0.4356,  ..., 0.2073, 0.4421, 0.3963],\n",
            "           [0.2356, 0.3421, 0.3862,  ..., 0.1930, 0.3673, 0.3069],\n",
            "           ...,\n",
            "           [0.2901, 0.3262, 0.5565,  ..., 0.2976, 0.3441, 0.3554],\n",
            "           [0.3079, 0.4060, 0.4900,  ..., 0.3320, 0.2721, 0.3287],\n",
            "           [0.3125, 0.4345, 0.3629,  ..., 0.2396, 0.4085, 0.3323]]],\n",
            "\n",
            "\n",
            "         [[[0.3202, 0.3338, 0.3251,  ..., 0.3720, 0.3131, 0.2974],\n",
            "           [0.1592, 0.3015, 0.3677,  ..., 0.3853, 0.3123, 0.3324],\n",
            "           [0.2463, 0.2780, 0.2721,  ..., 0.3246, 0.2096, 0.2686],\n",
            "           ...,\n",
            "           [0.1924, 0.3202, 0.3081,  ..., 0.2665, 0.3650, 0.3398],\n",
            "           [0.3169, 0.2016, 0.3323,  ..., 0.2497, 0.3345, 0.3835],\n",
            "           [0.2095, 0.1965, 0.3411,  ..., 0.2420, 0.2323, 0.3186]],\n",
            "\n",
            "          [[0.2824, 0.2309, 0.2128,  ..., 0.1884, 0.2283, 0.3358],\n",
            "           [0.2420, 0.2158, 0.2603,  ..., 0.2947, 0.2073, 0.3006],\n",
            "           [0.3531, 0.1818, 0.3334,  ..., 0.2657, 0.1457, 0.3286],\n",
            "           ...,\n",
            "           [0.2570, 0.1690, 0.2701,  ..., 0.3271, 0.1601, 0.2645],\n",
            "           [0.2556, 0.2545, 0.2118,  ..., 0.2908, 0.1923, 0.3587],\n",
            "           [0.2862, 0.2712, 0.1855,  ..., 0.2132, 0.2073, 0.3833]],\n",
            "\n",
            "          [[0.2739, 0.2287, 0.2921,  ..., 0.2920, 0.2937, 0.2457],\n",
            "           [0.2431, 0.2866, 0.3174,  ..., 0.2986, 0.3508, 0.3075],\n",
            "           [0.2894, 0.3702, 0.2573,  ..., 0.2327, 0.2609, 0.3534],\n",
            "           ...,\n",
            "           [0.2859, 0.3195, 0.3593,  ..., 0.1728, 0.1660, 0.2279],\n",
            "           [0.3257, 0.3124, 0.2434,  ..., 0.3403, 0.1619, 0.2883],\n",
            "           [0.2144, 0.2174, 0.3311,  ..., 0.2116, 0.2929, 0.2849]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.2576, 0.2915, 0.2851,  ..., 0.2806, 0.1467, 0.2666],\n",
            "           [0.2227, 0.2687, 0.2891,  ..., 0.3263, 0.1953, 0.2863],\n",
            "           [0.2878, 0.2406, 0.2950,  ..., 0.2718, 0.1931, 0.3826],\n",
            "           ...,\n",
            "           [0.3159, 0.1343, 0.2058,  ..., 0.3454, 0.3385, 0.3194],\n",
            "           [0.2217, 0.4428, 0.3735,  ..., 0.3077, 0.1081, 0.5048],\n",
            "           [0.1704, 0.2210, 0.3172,  ..., 0.1615, 0.2502, 0.4402]],\n",
            "\n",
            "          [[0.2408, 0.3399, 0.3061,  ..., 0.1856, 0.2896, 0.3041],\n",
            "           [0.1701, 0.3017, 0.3169,  ..., 0.1995, 0.3266, 0.2498],\n",
            "           [0.2098, 0.2846, 0.2393,  ..., 0.3286, 0.2684, 0.3091],\n",
            "           ...,\n",
            "           [0.2834, 0.2680, 0.2595,  ..., 0.1774, 0.2788, 0.2618],\n",
            "           [0.3518, 0.1526, 0.2217,  ..., 0.2894, 0.2118, 0.3209],\n",
            "           [0.2773, 0.2409, 0.2219,  ..., 0.2567, 0.1905, 0.3877]],\n",
            "\n",
            "          [[0.2564, 0.2520, 0.2320,  ..., 0.1386, 0.3161, 0.1881],\n",
            "           [0.3167, 0.2728, 0.2553,  ..., 0.2730, 0.1921, 0.2069],\n",
            "           [0.3320, 0.2399, 0.3033,  ..., 0.4145, 0.2020, 0.2813],\n",
            "           ...,\n",
            "           [0.3497, 0.2291, 0.1332,  ..., 0.3774, 0.2742, 0.2664],\n",
            "           [0.3907, 0.1357, 0.2438,  ..., 0.2101, 0.2317, 0.3163],\n",
            "           [0.2946, 0.1830, 0.3369,  ..., 0.2566, 0.2327, 0.2786]]],\n",
            "\n",
            "\n",
            "         [[[0.2405, 0.2750, 0.2264,  ..., 0.2436, 0.2006, 0.2289],\n",
            "           [0.2940, 0.2256, 0.2758,  ..., 0.2841, 0.3917, 0.2619],\n",
            "           [0.3340, 0.2319, 0.2615,  ..., 0.4586, 0.2466, 0.1745],\n",
            "           ...,\n",
            "           [0.4031, 0.2222, 0.4300,  ..., 0.3164, 0.3214, 0.2928],\n",
            "           [0.3048, 0.2311, 0.1926,  ..., 0.1538, 0.3068, 0.1949],\n",
            "           [0.2500, 0.3479, 0.2899,  ..., 0.3253, 0.3629, 0.2721]],\n",
            "\n",
            "          [[0.3178, 0.4114, 0.3614,  ..., 0.3638, 0.3167, 0.2981],\n",
            "           [0.3571, 0.4846, 0.3750,  ..., 0.4103, 0.5808, 0.3030],\n",
            "           [0.3543, 0.2597, 0.2596,  ..., 0.3769, 0.5078, 0.2934],\n",
            "           ...,\n",
            "           [0.5205, 0.3392, 0.4929,  ..., 0.2201, 0.5073, 0.3349],\n",
            "           [0.5256, 0.4987, 0.3371,  ..., 0.4079, 0.2546, 0.3152],\n",
            "           [0.3402, 0.4120, 0.5493,  ..., 0.4785, 0.3305, 0.3295]],\n",
            "\n",
            "          [[0.2839, 0.3403, 0.2078,  ..., 0.1866, 0.3332, 0.4291],\n",
            "           [0.3390, 0.2741, 0.1900,  ..., 0.2875, 0.4158, 0.2997],\n",
            "           [0.3306, 0.3649, 0.2474,  ..., 0.3075, 0.4438, 0.2464],\n",
            "           ...,\n",
            "           [0.4046, 0.3374, 0.3038,  ..., 0.3991, 0.3058, 0.1623],\n",
            "           [0.3957, 0.4477, 0.3524,  ..., 0.4365, 0.4658, 0.3273],\n",
            "           [0.3410, 0.2997, 0.4445,  ..., 0.2805, 0.3039, 0.3206]],\n",
            "\n",
            "          ...,\n",
            "\n",
            "          [[0.3344, 0.3459, 0.2793,  ..., 0.3271, 0.3378, 0.5011],\n",
            "           [0.2818, 0.3835, 0.4054,  ..., 0.2331, 0.5417, 0.4000],\n",
            "           [0.3147, 0.3358, 0.3489,  ..., 0.3958, 0.5928, 0.4446],\n",
            "           ...,\n",
            "           [0.3807, 0.2526, 0.2465,  ..., 0.2795, 0.3960, 0.3274],\n",
            "           [0.4150, 0.2463, 0.3394,  ..., 0.6080, 0.5413, 0.3056],\n",
            "           [0.3858, 0.3044, 0.3750,  ..., 0.4688, 0.5471, 0.3374]],\n",
            "\n",
            "          [[0.3316, 0.2485, 0.3779,  ..., 0.1998, 0.2763, 0.3557],\n",
            "           [0.3247, 0.3947, 0.4879,  ..., 0.4546, 0.4416, 0.4385],\n",
            "           [0.2985, 0.3635, 0.2189,  ..., 0.3512, 0.4844, 0.5099],\n",
            "           ...,\n",
            "           [0.3328, 0.3496, 0.5078,  ..., 0.6022, 0.4374, 0.4792],\n",
            "           [0.3104, 0.5637, 0.4345,  ..., 0.3866, 0.4916, 0.3566],\n",
            "           [0.3988, 0.3730, 0.3416,  ..., 0.4066, 0.4575, 0.3778]],\n",
            "\n",
            "          [[0.2815, 0.3052, 0.2513,  ..., 0.2676, 0.2990, 0.3917],\n",
            "           [0.3347, 0.2769, 0.3090,  ..., 0.5197, 0.3658, 0.3968],\n",
            "           [0.4323, 0.4180, 0.3105,  ..., 0.3925, 0.4307, 0.4118],\n",
            "           ...,\n",
            "           [0.3601, 0.4447, 0.3103,  ..., 0.3250, 0.3817, 0.3783],\n",
            "           [0.3014, 0.4583, 0.2662,  ..., 0.4579, 0.4962, 0.3550],\n",
            "           [0.3929, 0.3825, 0.3002,  ..., 0.5038, 0.3587, 0.3891]]]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    }
  ]
}