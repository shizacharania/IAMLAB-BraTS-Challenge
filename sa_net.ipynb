{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch # import torch modules\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "98_y6CHWgje0"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResSE_Block(nn.Module): # resSE block as the foundation of encoder and decoder blocks\n",
        "  def __init__(self, input_channels, size):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv3d(in_channels=input_channels, out_channels=input_channels, kernel_size=3, stride=1, padding=1)\n",
        "    self.instnorm = nn.InstanceNorm3d(num_features=4) #n features = channels\n",
        "    self.relu = nn.ReLU()\n",
        "    # add variables for SE\n",
        "    self.globalpooling = torch.nn.AvgPool3d(kernel_size=size)\n",
        "    self.input_channels = input_channels\n",
        "    self.fclayer1 = nn.Linear(in_features=input_channels, out_features=input_channels//4, bias=True) # reduces channels by reduction ratio\n",
        "    self.fclayer2 = nn.Linear(in_features=input_channels//4, out_features=input_channels, bias=True) # expands channels back\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # print(x.shape)\n",
        "    # print(\"\\nGoing to ResSE\")\n",
        "\n",
        "    # residual block\n",
        "    x1 = self.conv(x)\n",
        "    x2 = self.instnorm(x1)\n",
        "    x3 = self.relu(x1)\n",
        "    x4 = self.conv(x3)\n",
        "    x5 = self.instnorm(x4)\n",
        "    # print(\"x5\")\n",
        "    print(x5.shape)\n",
        "\n",
        "    # the SE module\n",
        "    x6 = self.globalpooling(x5) # global pooling layer to decrease spatial dimensions\n",
        "    # print(x6.shape)\n",
        "\n",
        "    x7 = x6.view(1, -1) # you need to view it in [1, x] format so it can go through an fc layer in pytorch (https://stackoverflow.com/questions/65945996/1d-cnn-on-pytorch-mat1-and-mat2-shapes-cannot-be-multiplied-10x3-and-10x2)\n",
        "    # print(x7.shape)\n",
        "\n",
        "    x7 = self.fclayer1(x7) # reduce channel\n",
        "    # print(x7.shape)\n",
        "    x8 = self.relu(x7)\n",
        "    # print(x8.shape)\n",
        "    x9 = self.fclayer2(x8) # increase channel\n",
        "    # print(x9.shape)\n",
        "    x10 = self.sigmoid(x9)\n",
        "    # print(x10.shape)\n",
        "\n",
        "    # scale - basically you go through the layers with [1, x] because it needs that format\n",
        "    # but then for scaling, you first need to add two extra dimensions in end (so it's same size/has the same number of dimensions as the input for SE module)\n",
        "    x11 = x10.view(1, self.input_channels, 1, 1, 1) # basically the size you want it to be - channels stays the same\n",
        "    # print(x11.shape)\n",
        "\n",
        "    # multiply the weights by the channels\n",
        "    x12 = torch.multiply(x5, x11) # e.x. [1, 24, 1, 1, 1] and [1, 24, 128, 128, 128]\n",
        "    # (number of batches and channels for which you need to multiply each weight to the channel, so should be same #)\n",
        "    # print(x12.shape)\n",
        "\n",
        "    # summation and then ReLU\n",
        "    x13 = torch.add(x12, x)\n",
        "    # print(x13.shape)\n",
        "    x14 = self.relu(x13)\n",
        "    print(x14.shape)\n",
        "    # print(\"Done ResSE\\n\")\n",
        "    \n",
        "    return x14 # returns output"
      ],
      "metadata": {
        "id": "WCSJf-NrjKT5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test ResSE_Block class with first block\n",
        "\n",
        "input = torch.randn((1, 24,128,128,128), dtype=torch.float)\n",
        "\n",
        "trial = ResSE_Block(input_channels=24, size=128)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ix1w-GAbXjR",
        "outputId": "6e7a2802-3cc0-4133-80e8-6431761edb82"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResSE_Block(\n",
            "  (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (globalpooling): AvgPool3d(kernel_size=128, stride=128, padding=0)\n",
            "  (fclayer1): Linear(in_features=24, out_features=6, bias=True)\n",
            "  (fclayer2): Linear(in_features=6, out_features=24, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test ResSE_Block class\n",
        "\n",
        "input = torch.randn((1, 48, 96, 96, 96), dtype=torch.float)\n",
        "trial = ResSE_Block(input_channels=48, size=96)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukTdZD0ejFa-",
        "outputId": "1856ccb5-ebb8-453a-e79c-979f291bfe54"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResSE_Block(\n",
            "  (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "  (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (globalpooling): AvgPool3d(kernel_size=96, stride=96, padding=0)\n",
            "  (fclayer1): Linear(in_features=48, out_features=12, bias=True)\n",
            "  (fclayer2): Linear(in_features=12, out_features=48, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n",
            "\n",
            "torch.Size([1, 48, 96, 96, 96])\n",
            "torch.Size([1, 48, 96, 96, 96])\n",
            "torch.Size([1, 48, 96, 96, 96])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3cwjFdqCff93"
      },
      "outputs": [],
      "source": [
        "class EncoderBlock(nn.Module): # if input is x, y, y, y --> output should be x*2, y/2, y/2, y/2 (except first and last block)\n",
        "  def __init__(self, n_blocks, input_channels, output_channels, size):\n",
        "    super().__init__()\n",
        "    self.resSEblock = ResSE_Block(input_channels, size)\n",
        "    self.downsample = nn.Conv3d(in_channels=input_channels, out_channels=output_channels, kernel_size=3, stride=2, padding=1)\n",
        "    self.n_blocks = n_blocks\n",
        "  def forward(self, x, downsample_bool):\n",
        "    # print(x.shape)\n",
        "    # print(x1.shape)\n",
        "    if self.n_blocks==1:\n",
        "      x1 = self.resSEblock(x)\n",
        "      # print(\" 1 downsample \")\n",
        "      # print(\"\\noutput of encoder block\")\n",
        "      if (downsample_bool==True):\n",
        "        x2 = self.downsample(x1)\n",
        "        return x1, x2\n",
        "        # print(x2.shape)\n",
        "        # print()\n",
        "      return x1, x1\n",
        "    else:\n",
        "      # print(\"side case x shape\")\n",
        "      # print(x.shape)\n",
        "      x1 = self.resSEblock(x)\n",
        "      # print(\"after first res\")\n",
        "      x2 = self.resSEblock(x1)\n",
        "      # print(\"\\noutput of encoder block\")\n",
        "      x3 = self.downsample(x2)\n",
        "      # print(x3.shape)\n",
        "      print()\n",
        "      return x2, x3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test encoder block with first block\n",
        "input = torch.randn((1, 24,128,128,128), dtype=torch.float)\n",
        "\n",
        "trial = EncoderBlock(n_blocks=1, input_channels=24, output_channels=48, size=128) # 1st encoder block\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, True)"
      ],
      "metadata": {
        "id": "WGRRVrUqkyeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd3e3492-4780-4e0e-afda-70037920c2aa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderBlock(\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=128, stride=128, padding=0)\n",
            "    (fclayer1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fclayer2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (downsample): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# last block\n",
        "input = torch.randn((1, 384,8,8,8), dtype=torch.float)\n",
        "\n",
        "trial = EncoderBlock(n_blocks=1, input_channels=384, output_channels=384, size=8)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, False)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzjP4R_8togA",
        "outputId": "d601eda0-0005-4793-be27-cfad0f3ba5e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EncoderBlock(\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=8, stride=8, padding=0)\n",
            "    (fclayer1): Linear(in_features=384, out_features=96, bias=True)\n",
            "    (fclayer2): Linear(in_features=96, out_features=384, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (downsample): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
            ")\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block1(nn.Module): # first scale attention block for the last decoding block\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 24x128x128x128\n",
        "    self.conv_initial1 = nn.Conv3d(in_channels=48, out_channels=24, kernel_size=1, stride=1) # conv for decreasing s2 channels\n",
        "    self.conv_initial2 = nn.Conv3d(in_channels=96, out_channels=24, kernel_size=1, stride=1) # conv for decreasing s3 channels\n",
        "    self.conv_initial3 = nn.Conv3d(in_channels=192, out_channels=24, kernel_size=1, stride=1) # conv for decreasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=24, out_features=6) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=6, out_features=24) # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1) # softmax for channels\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s1.shape[1] # number of channels we're working with \n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # decreasing channels using Conv3D\n",
        "    s2 = self.conv_initial1(s2) \n",
        "    s3 = self.conv_initial2(s3)\n",
        "    s4 = self.conv_initial3(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s2 = self.instancenorm(s2)\n",
        "    s3 = self.instancenorm(s3)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s2 = self.relu(s2)\n",
        "    s3 = self.relu(s3)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # trilinear upsampling for scales 2, 3, 4 (their spatial sizes - w, h, l)\n",
        "    s2 = torch.nn.functional.interpolate(s2, size=(128,128,128), mode='trilinear')\n",
        "    s3 = torch.nn.functional.interpolate(s3, size=(128,128,128), mode='trilinear')\n",
        "    s4 = torch.nn.functional.interpolate(s4, size=(128,128,128), mode='trilinear')\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales \n",
        "    p1 = s1 + s2 + s3 +s4\n",
        "    print(p1.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G1 = self.global_avg_pooling(p1)\n",
        "    print(G1.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G1 = G1.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G1.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g1 = self.fcn1(G1)\n",
        "    print(g1.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g1)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    # softmax\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g1)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g1)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g1)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S11 = torch.multiply(E1, s1)\n",
        "    w2_S12 = torch.multiply(E2, s2)\n",
        "    w3_S13 = torch.multiply(E3, s3)\n",
        "    w4_S14 = torch.multiply(E4, s4)\n",
        "    print(w1_S11.shape)\n",
        "    print(w2_S12.shape)\n",
        "    print(w3_S13.shape)\n",
        "    print(w4_S14.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S11 + w2_S12 + w3_S13 + w4_S14\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "4J5quBz5Z2Oz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test SA_Block1\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block1()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1qeVFZRd1W1",
        "outputId": "5fb2709e-448f-4fae-e598-545b5ab2c25b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block1(\n",
            "  (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "  (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 48x64x64x64\n",
        "    self.maxpool_initial1 = nn.MaxPool3d(kernel_size=2, stride=2) # maxpooling for first scale (reduce spatial size)\n",
        "    self.conv1 = nn.Conv3d(in_channels=24, out_channels=48, kernel_size=1, stride=1) # conv for increasing s1 channels\n",
        "    self.conv_initial3 = nn.Conv3d(in_channels=96, out_channels=48, kernel_size=1, stride=1) # conv for decreasing s3 channels\n",
        "    self.conv_initial4 = nn.Conv3d(in_channels=192, out_channels=48, kernel_size=1, stride=1) # conv for decreasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=48, out_features=12) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=12, out_features=48) # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1) # softmax for channels\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s2.shape[1]\n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # increasing spatial sizes of scale 1\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    # increasing spatial sizes of scale 1 (2 times)\n",
        "    s1 = self.conv1(s1) # increasing channels for scale 1\n",
        "    s3 = self.conv_initial3(s3) # decreasing channels for scale 3\n",
        "    s4 = self.conv_initial4(s4) # decreasing channels for scale 4\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s1 = self.instancenorm(s1)\n",
        "    s3 = self.instancenorm(s3)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s1 = self.relu(s1)\n",
        "    s3 = self.relu(s3)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # trilinear upsampling for scales 3 and 4 (their spatial sizes - w, h, l)\n",
        "    s3 = torch.nn.functional.interpolate(s3, size=(64,64,64), mode='trilinear')\n",
        "    s4 = torch.nn.functional.interpolate(s4, size=(64,64,64), mode='trilinear')\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales\n",
        "    p2 = s1 + s2 + s3 +s4\n",
        "    print(p2.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G2 = self.global_avg_pooling(p2)\n",
        "    print(G2.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G2 = G2.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G2.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g2 = self.fcn1(G2)\n",
        "    print(g2.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g2)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g2)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g2)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g2)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S21 = torch.multiply(E1, s1)\n",
        "    w2_S22 = torch.multiply(E2, s2)\n",
        "    w3_S23 = torch.multiply(E3, s3)\n",
        "    w4_S24 = torch.multiply(E4, s4)\n",
        "    print(w1_S21.shape)\n",
        "    print(w2_S22.shape)\n",
        "    print(w3_S23.shape)\n",
        "    print(w4_S24.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S21 + w2_S22 + w3_S23 + w4_S24\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "3cTIUj3b9hVj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test SA_Block2\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block2()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjZJwu6u_B-1",
        "outputId": "ff4e4706-0546-445f-8bc2-f8d274241c70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block2(\n",
            "  (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "  (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block3(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 96x32x32x32\n",
        "    self.maxpool_initial1 = nn.MaxPool3d(kernel_size=2, stride=2) # maxpooling for 1st and 2nd scale (reduce spatial size)\n",
        "    self.conv1 = nn.Conv3d(in_channels=24, out_channels=96, kernel_size=1, stride=1) # conv for increasing s1 channels\n",
        "    self.conv2 = nn.Conv3d(in_channels=48, out_channels=96, kernel_size=1, stride=1) # conv for increasing s2 channels\n",
        "    self.conv_initial4 = nn.Conv3d(in_channels=192, out_channels=96, kernel_size=1, stride=1) # conv for decreasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=96, out_features=24) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=24, out_features=96)  # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # softmax for channels\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s3.shape[1]\n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # increasing spatial sizes of scale 1 (2 times)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    # increasing channels for scale 1\n",
        "    s1 = self.conv1(s1)\n",
        "    # increasing spatial sizes of scale 2\n",
        "    s2 = self.maxpool_initial1(s2)\n",
        "    # increasing channels for scale 2\n",
        "    s2 = self.conv2(s2)\n",
        "    s4 = self.conv_initial4(s4) # decreasing channels for scale 4\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s1 = self.instancenorm(s1)\n",
        "    s2 = self.instancenorm(s2)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s1 = self.relu(s1)\n",
        "    s2 = self.relu(s2)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # trilinear upsampling for scales 3 and 4 (their spatial sizes - w, h, l)\n",
        "    s4 = torch.nn.functional.interpolate(s4, size=(32,32,32), mode='trilinear')\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales\n",
        "    p3 = s1 + s2 + s3 +s4\n",
        "    print(p3.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G3 = self.global_avg_pooling(p3)\n",
        "    print(G3.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G3 = G3.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G3.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g3 = self.fcn1(G3)\n",
        "    print(g3.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g3)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    # softmax\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g3)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g3)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g3)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S31 = torch.multiply(E1, s1)\n",
        "    w2_S32 = torch.multiply(E2, s2)\n",
        "    w3_S33 = torch.multiply(E3, s3)\n",
        "    w4_S34 = torch.multiply(E4, s4)\n",
        "    print(w1_S31.shape)\n",
        "    print(w2_S32.shape)\n",
        "    print(w3_S33.shape)\n",
        "    print(w4_S34.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S31 + w2_S32 + w3_S33 + w4_S34\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "AW2EDDBTEJ9g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test SA_Block3\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block3()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p47_b-BrGvRg",
        "outputId": "61baf482-8763-4de8-e653-a69e9fc84d45"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block3(\n",
            "  (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "  (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Block4(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # target is 192x16x16x16\n",
        "    self.maxpool_initial1 = nn.MaxPool3d(kernel_size=2, stride=2) # maxpooling for scale 1,2,3 (reduce spatial size)\n",
        "    self.conv1 = nn.Conv3d(in_channels=24, out_channels=192, kernel_size=1, stride=1) # conv for increasing s2 channels\n",
        "    self.conv2 = nn.Conv3d(in_channels=48, out_channels=192, kernel_size=1, stride=1) # conv for increasing s3 channels\n",
        "    self.conv3 = nn.Conv3d(in_channels=96, out_channels=192, kernel_size=1, stride=1) # conv for increasing s4 channels\n",
        "\n",
        "    self.instancenorm = nn.InstanceNorm3d(24)\n",
        "    self.relu = nn.ReLU()\n",
        "\n",
        "    self.global_avg_pooling = nn.AdaptiveAvgPool3d(1) # global pooling to make each channel one value\n",
        "    self.fcn1 = nn.Linear(in_features=192, out_features=48) # first linear layer to reduce channel size by ratio\n",
        "\n",
        "    self.fcn2 = nn.Linear(in_features=48, out_features=192) # second linear layer to increase channel size by ratio\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    # softmax for channels\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    \n",
        "  def forward(self, s1, s2, s3, s4):\n",
        "    channels = s4.shape[1]\n",
        "    print(\"channels: \" + str(channels) + \"\\n\")\n",
        "\n",
        "    # increasing spatial sizes of scale 1 (3 times)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.maxpool_initial1(s1)\n",
        "    s1 = self.conv1(s1)\n",
        "\n",
        "    # increasing spatial sizes of scale 2 (2 times)\n",
        "    s2 = self.maxpool_initial1(s2)\n",
        "    s2 = self.maxpool_initial1(s2)\n",
        "    s2 = self.conv2(s2)\n",
        "\n",
        "    # increasing spatial sizes of scale 3\n",
        "    s3 = self.maxpool_initial1(s3)\n",
        "    s3 = self.conv3(s3)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # instance normalization \n",
        "    s1 = self.instancenorm(s1)\n",
        "    s2 = self.instancenorm(s2)\n",
        "    s4 = self.instancenorm(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # relu\n",
        "    s1 = self.relu(s1)\n",
        "    s2 = self.relu(s2)\n",
        "    s4 = self.relu(s4)\n",
        "\n",
        "    print(s1.shape)\n",
        "    print(s2.shape)\n",
        "    print(s3.shape)\n",
        "    print(s4.shape)\n",
        "    print()\n",
        "\n",
        "    # summation of all scales\n",
        "    p4 = s1 + s2 + s3 +s4\n",
        "    print(p4.shape)\n",
        "\n",
        "    # global pooling layer\n",
        "    G4 = self.global_avg_pooling(p4)\n",
        "    print(G4.shape)\n",
        "    print()\n",
        "\n",
        "    # take out the last two dimensions of [1, x, 1, 1]\n",
        "    G4 = G4.view(1, -1) # -1 means it adjusts itself\n",
        "    print(G4.shape)\n",
        "    print()\n",
        "\n",
        "    # first fully connected layer\n",
        "    g4 = self.fcn1(G4)\n",
        "    print(g4.shape)\n",
        "    print()\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E1 = self.fcn2(g4)\n",
        "    E1 = self.sigmoid(E1)\n",
        "    # softmax\n",
        "    E1 = self.softmax(E1)\n",
        "    print(E1.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E2 = self.fcn2(g4)\n",
        "    E2 = self.sigmoid(E2)\n",
        "    # softmax\n",
        "    E2 = self.softmax(E2)\n",
        "    print(E2.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E3 = self.fcn2(g4)\n",
        "    E3 = self.sigmoid(E3)\n",
        "    # softmax\n",
        "    E3 = self.softmax(E3)\n",
        "    print(E3.shape)\n",
        "\n",
        "    # second fully connected layer + sigmoid\n",
        "    E4 = self.fcn2(g4)\n",
        "    E4 = self.sigmoid(E4)\n",
        "    # softmax\n",
        "    E4 = self.softmax(E4)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # add the last 2 dimensions so there's the same amount of dimensions in the E and the beginning scale (for multiplication later)\n",
        "    E1 = E1.view(1, channels, 1, 1, 1)\n",
        "    E2 = E2.view(1, channels, 1, 1, 1)\n",
        "    E3 = E3.view(1, channels, 1, 1, 1)\n",
        "    E4 = E4.view(1, channels, 1, 1, 1)\n",
        "    print(E1.shape)\n",
        "    print(E2.shape)\n",
        "    print(E3.shape)\n",
        "    print(E4.shape)\n",
        "    print()\n",
        "\n",
        "    # multiply the weights for the channels with the channels in all the scales\n",
        "    w1_S41 = torch.multiply(E1, s1)\n",
        "    w2_S42 = torch.multiply(E2, s2)\n",
        "    w3_S43 = torch.multiply(E3, s3)\n",
        "    w4_S44 = torch.multiply(E4, s4)\n",
        "    print(w1_S41.shape)\n",
        "    print(w2_S42.shape)\n",
        "    print(w3_S43.shape)\n",
        "    print(w4_S44.shape)\n",
        "    print()\n",
        "\n",
        "    # adding all the scales with weighted channels\n",
        "    output = w1_S41 + w2_S42 + w3_S43 + w4_S44\n",
        "    print(output.shape)\n",
        "    return output"
      ],
      "metadata": {
        "id": "oUXyxyT8Iap1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "model = SA_Block4()\n",
        "\n",
        "print(model)\n",
        "print()\n",
        "\n",
        "out = model(s1, s2, s3, s4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxvsjyotI8iI",
        "outputId": "e0c513c2-94de-4206-f198-b5364e0ca45c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SA_Block4(\n",
            "  (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "  (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "  (relu): ReLU()\n",
            "  (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "  (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "  (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "  (sigmoid): Sigmoid()\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBlock(nn.Module): # note: also contains sa block \n",
        "  def __init__(self, input_channels, output_channels, size):\n",
        "    super().__init__()\n",
        "    self.upsample = nn.ConvTranspose3d(in_channels=input_channels, out_channels=output_channels, kernel_size=2, stride=2)\n",
        "    # ^for the upsampling, conv transpose is not the same thing as conv. if you do kernel size of 3 and stride of 2 with this (i.e. what the paper said),\n",
        "    # then the output is an odd number. so, i just made the kernel size = 2 and stride = 2, but still increased the channels by 2 times\n",
        "    self.resSEblock = ResSE_Block(output_channels, size)\n",
        "    self.sa_block1 = SA_Block1()\n",
        "    self.sa_block2 = SA_Block2()\n",
        "    self.sa_block3 = SA_Block3()\n",
        "    self.sa_block4 = SA_Block4()\n",
        "\n",
        "  def forward(self, x, s1, s2, s3, s4, number_scale):\n",
        "    print(x.shape)\n",
        "    # depending on the scale, pick the class for the scale attention block\n",
        "    if number_scale == 1:\n",
        "      x1 = self.sa_block1(s1, s2, s3, s4)\n",
        "    elif number_scale == 2:\n",
        "      x1 = self.sa_block2(s1, s2, s3, s4)\n",
        "    elif number_scale == 3:\n",
        "      x1 = self.sa_block3(s1, s2, s3, s4)\n",
        "    elif number_scale == 4:\n",
        "      x1 = self.sa_block4(s1, s2, s3, s4)\n",
        "\n",
        "    x2 = self.upsample(x) # upsample\n",
        "    print(x2.shape)\n",
        "    x3 = torch.add(x1, x2) # add input + sa-net block's output\n",
        "    x4 = self.resSEblock(x3) # res block\n",
        "    return x4"
      ],
      "metadata": {
        "id": "TuHq6-3HK3rX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test decoder block class\n",
        "input = torch.randn((384,8,8,8), dtype=torch.float) \n",
        "\n",
        "trial = DecoderBlock(input_channels=384, output_channels=192, size=16)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 4)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "id": "fv3dY2EpLQPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fafe6c2-e271-4603-b40e-947567d0198d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=16, stride=16, padding=0)\n",
            "    (fclayer1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fclayer2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([384, 8, 8, 8])\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((192,16,16,16), dtype=torch.float)\n",
        "\n",
        "trial = DecoderBlock(input_channels=192, output_channels=96, size=32)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 3)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaSXVf2xSWvG",
        "outputId": "57aa8221-3f3b-43d5-c124-6fcda3f66b3f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=32, stride=32, padding=0)\n",
            "    (fclayer1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fclayer2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([192, 16, 16, 16])\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((96,32,32,32), dtype=torch.float)\n",
        "\n",
        "trial = DecoderBlock(input_channels=96, output_channels=48, size=64)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 2)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LT0GZGGSsHz",
        "outputId": "00ea1c7f-a75c-487a-e3fd-b0bf0849fb72"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=64, stride=64, padding=0)\n",
            "    (fclayer1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fclayer2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([96, 32, 32, 32])\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((48,64,64,64), dtype=torch.float)\n",
        "\n",
        "trial = DecoderBlock(input_channels=48, output_channels=24, size=128)\n",
        "\n",
        "s1 = torch.randn((1,24,128,128,128), dtype=torch.float)\n",
        "s2 = torch.randn((1,48,64,64,64), dtype=torch.float)\n",
        "s3 = torch.randn((1,96,32,32,32), dtype=torch.float)\n",
        "s4 = torch.randn((1,192,16,16,16), dtype=torch.float)\n",
        "\n",
        "print(trial)\n",
        "print()\n",
        "\n",
        "out = trial(input, s1, s2, s3, s4, 1)\n",
        "# print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-99jiyo2S2P8",
        "outputId": "aeb4ecc8-470f-4c41-f222-06513ce4bfde"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderBlock(\n",
            "  (upsample): ConvTranspose3d(48, 24, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
            "  (resSEblock): ResSE_Block(\n",
            "    (conv): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
            "    (instnorm): InstanceNorm3d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (globalpooling): AvgPool3d(kernel_size=128, stride=128, padding=0)\n",
            "    (fclayer1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fclayer2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "  )\n",
            "  (sa_block1): SA_Block1(\n",
            "    (conv_initial1): Conv3d(48, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial2): Conv3d(96, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(192, 24, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=24, out_features=6, bias=True)\n",
            "    (fcn2): Linear(in_features=6, out_features=24, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block2): SA_Block2(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial3): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=48, out_features=12, bias=True)\n",
            "    (fcn2): Linear(in_features=12, out_features=48, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block3): SA_Block3(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv_initial4): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=96, out_features=24, bias=True)\n",
            "    (fcn2): Linear(in_features=24, out_features=96, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            "  (sa_block4): SA_Block4(\n",
            "    (maxpool_initial1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (conv1): Conv3d(24, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv2): Conv3d(48, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (conv3): Conv3d(96, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
            "    (instancenorm): InstanceNorm3d(24, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "    (relu): ReLU()\n",
            "    (global_avg_pooling): AdaptiveAvgPool3d(output_size=1)\n",
            "    (fcn1): Linear(in_features=192, out_features=48, bias=True)\n",
            "    (fcn2): Linear(in_features=48, out_features=192, bias=True)\n",
            "    (sigmoid): Sigmoid()\n",
            "    (softmax): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "\n",
            "torch.Size([48, 64, 64, 64])\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SA_Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # first conv3d with 1x1x1 kernel (just to increase channels)\n",
        "    self.conv3d_1x1x1 = nn.Conv3d(in_channels=4, out_channels=24, kernel_size=1, stride=1)\n",
        "\n",
        "    # encoder blocks\n",
        "    self.encoderblock1 = EncoderBlock(n_blocks=1, input_channels=24, output_channels=48, size=128)\n",
        "    self.encoderblock2 = EncoderBlock(n_blocks=2, input_channels=48, output_channels=96, size=64)\n",
        "    self.encoderblock3 = EncoderBlock(n_blocks=2, input_channels=96, output_channels=192, size=32)\n",
        "    self.encoderblock4 = EncoderBlock(n_blocks=2, input_channels=192, output_channels=384, size=16)\n",
        "    self.encoderblock5 = EncoderBlock(n_blocks=1, input_channels=384, output_channels=1, size=8) # output_channels doesn't matter\n",
        "\n",
        "    # decoder blocks\n",
        "    self.decoderblock1 = DecoderBlock(input_channels=384, output_channels=192, size=16)\n",
        "    self.decoderblock2 = DecoderBlock(input_channels=192, output_channels=96, size=32)\n",
        "    self.decoderblock3 = DecoderBlock(input_channels=96, output_channels=48, size=64)\n",
        "    self.decoderblock4 = DecoderBlock(input_channels=48, output_channels=24, size=128)\n",
        "\n",
        "    # 1x1x1 convs to change channel size (leading to output of model)\n",
        "    self.conv1x1x1a = nn.Conv3d(in_channels=192, out_channels=3, kernel_size=1)\n",
        "    self.conv1x1x1b = nn.Conv3d(in_channels=96, out_channels=3, kernel_size=1)\n",
        "    self.conv1x1x1c = nn.Conv3d(in_channels=48, out_channels=3, kernel_size=1)\n",
        "    self.conv1x1x1d = nn.Conv3d(in_channels=24, out_channels=3, kernel_size=1)\n",
        "\n",
        "    # scale attention blocks for each scale\n",
        "    self.sa_block1 = SA_Block1()\n",
        "    self.sa_block2 = SA_Block2()\n",
        "    self.sa_block3 = SA_Block3()\n",
        "    self.sa_block4 = SA_Block4()\n",
        "\n",
        "  def forward(self, x):\n",
        "    print(x.shape)\n",
        "    # increase channels of input\n",
        "    x = self.conv3d_1x1x1(x)\n",
        "    print(x.shape)\n",
        "    # encoder block # 1\n",
        "    out1, x1 = self.encoderblock1(x, True)\n",
        "    print(out1.shape)\n",
        "    print(x1.shape)\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 2\n",
        "    out2, x2 = self.encoderblock2(x1, True)\n",
        "    print(out2.shape)\n",
        "    print(x2.shape)\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 3\n",
        "    out3, x3 = self.encoderblock3(x2, True)\n",
        "    print(out3.shape)\n",
        "    print(x3.shape) \n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 4\n",
        "    out4, x4 = self.encoderblock4(x3, True)\n",
        "    print(out4.shape)\n",
        "    print(x4.shape) \n",
        "    print(\"\\nnext block\\n\")\n",
        "    # encoder block # 5\n",
        "    out5, x5 = self.encoderblock5(x4, False)\n",
        "    print(out5.shape)\n",
        "    print(x5.shape)\n",
        "\n",
        "    print(\"\\nDecoder time\\n\")\n",
        "    # decoder block # 1 (contains SA-Net)\n",
        "    x6 = self.decoderblock1(x5, out1, out2, out3, out4, 4)\n",
        "    print(x6.shape)\n",
        "    output1 = self.conv1x1x1a(x6)\n",
        "    print(\"output1 \" + str(output1.shape))\n",
        "    trilinearoutput1 = nn.functional.interpolate(input=output1, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output1 \" + str(trilinearoutput1.shape))\n",
        "\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # decoder block # 2 (contains SA-Net)\n",
        "    x7 = self.decoderblock2(x6, out1, out2, out3, out4, 3)\n",
        "    print(x7.shape)\n",
        "    output2 = self.conv1x1x1b(x7)\n",
        "    print(\"output2 \" + str(output2.shape))\n",
        "    trilinearoutput2 = nn.functional.interpolate(input=output2, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output2 \" + str(trilinearoutput2.shape))\n",
        "\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # decoder block # 3 (contains SA-Net)\n",
        "    x8 = self.decoderblock3(x7, out1, out2, out3, out4, 2)\n",
        "    print(x8.shape)\n",
        "    output3 = self.conv1x1x1c(x8)\n",
        "    print(\"output3 \" + str(output3.shape))\n",
        "    trilinearoutput3 = nn.functional.interpolate(input=output3, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output3 \" + str(trilinearoutput3.shape))\n",
        "\n",
        "    print(\"\\nnext block\\n\")\n",
        "    # decoder block # 4 (contains SA-Net)\n",
        "    x9 = self.decoderblock4(x8, out1, out2, out3, out4, 1)\n",
        "    print(x9.shape)\n",
        "    output4 = self.conv1x1x1d(x9)\n",
        "    print(\"output4 \" + str(output4.shape))\n",
        "    trilinearoutput4 = nn.functional.interpolate(input=output4, size=(128,128,128), mode='trilinear') # trilinear interpolation\n",
        "    print(\"trilinear interpolation output4 \" + str(trilinearoutput4.shape))\n",
        "\n",
        "    return trilinearoutput1, trilinearoutput2, trilinearoutput3, trilinearoutput4"
      ],
      "metadata": {
        "id": "S15bw1K6mFip"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn((1,4,128,128,128), dtype=torch.float)\n",
        "\n",
        "model = SA_Net()\n",
        "\n",
        "# print(model)\n",
        "print()\n",
        "\n",
        "out = model(input)"
      ],
      "metadata": {
        "id": "ACPaXIW2mbeV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13283457-7851-4739-9c00-7e5bc70179d9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "torch.Size([1, 4, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "\n",
            "Decoder time\n",
            "\n",
            "torch.Size([1, 384, 8, 8, 8])\n",
            "channels: 192\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "torch.Size([1, 192])\n",
            "\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "torch.Size([1, 192, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "output1 torch.Size([1, 3, 16, 16, 16])\n",
            "trilinear interpolation output1 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 192, 16, 16, 16])\n",
            "channels: 96\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "torch.Size([1, 96])\n",
            "\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "torch.Size([1, 96, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "output2 torch.Size([1, 3, 32, 32, 32])\n",
            "trilinear interpolation output2 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 96, 32, 32, 32])\n",
            "channels: 48\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 32, 32, 32])\n",
            "torch.Size([1, 48, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 12])\n",
            "\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "torch.Size([1, 48])\n",
            "\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "torch.Size([1, 48, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "output3 torch.Size([1, 3, 64, 64, 64])\n",
            "trilinear interpolation output3 torch.Size([1, 3, 128, 128, 128])\n",
            "\n",
            "next block\n",
            "\n",
            "torch.Size([1, 48, 64, 64, 64])\n",
            "channels: 24\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 64, 64, 64])\n",
            "torch.Size([1, 24, 32, 32, 32])\n",
            "torch.Size([1, 24, 16, 16, 16])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 6])\n",
            "\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "torch.Size([1, 24])\n",
            "\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "torch.Size([1, 24, 1, 1, 1])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "torch.Size([1, 24, 128, 128, 128])\n",
            "output4 torch.Size([1, 3, 128, 128, 128])\n",
            "trilinear interpolation output4 torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output1, output2, output3, output4 = out"
      ],
      "metadata": {
        "id": "2Frv5OozRchm"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output1.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YK-PnjKRkZJ",
        "outputId": "a78925e8-1894-4db4-ce22-9c8869851686"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rqgaZwdRpoT",
        "outputId": "57f7a753-fd1b-43a5-db55-0465367fbb47"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output3.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tetr9iHYRq45",
        "outputId": "7b0545ed-a567-4d7a-982b-811c593b87b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpiA6vmtRrmg",
        "outputId": "5987da22-afd7-471a-b88c-d3e1900df8f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 128, 128, 128])\n"
          ]
        }
      ]
    }
  ]
}